# Recap

On 2024-07-23, I resolved a problem with tracking different sizes in the
kinds of types. The problem was that `Option` and `Result` were partial
type constructors (they could not be applied to a 64-byte argument).
The solution was to break types into two different types: ordinary
types and composite types. Composite types cannot be used to instantiate
a type variable. One correction I'll add is changing

    Option : Type -> CompositeType
    ==>
    Option : CompositeType -> CompositeType

We can put anything in an `Option`, even another composite type.

Also, I believe that it might be possible to treat fixed-length array types
the same way. I am not sure if it is actually worth doing though.

# Regions, Uniqueness, Subtypes

Putting everything together, what kind of syntax might we have? I'll
use something verbose but explicit. In a high-level language:

    replicate : (r : Region) -> (a : Type) -> S64@(Many,GlobalHeap) -> a@(Many,r) -> (List a)@(Many,r)

We annotate types with uniqueness and with region information. These
annotations are pushed down into the fields of ADTs. So, for example,
the `a` in `List a` does not have any annotations because all of the
fields of type `a` inherit the annotation from the parent type.

Our list type can be used to represent a list where both the spine and the
elements are unique. It can also be used to represent a list where both
the spine and the elements are nonunique. However, it cannot deal with
a list where the spine is unique but the elements are not. I've never
felt very sure about how to deal with this. One solution is to just make
a separate type. Another solution is to add a magic type constructor
that subverts the uniqueness. Linear haskell has this (for a linear type
system) in the form of the `Unrestricted` type constructor. If we adopt
that here, we could use `replicate` like this:

    replicate{GlobalHeap, Unrestricted Person}(100,myUnrestricted myPerson)

A unique reference to something wrapped in `Unrestricted` would not give
us the ability to mutate it. We could recover a nonunique reference to the
object or even create additional "unique" references to it. I do not like
this because of the bad ergonomics for the programmer. But it prevents us
from having to define two different list types. Every container type is
going to have this same problem.

I believe that my conclusion when I thought about this before was that
supporting the "unique spine, nonunique element" case was not worth doing.
Bending the type system to support this is doable (but somewhat painful),
but incorporating this into the runtime is even worse. We would need to trace
mutable data to find the immutable (nonunique) elements at the leaves. And
that's not an easy task. We end up with scenarios where it's possible for
a GC cycle to discover the element, and then we free the spine later, but
the reference count for the element is zero (because RC from mutable things
should not need to be tracked), and it's a mess.

# Regions and Global Heap

It would be neat if the global heap could be treated as just another region.
That way, a region-polymorphic function would not need to be specialized.
The region would just be passed in as an argument, and that argument could
be the global heap. If we are doing any kind of GC that involves tracing,
this should actually work just fine. When values go out of scope, both the
global heap and regions work the same way. Allocation differs slightly
but not on the common path. Consider exhausting a block and taking the slow
path of asking the runtime for a new block to allocate into. When allocating,
into a region, this is never an acceptable time to force a collection cycle
to occur. But when allocating into the global heap, it might be.

Since this different behavior happens on the slow path, it's fine.

# Fixed-Size Integral Types and Regions

An `S64` doesn't actually live in any region. It's always on the stack or
in a register. But it is difficult to capture this in the type system.
Consider a function that operates on any 8-byte type (including those
that have pointers):

    head : (a : Type8) -> (r : Region) -> (List a)@(Many,r)-> a@(Many,r)
    head{S64} : (r : Region) -> (List S64)@(Many,r)-> S64@(Many,r)
    head{Foo} : (r : Region) -> (List Foo)@(Many,r)-> Foo@(Many,r)

A value of type `S64` is never tied to a particular region, but a value
of type `Foo` might be (if `Foo` is allocated on the heap or is a struct
that contains heap-allocated fields).

I think this is just something that must be endured.

# Regions on the Stack

Some region allocations can be optimized further. If the region is known
to contain a small number of allocations, we should use the stack
(or something like it) instead of paying the overhead of managing blocks.
The difference between the two is summed up in this way:

* A stack-based approach never needs to check if space is available. It is
  simply assumed to be available, and the program fails with SIGSEGV if it
  is not. A stack-based approach must be restricted to some small number of
  kilobytes of allocation.
* A region-based approach allocates into blocks. The memory in these blocks
  are filled contiguously. This must always check to see if we have reached
  the end of the block. This can handle arbitrarily large objects.

Actually, stack-based allocation has even more restrictions. The stack cannot
be understood as a resource that can be passed around freely. If we have a
chain of `withStack (\s1 -> withStack (\s2 -> ...))`, we cannot allocate
into `s1` inside the second callback. So really, what makes the most sense
is to just have this instead:

    withStackAllocated :: forall (b : Type) (br : Region) (u : Uniqueness) (v : Uniqueness).
      (forall (r : Region). a@(u,r) -> b) -> b@(v,br)

This requires rank-2 types. But now we can use our stack-allocated object
in any position that would normally take a region-allocated object. But
the region is exposed there in a read-only way. This suggests that region
binders need to be equipped with a capability indicating whether or not
allocating new objects into the region is permitted. This makes sense.
Think about a function for looking up a value from a map:

    lookup : forall (r : Region[ReadOnly]). (Map a)@(Many,r) -> S64@(Many,GlobalHeap) -> a@(Many,r)

We do not expect a `lookup` function to allocate anything into the region,
and this type makes that guarantee explicit. Representationally, nothing
is different about a read-only region and a read-write region. They are
both just a pointer to some metadata. Here's another example:

    bool : forall (r : Region[ReadOnly]). Bool@(Many,GlobalHeap) -> a@(Many,r) -> a@(Many,r) -> a@(Many,r)

During function application, nearly all region variables can be inferred.
Functions that accept a lot of read-only data are going to end up with
a ton of region arguments. This has always been my hesitation with regions.
They lead to a ton of region variables in type signatures.

In all the examples in this entry, I have put primitive types like `Bool`
and `S64` on the global heap. There is no point in having a region variable
for these. The argument would just be unused, so it is better to require
the caller to coerce the value instead. A slightly better solution is
introducing another heap type called "prim" or something like that.
Then we would write:

    add : S64@(Many,Prim) -> S64@(Many,Prim) -> S64@(Many,Prim)

Although `Prim` is technically a region (and can be passed as an argument),
it's not actually possible to allocate anything into it. This helps clarify
cases where we just need a placeholder region.

It would be kind of neat if the global heap had to be threaded through
programs explicitly. Currently, it's just kind of available everywhere, and
it can be used in the body of a function without impacting the function's
type signature. But under the hood, it does actually have to be passed in.
That is, in assembly, the way a function is called is different if it performs
any global-heap allocations (even just local ones that do not escape).
We could capture this in the type system. But how exactly? The global heap
is just like all the other regions. We could distingush regions from
garbage-collected regions. Then we would have something like this:

    data Mode = ReadOnly | ReadWrite
    data Collection = Uncollected | Collected
    data Region = Region Mode Collection
    myFunction : (g : Region ReadWrite Collected) -> Foo@(Many,g) -> Bar@(Many,g)

The function `myFunction` uses the global heap. It takes an argument that
lives on this heap, and it allocates something into this heap as a result.
There are two interesting things about this approach:

1. We can actually allocate multiple GC-managed heaps.
2. A function has locally make use of its own GC-managed heap. If it does
   this, the arguments and the return value cannot talk about this heap.
   When `withCollectedHeap` returns, the local heap is discarded without
   any need for heap scans.

Additionally, this means that it is possible to build the programming language
without designing a garbage collector. There are some programs that can be
conveniently written with a LIFO stack of regions and single-owner objects
(uniqueness) that are deallocated by something like `free`. I don't
personally think that it's a good idea to build most programs this way,
but it works fine in small cases. I would need to have `freeze` kill the
program when used in a `Collected` heap. But allocating something mutable
into a `Collected` heap should be fine because we could can infer where
deallocations should happen.

# Subtypes

We want the following subtyping relations:

* `ReadWrite <: ReadOnly`. If a function uses a region in a read-only way,
  we can pass it a read-write region. This is like dropping a write capability.
* `Collected <: Uncollected`: If a function needs an uncollected region
  (probably to allocate into it), we can give it a collected region instead.
