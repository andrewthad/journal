# Reference Counting

Now I'm thinking about reference counting again. I thought about not
counting any references from the stack and basically just waiting until
a function returns to decide whether or not anything referenced by the
stack is live. But this only works when there is a single stack frame.
It doesn't work when functions can call other functions.

The problem is that we really need those references from the stack to
count. Let's say that we allocate something, bind that object to a
local variable, and then feed it into a function the uses it as the
field of an object. At some point, that object will die, and the runtime
will have to ask "is anything still referencing the object that this field
points at?" Tracking references from the stack could be more simple. It
could be a binary yes or no, with "yes" meaning that there are one or more
references from the stack.

It's beginning to feel like some variant of deferred RC will make the
most sense. Before, I have thought about deferred RC as a trick to make
a nursery compatible with RC. But now I'm thinking about something different.
If a user is trying to improve the performance of allocation and deallocation,
they need to use regions. Since I have a different goal for deferred RC,
I no longer need to wait for the program to produce large amounts of
unreachable memory. The trace-and-update operation can run much more frequently
because there is nothing to gain by running it infrequently.

The strategy of The Recycler, explained in section 2 of the paper, is:

1. Changes in heap objects result in increment/decrement pushed to a
   mutation buffer.
2. Every object is allocated with an initial RC of 1. A decrement is
   immidiately pushed into the mutation buffer.
3. No immidiate operations for references from stack. During collection,
   the stack is traced to produce a "stack buffer". These references are
   interpreted as increments for the current epoch and then as decrements
   for the next epoch. 
4. For reasons I don't fully understand, there is an epoch delay in processing
   decrements from the mutation buffer. The paper says that this is "to avoid
   race conditions that might cause the collector to process a decrement
   before the corresponding increment has been processed". I think this might
   only matter in a multithreaded setting.
5. There is a collector CPU/thread with exclusive access to all of the
   counters.

This is a cool strategy. Observations:

* Range operations on arrays of boxed elements are still terrible, just like
  they are in vanilla RC. If the mutation buffer has a fixed size, it's not
  even possible to support range operations on arrays since you might end up
  pushing more elements than the mutation buffer has room for.
* In a polymorphic setting, the prompt updates to the mutation buffer will
  require some kind of "if this is a boxed, do one thing, otherwise, do other
  thing" all over the place. This might be ok though. If we unconditionally
  push the value and its type, we have to figure it out later, but we really
  don't want to fill up the mutation buffer with a bunch of no-ops.
* The paper describes concurrent collection. This features: (1) a dedicated CPU
  for performing the updates and (2) collector triggered by various events.
  I'm less interested in these features. I would rather have collection happen
  deterministically. The most obvious trigger is the mutation buffer. Let's
  say that it has, maybe 300 slots, and when they are full, we perform a
  collection. But this is not great. If we didn't have anything that was
  variable-length (e.g. regions, arrays), then the number of slots in the
  mutation buffer would provide an upper bound on the unreachable memory
  that was being kept live. If every object was at most 64 bytes and there
  were 300 slots, then we could have 300 unprocessed decrements, plus whatever
  was in the stack buffer, plus everything reachable from anything that was
  supposed to be axed. So nevermind, it's actually already unbounded.
* It's possible to get rid of the stack buffers (and avoid scanning the stack).
  The cost is that we have to push all (boxed) local variables onto the
  mutation buffer, and when they go out of scope, we have to push decrements
  for them. There are some elision opportunities here. For example, if a
  local variable's lifetime is dominated by an object that it was a projection
  from, we can avoid adjusting the counter. But in many cases, we will not
  be lucky like this.

Possibly the biggest difference between this strategy and the nursery-based
strategy I had previously thought about is that this one includes a form of
intensional polymorphism that infects every polymorphic function.
By contrast the nursery-based scheme makes the ordinary code path
("the mutator") more simple. 
