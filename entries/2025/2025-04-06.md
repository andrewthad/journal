# Thoughts Continuing 2025-02-21 Entry

I'm coming back to this after a month, and the entry that I wrote on 2025-02-21
still feels pretty accurate to me. Here are two related concessions that are
starting to feel more appealing:

1. Represent pointers with 64 bits instead of 32 bits.
2. Represent pointers fully resolved instead of as an offset.

It's possible to do the first one without the second one, but it's not possible
to do the second one without doing the first one. By doing both, here are the
things that we lose:

* We cannot serialize an in-memory representation. Or at least, we cannot
  serialize something in such a way that it can be rehydrated with `mmap`.
  We would need some kind of "fixup" step (like GHC's compact regions).
* Pointers are larger. They take up more space.

Here is what we gain:

* It is no longer necessary to resolve addresses.
* Because we don't need to resolve addresses, regions can be cleanly
  represented by a pointer to region metadata. Regions do not have to be
  interpreted as both a base pointer and metadata. This helps with codegen
  when lowering to C.
* We can take interior pointers to arrays.

I think this trade is worthwhile because I no longer think that the downsides
are very serious. In particular:

* Using `mmap` to load in data is cool, but it assumes a particular
  environment: A traditional UNIX system. This doesn't work terribly well in
  the environments that cloud providers offers. There, it makes more sense
  to load data from object storage and deserialize it (which implies
  validating it). I don't think this feature is useless. I just think
  that it's not worth complicating things for. Especially for small objects,
  serialization makes more sense because you get to validate the data.
* The extra space needed for 8-byte pointers should be acceptable because
  a sufficiently low-level language helps the user avoid pointers.
  In particular, if we can inline arrays into data structures, we should
  be alright.

Even with 64-bit pointers, we could still keep a restriction on the size
of an array. This could be a restriction to 32 bits, or it could be 48 bits.
The only place that 32 bits is going to help us is when we have an object
with a bunch of string fields in it. We could arrange all of the fields
so that we only pay 96 bits (instead of 128 bits) for each string. But I'm
not sure if that's a good enough reason to do that. We definitely want
the 48-bit restriction because that lets us use an array as one choice
in a 128-bit result type.

Now, onto the the next thing.

# Splitting Up Blocks

Making all blocks be 4KB has an appealing simplicity, but it has a serious
flaw: It is not possible to allocate arrays that are larger than 4KB. For
this reason, I think that this is not acceptable even as a short-term
solution. I need to figure out how to split up (or merge) blocks. It is
not necessary to support all sizes. We don't need any blocks smaller
than 256B (maybe 512B), and it's fine to have all the sizes be powers
of two. This problem space feels a lot like the problem space that a
traditional allocator sits in. Maybe I should start by using a traditional
allocator and then wait until I have enough programs to benchmark doing
something custom here.

It's worth considering mimalloc here. Look at `mi_heap_new` and
`mi_heap_malloc`. I think this can be done without changing the API
for function calls. We can put a `mi_heap_t*` in the region metadata
(beside the reference count).

# Regions With Just One Object

I should probably use a traditional allocator for the regions that only
have one object. These allocators can handle small objects, which is good.
Again, mimalloc should work well here. We could probably allocate these
with `mi_malloc_small`. We need to put the read-only region metadata
(possibly just a reference count) adjacent to the object. And when we
deallocate, we have to make sure that we use `mi_free` instead of
`mi_heap_destroy`.

# Multithreading

The interaction between multithreading and memory management is painful.
Here are the rules that I am aware of:

* Do not allocate into the same region from multiple threads
* Do not mess with reference counts from multiple threads

This makes it difficult to share memory across threads. One pattern
that might work is having a fork-join primitive that has the parent thread
do the increment and decrement operations on the reference counter. But
I cannot figure out how to stop the child thread from performing any
operations on the reference counts.

Another option is completely prohibiting any shared memory between the
threads. It's possible to do this by restricting the context or by having
a primitive only takes top-level functions as arguments. This works, but
it's very restrictive.

# Constant Data

I need to put constant objects somewhere. I think I can just stick them
in a read-only part of memory and set the reference count to something
really high. I'm not sure if C gives you a way to set up a piece of
memory like this. I might be able to stash information in each objects
symbol table and then construct the actual "static data" area at load
time. It would be better to do this at compile time, but again, C probably
pushes us toward load time. We might need an indirection to be able to
do this without giving up separate compilation.

A more simple alternative is to start by just allocating these like other
data. Then I could add the "top region" later.

Note to self: Think about how these strategies interact with multithreading.

# Nonuniform Representation of Function Arguments

I have a better writeup of this in a binder. I think it would be nice
if we always used staging for HOF. I'd like to use 128-bit registers
(or maybe 256-bit registers) for values with abstract types. The interaction
between this and HOF is not good. Also, as I've played around with functions
returning "result" types, I've found that specialization of the result type
helps a lot. But again, this does not play nicely with a traditional
implementation of HOF, which assumes uniform representation.

# The Language and The Language

Making a PL is a big chicken-and-egg problem. We need a compiler to actually
run our code, but we need code to motivate working on the compiler. One option
is to take a subset of the language. The right subset can be compiled with
a more simple compiler.

The most obvious subset of the language I want to make is one that lacks
regions. That is, all of the objects are existentially packed with their
corresponding region. For this subset, we can use any kind of automatic
memory management scheme, not just RC. It might be possible to create a VM
for this subset, but I'm not sure that this is any more convenient than
compiling to C.

This thought doesn't seem to be going anywhere. Sorry.
