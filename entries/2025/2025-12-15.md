# More Thoughts on Intensional Polymorphism Difficulties

After trying to add first-class functions (but not necessarily closures)
to a toy programming language, I've started to notice places where my
approach to intensional polymorphism does not work great. The strategy
that I've been using is to represent polymorphic types as sizes at runtime.
That's it. Just sizes. This works fine for most polymorphic data types.
You cannot put several fields with different unknown types in the same
data constructor, but that's a need that I don't commonly have. Functions
with abstractly typed arguments just need to be given pointers to values
at runtime (instead of the values themselves). And to return a value with
a polymorphic type, we need to use an out parameter. The approach described
by these rules seems to work fine.

First-class functions lead to problems. The problems all have to do with
calling conventions. One issue is that, when we see a function with a
type like `S64 -> S64`, we cannot use the C type `int64_t (*)(int64_t)`.
It would be really nice to be able to use this though because it would
give us a nice calling convention when we applied the function. The
problem is that sometimes, we might be using our `S64 -> S64` function
in a context where all we know is that the type is `a -> a`. For example,
we can pass an `S64 -> S64` function to a `modify` with the type
`(Array a, Int, a -> a) -> Array a`. And it can go the other way too.
Sometimes, we might pass the identity function (has type `a -> a`)
to a function that is specifically working on integers. So we end up
in a situation where we are nudged in the direction of indirecting
things more than we would like to.

We can push this difficult into the types themselves instead of punishing
all indirect function calls. Here's the idea: There is a type constructor
`Ref` that can be a pointer to anything and has a fixed size. Additionally,
functions are prohibiting from taking arguments with abstract types. So,
for example:

    filter : (Array a, Ref a -> Bool) -> Array a

In a system with regions, `Ref` needs to either be second class, or it
needs to be associated with a region. For example:

    filter : forall r s. (Array@r a, forall t. Ref@t a -> Bool) -> Array@s a +{Alloc(s)}

We can take a reference to an element of an array:

    indexRef : (Array@r a, S64) -> Ref@r a

We can recover a value from a reference of a known concrete type:

    recoverS64    : Ref@r S64 -> S64
    recoverPerson : Ref@r Person -> Person

We probably want some kind of `MutRef` type as well. I'll ignore that for now
because it's not complicated.

It would be neat if a `Ref` to boxed data just reused the pointer itself.
I don't think it's possible to do that though because then we would not
treat everything homogeneously. It's got to be done as a dereference
(accompanied by a size).

Let's consider how we would treat some common array functions:

    map : (a -> b) -> Array a -> Array b
    ==>
    map : (forall w x. Ref@w a -> WriteRef@x s b -> () +{Mut s}) -> Array@r a -> Array@s b
    ==> (without regions annotations on refs)
    map : (Ref a -> WriteRef s b -> () +{Mut s}) -> Array@r a -> Array@s b

It is nice to do this with references as second-class values instead.
The type signatures are unbearable without them. Let's try a fold:

    fold : (b -> a -> b) -> b -> Array a -> b
    ==>
    fold : (? -> Ref a -> ?) -> b -> Array a -> ?
    ==>
    fold : (forall s1. MutRef s1 b -> Ref a -> () +{Mut s1}) -> MutRef s b -> Array a -> () +{Mut s}

This is more difficult. We have to repeatedly update the `Ref` while folding
over the array. This is pretty hard to read, but it does work. Let's try an
update function for a mutable map:

    update : (forall s1. MutRef s1 a -> () +{Mut s1}) -> MutMap s a -> () +{Mut s}

It would be nice to not track state tokens like GHC does. Consider this:

    update : (MutRef a -> () +{Mut}) -> MutMap a -> () +{Mut}

It's much easier to read, and it's still evident that the mutation is
happening. Or even this instead:

    update : (MutRef a -> ()) -> MutMap a -> ()

If there are no global mutable variables, we still end up with referential
transparency. It might be important to ban closing over mutable variables
though if we want to have closures. It looks I wrote about this in some
depth on 2025-08-11. In that post, I ended up describing a system with
mutable, immutable and read-only values. The difficulties that I encountered
were that the read-only arrays could be very difficult to reason about.
You would never want to put them in a data structure because it would
lead to confusing behaviors in the case that something mutable aliased
them. So what would they be useful for? Things like a POSIX `write` to
a file descriptor, and also standard array functions like `sum` and possibly
even `map` and `fold`. It's a little odd to include `map` and `fold` since
the function argument could modify the backing array itself. But if it did,
the result would still be deterministic. It's not unreasonable to commit
to an iteration order for both of these functions.

On 2025-11-06, I described why I had rejected the use of second-class values
as a way to suppress region annotations. I'm not sure that I still agree
with myself. Field projection itself can have special typing rules. It's
true that this will not generalize nicely to anything built out of a chain
a projections, but I'm not convinced that this limitation has any serious
practical consequences.

So perhaps we could have this instead:

    map : (Ref+RO a -> Ref+RW b -> ()) -> Array+RO a -> Array+I@r b +{Alloc(r)}

Notice that the final array is a true immutable array.
This signature is not bad. It's very flexible in what it accepts. And it's
easy to lower it to C code that (given that there is no inlining happening)
is optimal.

It would be so nice to just drop the distinction between read-only and
immutable. Then the `map` function would return a mutable array instead.
But, as I already noted on 2025-08-11:

> A system like this would inherit one of C's weaknesses. And that weakness is
> that data that the user considers "immutable" is not really immutable. If you
> read from an "immutable" object at some time during program execution and then
> you read from it again later, you might get different results. Not only does
> the compiler have to be prepared for this, the user has to be prepared for this
> as well.

But maybe this is not as bad as I make it out to be. The way to recover
your ability to reason about this system is to make sparing use of mutable
arrays. For example, if you do not pass any mutable data to a function,
you don't have to worry about aliasing. Anything mutable that is allocated
inside the function cannot alias any other data. What kinds of functions
really need to take mutable arrays as arguments:

* In-place modifications. Functions like `reverse` are fine because there
  is only one argument. Functions like `permute` are problematic because
  the array of indices might also be the backing array.
* Functions that read into a buffer.

Alright. I'll give up on trying to unify immutable arrays and read-only
arrays. Here's another way that we might want `map` to look:

    map        : (Ref a -> WriteRef b -> ()) -> Array a -> Array@r b +{Alloc(r)}
    map        : (Ref+R a -> Ref+W b -> ()) -> Array+R a -> Array@r b +{Alloc(r)}
    mapInPlace : (MutRef a -> ()) -> MutArray a -> ()

`Array` and `Ref` are pretty similar. It should not be this difficult to pick
a notation. Let's think:

* `Array+RW`: A mutable array
* `Array+W`: A write-only array
* `Array+R`: A read-only array (might alias mutable arrays)
* `Array+0`: An array that is not accessed in any way
* `Array+I`: An immutable array (cannot alias mutable arrays)
* `Array`: Possibly a shorthand for `Array+I`. This is the most common use.

# Ref Issues

I thought more about the `Ref` strategy for mapping over arrays and realized
that it has a flaw. What happens if the function does not write to the `WriteRef`?
That's a problem. We need `map` to look more like this:

    map : (Ref a -> b) -> Array+R a -> Array@r b +{Alloc(r)}

But where the function has a calling convention that causes it to accept
and argument pointer to which the output gets written. We could just make
all functions have this calling convention, but this would negatively impact
lots of code. We could wrap `b` in something kind of like how `a` is wrapped:

    map : (Ref a -> Out b) -> Array+R a -> Array@r b +{Alloc(r)}

But that seems inappropriate. `Ref` is truly a pointer to a value, and it
can be dereferenced to recover the value. But `Out` is really just the value
itself. It would be more appropriate to introduce a different arrow:

    map : (Ref a => b) -> Array+R a -> Array@r b +{Alloc(r)}

This more clearly communicates what is going on. For example, we have an
ordinary increment function that looks like this:

    increment : Int -> Int

And then we have the variant of `increment` that can be used in `map`:

    increment' : Ref Int => Int

The first of these is more optimal in cases where we are calling a known
function with concrete types. The second has the flexibility to be used
in situations where a function with abstract argument and result types
is needed. There are other variants:

    increment''  : Ref Int -> Int
    increment''' : Int => Int

Both of these are useful in their own way. Consider a function that orders
a map by hashing everything:

    hashAndSort : (Ref a -> Int) -> Array a -> (Array@r Int, Array@r a)

We know that the hash function returns an `Int` and it's good to be able
to use a calling convention that takes advantage of this.

An alternative is to get rid of `Ref` and have `=>` change the calling
convention for the arguments and the result. This is more simple (a little
more uniform), but it gives users less control over the generated code.
I like the `Ref` thing.

If we already have `Ref` available, can we use it to collapse the distinction
between boxed types and unboxed types? For example, consider a `Person` type
with 10 fields. In most cases, it makes sense to pass this around by reference
(instead of copying all the data). So we would use `Ref Person` nearly
everywhere instead of `Person`.

This does not work well for tagged unions. The problem with these is that
payloads corresponding to the different tags will not generally have the
same size. Consider a type like:

    data Expr
      = Arithmetic Op (Ref Expr) (Ref Expr)
      | Literal S64

One of these data constructors needs more space than the other. To bring
this into the `Ref`-based framework, we would need to have `Expr` be a
type with unknown size (which cannot be stored). This is not too different
from how I am thinking about dealing with abstract types. A `Ref Expr` would
still be allowed. We could build an `Arithmetic` or a `Literal` directly
(since their sizes are known) and then take a `Ref` to them and upcast
to `Expr`.

This is kind of going in the right direction. Something that's interesting
about this strategy is that it suggests that the `Ref`, not the underlying
data type, is what needs to be tagged. For example:

    data Person = Person Int Int Int Int Int Int
    brandon : Ref@r Person

This gets more tricky when the type has boxed fields:

    data Person = Person (Ref@$ String) (Ref@$ String) Int
    brandon : Ref@r Person

Now the data type is incomplete until it gets paired with `Ref`. This does
not really make sense. It should look like this instead:

    brandon : Ref@r Person@r

The `r` attached to `Ref` means that the person itself is backed by
the region. And the `r` attached to the person means that all of their
heap-allocated fields live in that region. That's fine. It can probably
be cleaned up with a shorthand:

    brandon : *Person@r

And this shorthand duplicates the `r` into both places.

Let's see what a cons list would look like:

    data List a
      = Cons a (Ref@$ (List@$ a))
      | Nil

Alternatively, with the shorthand:

    data List a
      = Cons a *List(a)@r
      | Nil

What's the point of doing this though? What would we gain? Here are
a few benefits:

* The system itself is more simple. There is no longer a distinction between
  boxed types and unboxed types.
* For certain types, it is useful to deal with them both by reference or
  by value depending on what context we are in. In particular, it can be
  useful to have an array of elements where the elements are unboxed in
  the array, but when we index into the array, we want a pointer to the
  element (instead of a copy of it).
* Function pointers avoid unneeded indirections for some of their arguments.
  For example, consider something like `filter : (Ref a -> Bool) -> [a] -> [a]`.
  The predicate needs to be `Ref a -> Bool` to have a uniform representation.
  With this, we can filter array of a known-size type like `Person`. However,
  we can also have a variant of filter with the type signature
  `(Ref a -> Bool) -> [Ref a] -> [Ref a]`, and this one is better when the
  array has pointers. It lets us avoid nesting `Ref` (e.g. `Ref (Ref a) -> Bool`).

The system that I'm describing is similar to Golang. One quirk of Golang 
that I dislike is that its built-in map type is actually just a pointer,
but users cannot work with it as though it were a pointer. The same is
true for channels. See https://www.tapirgames.com/blog/golang-has-no-reference-values
for a description of the C `struct` that backs Golang's built-in reference
types.

There is a temptation to specialize operations on nearly any polymorphic data
structure for the common case where the element is a `Ref`. Let's say that
we are mapping over an array, going from one Ref type to another. We might
want this:

    map : (Ref a -> Ref b) -> [a] -> [b]

Notice that for this case, we do not even need the `=>` arrow.
Specializations like this might also be beneficial for Array/String.
I don't think this is a good path to go super far down, but it's nice
to have available for a few common types.

This approach to polymorphism contrasts strongly with the approach taken
by rust. Rust monomorphizes functions. This strategy works, and lots of
other languages do this, but it's complicated to implement, and you
basically lose separate compilation since all of your build artifacts
have to expose the bodies of polymorphic functions.

As a side note, I think I had started down this path years ago, but at
the time I was only thinking about taking references to array elements.
I had given up on it because it is incompatible with semispace GC. But
with regions, it works fine.

I do not like having to specify the region twice in the data constructor
for List. I'm having a hard time figuring out how this could be avoided.
It needs to be possible to have an unboxed type that refers to a region.
So it needs to be on the type itself. Oh, maybe we can just keep it off
of the `Ref`. Let's say that we have a `Person` type with just primitive
data, no pointers. We would write:

    bob1 : Person@0 // Top-level person as a struct
    bob2 : Ptr Person@0 // Pointer to a top-level person
    bob3 : Ptr Person@r // Pointer to a person, backed by some runtime region

This is probably fine, but it does not work with the trick of using
second-class values to elide region variables. Or maybe it does. It
should still be possible to have these rules:

    // Only for second-class values, not first-class values
    forall (a : Struct). a@r <<: a@âŠ¤ (quasi-subtyping, a term I made up)
    (a <<: b) ==> CTX[x : a {2}] |- x typechecks against b
    (a <<: b) ==> CTX[x : Ptr a {2}] |- x typechecks against Ptr b
    (a <<: b) ==> CTX[x : f a {2}] |- x typechecks against f b

This means that second-class values can forget their regions annotations,
and the forgetfulness passes through type constructors, although the
recovered values need to remain second class.

Thinking about it, I'm not sure if the second-class trick works well with
the Linear Regions Are All You Need paper's lowering. It's fine for this
to not work.
