# Something Like Heist Templating

I really like the heist templating language. It's a Haskell library that's
part of the snap web framework, but it's usable without snap. I've been
thinking about how to create something like heist without having functions
as first-class values. I think that you run into a need for GADTs, which
makes sense since GADTs or something like them are required for
defunctionalization. (See the paper Typed Closure Conversion from POPL 96.)
Let's see:

    type Context (e : *) = Map Text e
    type Person = { name : String, age : I64, ... }
    type PersonField = PersonName | PersonAge | ...
    ctx : Context PersonField = { "name": PersonName, "age": PersonAge, ... }
    applyTemplate :
         (e -> v -> Html) // The data is v and the field extractor is e
      -> Context e
      -> v
      -> HtmlTemplate
      -> Html

This works, and it only requires functions as second-class values. However,
it's not powerful enough to express templates that enumerate array fields.
Suppose that a `Person` has many pets. If we have first-class functions,
we can do it this way:

    // Note: Action requires an existential type
    type Action (e : *)
      = ActionOne (e -> Html)
      | ActionMany (e -> Array c) (Context c)
    type Context (e : *) = Map Text (Action e)
    applyTemplate :
         Context e
      -> e
      -> HtmlTemplate
      -> Html

This is simple, and it lets you build (and analyze) the spine of the substitution
context without having any values available.

# Variance Annotations

I had been worried about functions and about type constructors that use
type arguments contravariantly. My concern was that it would lead to
annotations being needed in a lot of places. I think I was wrong about
this. Variance can always be inferred except when higher-kinded types
are present.

# Functions and Intensional Polymorphism

Intensional polymorphism is a way of compiling polymorphic code without
specialization. In the system I imagine, it just means passing a size argument
in most places that a type variable shows up as an argument. Two notable
things I've run into:

1. Data constructors cannot have multiple polymorphic fields. It's just too
   much of a pain to compute the offset. Also, I realized that I never write
   data types that need this anyway.
2. I had to rethink how to pass a polymorphically typed value to a function.
   Originally, I thought it would be best to have maximum width (e.g. 32 bytes)
   and then pad the value out and store it in an AVX register. But you need
   AVX-512 (with masked loads and stores) for this to work well. That puts
   a lot of architecture constraints on the system, and it seemed difficult
   to make it work. I thought about it and realized that passing a pointer
   to the value would actually work well. As a bonus, there's no upper bound
   on the size when we do it this way. What's strange about this is that
   we cannot store the pointer anywhere. We can only read from it. This
   use restriction is fine, but it's important to keep it in mind. Because
   if we somehow accidentally returned the pointer from the function (or
   stored it somewhere), that could violate a lifetime invariant. One way
   of describing this is that the generated C code must use the pointer
   as a second-class value.

So what happens when we try to work with first-class functions? First, let's
think about just passing a function as an argument (second-class function
values). Without polymorphism, everything is simple. C supports function
pointers. But with polymorphism, it becomes more complicated. Let's think
about mapping over an array:

    map : {a} -> {b} -> (a -> b) -> Array a -> Array b

Since the implementation of `map` will call a function with an unknown
argument type (and an unknown result type), it needs to use pointers
for the argument and the result. That means that, for any function that
exists, we need to prepare a maximally polymorphic wrapper. Like this:

    int incr(int a) { return a + 1; } 
    void incr_polymorphic(int* out, int* a) { out = incr(*a); }

But it gets worse. One would hope that a function that accepted
a monomorphic function as an argument would get to use nice non-wrapped
functions. For example:

    mapI : (Int -> Int) -> Array Int -> Array Int
    mapI(incr, [0,1,2,3]) : Array Int

That seems to work. But what about functions that start out polymorphic
and are later monomorphized:

    const5 : {a} -> a -> Int
    mapI(const5{a}, [0,1,2,3]) : Array Int

One thing that will help us here is to reject Haskell's approach to using
subtyping for function. That is, `const5` cannot be used in places where
values with the type `Int -> Int` are needed. So we might actually have
something more like this:

    int const5(size_t sz, void* arg) { return 5; }

But here, we are stuck. We can get a C value of type `int(*)(int)` from this:

    int const5_apply_int(int arg) { return const5(sizeof(int), &arg); }

But we do not have a general way to do this. The problem is that the calling
convention is not stable under type argument application. This suggests that
any function passed as an argument to a function must be homogenized by
having all arguments indirected by pointers. I cannot see any way to avoid
this. Possibly, we could build an array with all the arguments instead:

    // Each arg is 32 bytes.
    int const5_generalized(unsigned char* opaque_args) {
      size_t sz = extract_size_t_at_index(opaque_args, 0);
      size_t arg = pointer_to_index(opaque_args, 1);
      return const5(sz, arg);
    }

This works. We can actually do slightly better. We don't have polykinds, so
the sizes of all types arguments should be known. That means that we do not
need 32 bytes for each type argument. In fact, we could just split functions
up into the type arguments and the value arguments. We could disallow
partial application of both of these, although supporting partial application
of values would not be difficult. Here's an example of a function:

    // the boolean eliminator
    bool : {a} -> a -> a -> Bool -> a
    // in C, this variant is used when bool is called directly
    void bool(size_t sz, void* out, void* x, void* y, int b) {
      void* src = (b == 0) ? x : y;
      memcpy(dst, src, sz);
    }
    // in C, this variant is used when bool is called indirectly
    void bool_indirect(void* type_args, void* val_args, void* out) {
      struct bool_val_args bool_val_args;
      struct bool_type_args bool_type_args
      memcpy(&bool_val_args, args, 96);
      memcpy(&bool_type_args, args, 8);
      bool(bool_type_args.sz, out, bool_val_args.x, bool_val_args.y, bool_val_args.b);
    }

The partial application of a function to its type arguments is represented by:

    struct func {
      void(*fn)(void*, void*, void*);
      void* type_args;
    }

This is not full support for partial application as it is usually understood
in function programming. This is partial application just for type arguments.
This means that the generalization of a function like `increment` will take
an unused argument:

    void incr_indirect(void* type_args, void* val_args, void* out) { *out = (*int)(val_args) + 1; }

One tricky problem that I overlooked is that the memory backing `type_args`
needs to be managed somehow. But type arguments are all very small. A region
has no representation at runtime (zero bytes), and ground type is represented
by its size, for which we only need a single byte. So it may make more sense
to do this instead:

    struct func {
      void(*fn)(uint64_t, void*, void*);
      uint64_t type_args; // Interpreted as 8 type arguments
    }

This is the same size (16 bytes), but it works in contexts where functions
are created with existential types and universal quantification. The only
restriction is that a function cannot have more than 8 type arguments, but
I think that's a reasonable restriction. So let's go back to the beginning.
Let's look at `map` again:

    map : {a} -> {b} -> (a -> b) -> Array a -> Array b

First, we have the direct verison:

    struct array map(uint8_t a, uint8_t b, struct func func, struct array src) {
      unsigned char* dst_payload = allocate(src.length * b)
      unsigned char* src_cursor = src.payload;
      unsigned char* dst_cursor = dst_payload;
      for(...) {
        // Here, we are able to use src_cursor directly because the
        // argument function is unary. In other cases, we would need
        // to build something padded out on the stack.
        fn.fn(fn.type_args, src_cursor, dst_cursor);
      }
      return (struct array){.length = src.length, .payload = dst_payload};
    }

And then we have the indirect version:

    void map_indirect(uint64_t type_args, unsigned char args[64], void* out) {
      uint8_t a = (uint8_t)type_args;
      uint8_t b = (uint8_t)(type_args >> 8);
      struct array* out_typed = out;
      struct array src;
      memcpy(src,args,sizeof(struct array));
      struct func func;
      memcpy(func,args + 32,sizeof(struct func));
      *out = map(a, b, func, src);
    }

It feels strange that the value arguments to `map_indirect` need to be padded
like this. I guess the important question is whether or not is it possible
to somehow call `map_indirect` without knowing the types of the values that
it is given. I don't know. Clearly, it's possible for `increment` to be
called in a context whether we no longer know the argument type. It's more
difficult to imagine how this could happen with `map` since we don't have
partial application. Really, it's difficult to see how we would ever end up
using `map` as the argument to a higher order function. If we had partial
application, it would be easier to imagine. Because `map(increment)` has
the type `Array(Int) -> Array(Int)`, and that could show up in any "update"
function, and the "update" function would only understand that it was going
to perform an `a -> a` operation.

Perhaps it's worth thinking about partial application. We're already very
close to having it. If we can partially apply a function to arbitrary runtime
values, we end up needing to build closures, and we have to have a place to
store them, which is no fun. But we could be a little more clever about
this. Here are two approach.

* Partially applying a function to value arguments results in a second-class
  value. Such a closure cannot escape because it references the stack.
* Alternatively, partial application could require an allocation capability.
  The resulting closure is first class.

I like the second approach more because we could add a "stack region" thing
that lets us recover stack allocation.

So, what do we end up with. We need a big buffer that lets us feed in the
arguments one by one. What if we do this:

    struct func {
      void(*fn)(void*, void*);
      unsigned char* args; // Type args and value args, backwards
    }

Why backwards? The trick is that we start by allocating the total amount
of memory that will be needed for all of the arguments. Then, we bump the
pointer all the way to the end of the array. We can partially apply the
arguments one by one, decrementing the pointer as we apply. Once all of
the arguments are present, we will be back at the beginning of the array,
and we can feed it into the function.

There are some problems with this. This will not work correctly if a
closure is reused by being applied to different arguments. We would
end up with two different closures fighting over control of the same
buffer. This should have been evident from the way the allocation was
happening in the wrong place (not where the partial application was
actually happening). Gosh, partial application is a pain.

We could instead require that, every time that we apply to an additional
argument, we copy the environment. That's the right way to solve this.
But it requires keeping track of more stuff. We need to know how big
the args array currently is:

    struct func {
      void(*fn)(void*, void*);
      unsigned char* args; // Type args and value args, forwards
      size_t args_size; // Total number of bytes
    }

Now if we take a pointer to a top-level function, we start with `args=NULL` and
`args_size=0`, which does not require allocation. I wish that `struct func`
was smaller. I really wanted it to stay at 16 bytes or smaller. I could switch
to something where I chain them all together as a chunked linked list. And then
inside the actual implementation, we would begin by walking the list and
turning it into an array on the stack (the size would be known at compile
time). That's not a terrible implementation. And it keeps the struct small.
I think I might like this.

Also, this strategy works with effectful functions too. The extra context
for the effect needs to be passed *after* all of the value arguments.
