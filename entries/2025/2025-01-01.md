# Difficulties With RC and Polymorphism

It is difficult to treat unknown types uniformly when using RC. The difficulty
is that, when I store a 64-bit integer in an object, I don't need to mess with
a reference count. But when I store a 64-bit pointer into an object, I do.
What can we do to improve this?

One option is deferred RC. If we don't update the counters in real time,
we scan the stack instead to find the roots, but we have full type information
available. This strategy is sort of like having a GC nursery because
we get to ignore everything that is unreachable.

How much can we tighten the timeline? Normally, we wait until a bunch of
memory has been allocated and then we scan the stack all the way from the
roots. The ASAP paper (not intended for an RC setting) suggests more
narrowly tailored scans. I'm not going to consider the specific recommendations
of ASAP right now, but I'll think about a few possible cases:

* Consider a function that is "nonwasteful". That is, no heap objects go
  out of scope. In this scenario, we should wait to mess with RC updates until
  the functions returns. At this point, we can scan the (freshly allocated)
  object that is being returned and perform RC updates. Think about something
  like `replicate : Int -> a -> Array a` that creates an array where all
  elements are the same. This `replicate` is nonwasteful, so a function that
  calls it could be nonwasteful. If we shore up RCs at the end of the calling
  context, we might discover that the array's element type is something that
  doesn't require tracking a count.
* Consider linear mutable data. This can only go out of scope if it is
  either (a) explicitly dropped or (b) explicitly frozen. We can always wait
  to update RCs until one of thee final two actions is taken. So, if we have
  a mutable array and we are updating it in a loop, we never have to worry
  about RC updates during the loop.

This needs to be thought through more fully. Suppose we allocate something,
write it into a mutable array, and then replace it. Does the RC ever get
incremented (or decremented)? How do we determine that this memory is available
for reuse? Here's an option. At allocation time, the RC starts as zero. We
really don't want to track reference from the stack. When we write the object
into the array, the original reference to the object dies because it is no
longer used. But we cannot reclaim the memory because it is then referenced
by the array. As we continue to modify the array, this knowledge degrades to
"might be referenced by the array". Once we freeze the array, we scan it and
then update the RCs. At this moment, we can examine the counter for the
possibly dead object. We free the object if the counter is zero.

That is one particular scenario illustrating how I would like this to function.
I'm not sure if this works more generally though.

I thought about this idea more last night. If we pretend that there are
no recursive join points, then we get a pleasant result. All binders
(in an ANF language) that are bound to fresh allocations can be revisited
when a function exits. We can avoid messing with any reference counts until
the function returns. We cannot deallocate something that is returned. We
a function returns, we scan the returned value and update RCs. Then we
visit all binders and deallocate fresh objects that still have a zero RC.

Recursive join points complicate things. Whenever we jump to a recursive
join point, we need to treat this like we treat a return.
