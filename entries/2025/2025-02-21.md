# Where To Allocate Regions

I keep getting tripped up on this. I have a reasonably good solution, but
it's hard to start working on some of the built-in wrappers for syscalls
unless I know how memory allocation works. These wrappers are all hand-written
C code, so it's difficult to parameterize them. Here two different approaches
that I have considered that seem to work:

1. Regions are not actually contiguous. We carve up a block of 32GB into 4KB
   blocks, and each time a region runs out of space, it fetches a block from
   the list. Large allocations need to do something special (they require
   contiguous blocks). Some syscalls might benefit from doing something special
   as well. They could overallocate and then return the unused blocks to the
   global pool.
2. Regions are contiguous. Each region is its own 32GB of virtual address space.

Notice that, in either case, the 32GB restriction not a limitation of the
instruction set. It stems from a desire to make offsets representable with
32 bits instead of 64 bits, which cuts the size of all stored pointers in half.

Fully committing to strategy (1) lets us do some cool stuff. On x86-64, we could
resolve offsets to addresses with either of these strategies:

* Use segment register GS as the base (single instruction to compute address)
* Use RIP-relative addressing (requires two instructions to compute the address)

RIP-relative addressing makes the most sense if we want to be able to reuse
the same C code for ARM systems.

Here's a question: What does strategy 2 give us that strategy 1 does not?
I'm aware of two things:

* The whole program can use more than 32GB of memory
* Serializing regions is trivial

It's possible to work around the serialization deficiency of strategy 1. We
can just trace stuff and rebuilt it in contiguous memory. Tracing degrades
performance, but serializing raw objects is already an unusual thing to do,
and tracing makes it possible to repack the object in a more optimal way. 

But the memory thing might be a big deal. Some users really might need more
than 32GB across an entire program.

But there are some drawbacks to strategy 2, even when it works. How do we
reuse these regions after they go out of scope? When do they get unmapped?
What if we reuse one and it stays alive for a long time, but it does not
use nearly as many bytes we have backing the region? Again, do the pages
ever get unmapped? These difficulties are similar to the more general
"when to reclaim memory" difficulty that all automatic-memory-management
systems face, but here it's worse. When everything shares a global space,
the common solution is to just assume that we never need to return any
memory to the kernel. After all, some allocation will probably reuse the
page eventually. But with nonoverlapping regions, it is impossible to get
this same guarantee. In a program that runs long enough, it is likely
that every nonoverlapping region becomes maximally inflated. It is not
possible to guess how many bytes a region will require when it is first
allocated. Basically, what I'm trying to say is that there are some downsides
to this approach, and we lose some of the predictability that regions are
supposed to provide us.

If we give this up, the only way that an application could consume more
than 32GB of memory is by forking multiple processes. Each process has
its own virtual address space. We could use a read-only mmap to share
some of the memory between the processes.

An alternative is to just let the offsets be larger.
