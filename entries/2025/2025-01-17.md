# Reference Counting Without Deferral

As I've continued to think about this, I've realized that I do not want
to use any form of deferred RC. Here are the reasons:

* Deferred RC is more difficult to implement
* Any strategy that exploits the generational hypothesis (i.e. most objects
  die young) makes performance subject to unpredictable runtime settings.
  This includes allocating into a nursery. It also includes mutation-buffer
  strategies that coalesce increments and decrements to avoid updating the
  counter at all.
* Users have a better mechanism available for eliminating this overhead:
  regions. And their performance is extremely predictable.

# Trading Immidiacy for a Read-Only RC Optimization

There is one particular RC optimization that I find interesting, but I cannot
find it discussed anywhere. It requires trading away immidiacy. Consider this
function:

    sum : List Int -> Int
    sum(initial):
      // This is a recursively defined join point
      go(xs, acc): case xs:
        Nil -> acc
        Cons y ys -> go ys (acc + y)
      go(initial, 0)

Traditional RC needs to do some amount of fiddling with the counts in this
function. Why? Because `sum` might be the final use of this list. And so it
must be possible to free the memory as we are walking the list. It's a shame
that this is necessary. It would be much nicer to just walk the list and
ignore all of the counters.

If the argument list `initial` is guaranteed to not be the sole reference
to this list, then we can ignore all of the counting in the body of the
function. The only way to get this guarantee is to say that function arguments
are live until the end of the function. The decrement could be done in the
callee (i.e. `sum`) or in the caller. Doing this in the caller is preferable
because the caller might know that that the value it passed to the callee
stays live even longer.

I found an old version of the Python C API Manual that talks about this:

> It is not necessary to increment an object's reference count for every
> local variable that contains a pointer to an object. In theory, the object's
> reference count goes up by one when the variable is made to point to it and
> it goes down by one when the variable goes out of scope. However, these
> two cancel each other out, so at the end the reference count hasn't
> changed. The only real reason to use the reference count is to prevent
> the object from being deallocated as long as our variable is pointing to
> it. If we know that there is at least one other reference to the object
> that lives at least as long as our variable, there is no need to increment
> the reference count temporarily. An important situation where this arises
> is in objects that are passed as arguments to C functions in an extension
> module that are called from Python; the call mechanism guarantees to
> hold a reference to every argument for the duration of the call.

I've archived the entire file as `python-c-api-reference-counts.html`.
This analysis of Python's system helps me think about my system. Here
is what needs to happen (in any form of prompt RC):

* Every reference to an object counts, and it counts immidiately.
* When a function is called, it is necessary to increment the counts
  for each of the arguments.
* If an RC ever reaches zero, it suggests that an object can be
  deallocated immidiately. This means that we have to be careful
  about the order in which increments and decrements happen.

We can draw inspiration from Python docs and extend it somewhat:

* If the lifetime of a stack reference is dominated by any kind of
  reference to the same object, then the increment and decrement
  can be omitted. 
* If static analysis reveals that nothing locally reachable can alias
  a stack reference, the increment and decrement can be omitted. The
  easiest way for this to happen is if the object is allocated
  locally, and it doesn't get passed to any functions that could
  possibly return it embedded inside of another object (which can
  be determined just by looking at type signatures).

Let's think about the `sum` example again:
  
    sum : List Int -> Int
    sum(initial):
      go(xs, acc): case xs:
        Nil -> acc
        Cons -> go xs.tail (acc + xs.head)
      go(initial, 0)

Right when we enter the function body, which is the count assigned to
`initial`? Let's say that the caller is not allowed to decrement the
counts of final-use argument until after the function completes. In
the callee, this gives us a weird convention that the arguments, unlike
any of the other binders, do not need an increment or a decrement.
We can do this because their lifetimes are dominated by the calling
context. We know that all of these counters of any argument object
must be at least one. Let's analyze:

* Jumping to the join point with `go(initial, 0)` is a final use of
  `initial`, but `initial` is rebound to `xs`.

I need to think through how this interacts with join points better.
It's going to be easy to think about if they work the same way as
functions. So maybe the callee should have to perform the decrement
either before returning or jumping, because whenever we jump to
a join poin, we are going to have to make things accurate. Let's
try again:

* Entry to function: the count of `initial` is at least 2.
* Jumping to the join point with `go(initial, 0)`: No change
  to the count of `initial`. It should increment because
  `xs` is assigned to it, and it should decrement because
  it is a final use of the binder, so the counter is unchanged.
* Nil case: When we return `acc`, we decrement the counter
  for `xs`.
* Cons case: After projecting both fields from `xs`, we decrement
  the counter for `xs`. We increment the counter for the head
  of `xs`. Then we jump. The jump does not require changing the
  counter of `xs.head` further.

This is exactly what I was trying to avoid. At each step of the
loop we increment a counter, and then we decrement it mere clock
cycles later. It's difficult for static analysis to see this because
it happens across a join-point boundary.

This must be approached differently. Object-graph dominance is a useful
strategy. It's easy for static analysis to discover that `xs` is always
reachable from `initial`. This means that if we return to the "xs is live
for the entire body of the callee" plan, the increments and decrements
required for `xs` beginning and end may be omitted. So now we have:

* Entry to function: the count of `initial` is at least 1.
* Jumping to the join point with `go(initial, 0)`: No change. Even
  though `initial` is no longer used, it's lifetime is artificially
  extended. So its counter is not decremented. For an entirely different
  reason, we do not increment its counter. The increment is suppressed
  because static analysis has revealed that `xs` does not need increments
  or decrements at the edges of its lifetime.
* Nil case: Just returns acc. No changes to counters.
* Cons case: No changes to counters. The lifetime of `xs` is uncounted.
  The projection of `xs.tail` would cause an increment, but this is
  nullified by it going out of scope (and being assigned to `xs` for the
  next iteration). A different way of looking it is that `xs.tail` is
  dominated by `initial`, so when it is assigned to a binder, we do not
  perform an increment.

This works. The more general idea is this: identify dominance relationships,
both lifetime dominance and object-graph dominance. If A dominates B in both
ways, then B does not require that a counter be incremented or decremented.
By extending all binders' lifetimes to the end of their scope (including
function arguments, join point arguments, and ordinary binders), we increase
the number of situations where lifetime dominance occurs. This is particularly
helpful for function arguments because often the argument is used outside
of the function.

# On-Stack Allocations for Reference-Counted Objects

Here's another easy win. If an non-escaping object with a bounded size
is allocated in a function (not in a loop), we can initialize the RC to 1
like we normally would, but we would allocate it on the stack instead, and
when it died, we would not decrement the counter. It's not possible to
free it anyway. We just wait for the stack frame to be destroyed instead.

This strategy might overlap some with regions though and might not be
necessary.

# Horrible Range Operations on Arrays of Boxed Elements

I think that I have just come to accept that this will happen. It's ok.
This only happens when the array points outside of its region into
packed regions.
