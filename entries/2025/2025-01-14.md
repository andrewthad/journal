# Region Capabilities Without Linear Types

I had an idea. Instead of linearly consumed region capabilities, what
if every region was just reference counted. This means that there would
be no "delete" or "free" operation. When the reference count for a region
hits zero, the region is deallocated. This strategy has several advantages:

* Accesses are no oversequentialized.
* Existential packing of regions is trivial.
* It's possible to represent objects in an unknown region. This is a big
  deal, and I discuss it more below.

Performance should not be degraded generally. The only time that a region's
reference count is incremented is when the region is existentially packed.
In case where this never happens, no RC operations are performed.

One notable difference here is that the binder for the region is the
capability. For example:

    new      : Unit -> (r : Region, Handle r)
    allocate : (r : Region) -> Handle r -> Foo@r

Let's this about representing objects in an unknown region. First, let's
motivate this. Consider a function that reads from several boxed values
and constructs a result that aliases none of them. In Haskell:

    swizzle : Foo -> Bar -> Baz -> Bang

But with regions, we end up with something unpleasant:

    swizzle : (r, s, t, u : Region) -> Foo@r -> Bar@s -> Baz@t -> Bang@u

This is the kind of ergonomics problem that Rust's lifetime elision rules
improve. Let's see what we can do even without any tricks.

    swizzle : (u : Region) -> (∃r.Foo@r) -> (∃r.Bar@r) -> (∃r.Baz@r) -> Bang@u

And maybe the shorthand for this would be:

    swizzle : (u : Region) -> Foo -> Bar -> Baz -> Bang@u

Not bad. There is a slight problem though. When `swizzle` explicitly introduced
separate binders for each region, the RC elision was simple. Just don't mess
with anything because the calling context must hold references to these. But
with existentially quantificatied regions, `swizzle` might be responsible for
more. When we unpack, we have to increment the RC. But the unpack and the
"goes out of scope" will cancel neatly, so the increment and the decrement
should both be unneeded. But we must increment the count any time we copy
the packed value itself into a data structure. What I think we need to do is
to perform the unpack immidiately in the function body. Then the RC no-op
should be clear to the compiler. This is all still a little fuzzy to me, but
I think there are ways forward.

Something strange is that the system that I envision has handles and
capabilities backwards, representation wise, from where Linear Regions Are
All You Need has them. In the paper, capabilities have no representation at
runtime, but my region binders (which are vaguely like capabilities) act
as a base pointer to shrink pointers from 8 bytes down to 4. All of the
handle metadata can be stored at a known position at the beginning of
the region, so my handles (basically just an allocation capability) do not
need any representation at runtime.

A reasonable question to ask at this point is "why bother with handles?"
On one hand, I really like being able to specify whether or not a function
can allocate into a region. On the other hand, it's more noise. But maybe
it's not that much more noise. I need to keep thinking about it. It's not
a big change either way. I feel like handles should help with some kind of
static analysis or even with an optimization, but it might really just
be something for the programmer's benefit.

# Cool Things About Linear Mutation Capability

Linear mutation capabilities are even cooler than I originally thought that
they were. One neat thing is that some operations can operate across two
sequenced timelines:

    copy : MutableArray s1 a -> MutableArray s2 a -> Int -> Int -> Cap s1 -> Cap s2 -> (Cap s1, Cap s2)

This copies a range from a source array into a target array. The operations
performed on each array prior to the `copy` operation are only ordered
within their own sequencing timeline. The `copy` operation causes the two
timelines to briefly join, and then they are free to go their separate ways
again. As another example, consider interactions with the "real world":

    posixReadUntilFull : Fd -> MutableArray s U8 -> Cap s -> Cap World -> (Cap s, Cap World)

In GHC, we would need a `MutableByteArray RealWorld` as the argument. But in
the system I propose, the real world and timeline `s` only join up for a brief
moment. Let's see if it's possible to address another shortcoming of GHC's
approach: 

    posixWriteMutable : Fd -> MutableArray s U8 -> Cap s -> Cap World -> (Cap s, Cap World)

It should also be possible to write an immutable (frozen) array to this file
descriptor. Can we somehow wrap `posixWriteMutable` to make this possible?
As it is written, no, we cannot. The problem is that the function's type
signature communicates that it might modify the array. One solution is to
introduce a second capability, one that grants write permission to all mutable
objects in the sequenced timeline. For example:

    writeArray : MutableArray s a -> Int -> a -> Write s -> Cap s -> Cap s

The `Write` capability is not consumed linearly. Now, it is clear that
`posixWriteMutable` does not modify the argument array. We can introduce a
primitive that allows us to pretend that an immutable array is mutable:

    coerceArray : Array a -> (∃s. Cap s, MutableArray s a)

And now we can coerce an immutable array so that it may be given as an
argument to `posixWriteMutable`.

There is something deeply unsatisfying about this approach. We pretend that
an immutable object is mutable. But really, we should be doing the opposite.
In Rust, a borrow provides immutable access to a mutable value, which is the
opposite of what I have done above. Really, we want the more fundamental
operation to be:

    posixWriteImmutable : Fd -> Array U8 -> Cap World -> Cap World

And we should instead build `posixWriteMutable` on top of this. But how
can be borrow? Maybe something like this:

    borrow : MutableArray s a -> Cap s -> Cap r -> (Array a -> Cap r) -> (Cap s, Cap r)

This works but only because I hardcoded the result to be a capability,
preventing the array from escaping. This is, however, not in ANF. So it's
flawed in at least two ways.

I still need a better answer to this problem. The `Write` capability is not
a good plan, but neither is the `borrow` primitive. I need a way to freeze
something temporarily and then bring it back. The difficulty is that we have
to stop the immutable (borrowed) array from being used after the temporary
freeze ends. Maybe this:

    begin : MutableArray s a -> Cap s -> (x : Array a, Restore x s)
    end   : (x : Array a) -> Restore x s -> Cap s

No good. The immutable array can be used after calling `end`, which defeats
the purpose.

Let's take a step back. If immutable arrays did not exist, how would we
communicate immutability? We could have a `Write` capability and an opposite
capability that meant that it was impossible to write to any of the values.
Consider this approach:

    Write     : State -> Type // always consumed linearly
    Antiwrite : State -> Type // always consumed linearly
    new     : ∃s. Write s
    freeze  : Write s -> Antiwrite s // permanently freeze
    restore : Restoration s -> Antiwrite s -> Write s
    borrow  : Write s -> (Antiwrite s, Restoration s)

The idea is that we can temporarily drop our write privileges and then pass
the `Antiwrite` to a function that only needs to read. Actually, I think
this might make more sense:

    Write : Token -> SeqType
    Read  : Token -> SeqType
    new   : ∃s. Write s
    readArray  : forall (f :: Token -> SeqType). MutableArray s -> Int -> f s {1} -> (a, f s {1})
    writeArray : MutableArray s a -> Int -> a -> Write s {1} -> Write s {1}

A read-only context doesn't actually accept a read capability. It accepts a
polymorphic capability. This makes it possible for a function to communicate
that it cannot write to its mutable argument:

    posixWrite : Fd -> MutableArray s U8 -> f s -> Cap World -> (f s, Cap World)

This is similar to having a separate write capability except that we've
squeezed it all into one capability into of breaking it into two of them.
Oh, I can see how immutable values could be built:

    freeze  : Foo s -> Write s {1} -> (∃t. Foo t, Read t)
    discard : Read s {1} -> Unit

Notice that this `Read` capability does not require linear consumption. We can
feed it into something like `readArray` and then discard the token that we get
as the result. As a shorthand, let's say:

    type Array a = (∃s. MutableArray s a, Read s)

I'm getting closer, but this still doesn't give everything that I want. We
are able to reuse `posixWrite`, but it still takes a mutable array and a
bogus `f s` argument. This becomes a bigger problem for functions that take
multiple immutable arrays as arguments.

Thinking about this more, I see that it will be impossible to implement
fully general borrowing on top of the system I am designing. The problem is
that I need to ensure that all reads complete before the borrow ends, but
all my reads are unsequenced, so it's not possible.

An even more critical problem is that recursively defined mutable data
structures cannot be safely borrowed. If we can borrow, we can extract
a field, store it in an object, and have it outlive the borrow. Even
a syntactic borrow that takes a program block as an argument suffers from
this deficiency.

The two options I have are:

1. Just give up on borrowing entirely. Add mutable/immutable variants of
   several common functions.
2. Make everything accept a mutable array instead of an immutable array
   and do something to make it so that we can only read from the array.

I prefer option 1. For many data structures, we don't really need to borrow
anyways. Even with arrays, it's more common to just freeze the array and be
done with modifications. I've worked on applications where there were
exceptions to this rule, but generally, it holds. Especially with textual
data.
