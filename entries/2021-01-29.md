# User-Powered Vectorization

Matt Pharr comments on auto-vectorization:

> I think that the fatal flaw with the approach the compiler team was
> trying to make work was best diagnosed by Tim Foley, who's full of great
> insights about this stuff: auto-vectorization is not a programming model.
> 
> The problem with an auto-vectorizer is that as long as vectorization can
> fail (and it will), then if you're a programmer who actually cares about
> what code the compiler generates for your program, you must come to deeply
> understand the auto-vectorizer. Then, when it fails to vectorize code you
> want to be vectorized, you can either poke it in the right ways or change
> your program in the right ways so that it works for you again. This is
> a horrible way to program; it's all alchemy and guesswork and you need
> to become deeply specialized about the nuances of a single compiler's
> implementation - something you wouldn't otherwise need to care about
> one bit.

Matt went on to write Intel's ISPC. ISPC puts the user in control of when
vectorization happens. To do this, it must introduce restrictions. From
the [manual](https://ispc.github.io/ispc.html):

> It is illegal to have a `break` statement or a `return` statement within a
> `foreach` loop; a compile-time error will be issued in this case.

This makes sense given that the order in which the elements are processed
is considered implementation-defined. The manual says:

> In general, however, you shouldn't make any assumptions about the order in
> which elements of the iteration domain will be processed by a `foreach` loop.
> For example, the following code exhibits undefined behavior ...

What then, can a `foreach` do? Two uses that I like to think about are:

1. A commutative operation on an accumulator. Addition, multiplication, etc.
2. Writing to the matching slot in a destination array.

To be clear, there are other things that you can do in a `foreach`. These two
are just the ones that I like to focus on because I think it might be possible
to carry them over to a functional programming language. Writes to a destination
array are kind of tricky although restricting the user to a `map` operator is
possible.

I was playing with an idea for a trie recently, and I wrote some code that looked
like this: 

    typedef struct Node_t {
      uint32_t tetragrams[8];
      uint8_t lens[8];
    } Node;
    // Find the one match.
    for(int i = 0; i < 8; i++) {
      if((node->tetragrams[i] == gram) && (node->lens[i] == truncatedRemaining)) {
        return i;
      }
    }

I also wrote a manually-vectorized version of the code that is difficult to
understand. Basically, all that I am trying to accomplish is finding the
first element where both a 32-bit tetragram and an 8-bit length match. This
program uses a `return` to break out of a loop, something that doesn't
make sense in an unspecified-iteration-order `foreach`. But this can be
rewritten to avoid the need to break out early (pseudocode follows):

    // Types:
    // countLeadingZeros : Vec 8 Bool -> Int
    // (==.) : Vec n Word32 -> Word32 -> Vec n Bool
    // (==.) : Vec n Word8  -> Word8  -> Vec n Bool
    let matches : Vec 8 Bool =
          foreach tetragram <- node.tetragrams, len <- node.lens:
            (tetragram ==. gram) &&. (len ==. truncatedRemaining)
     in 8 - countLeadingZeros(matches)

When targetting AVX512, it should be possible to produce extremely efficient
code from this. What about lesser targets though? What about WASM and
OpenRISC? Well, we're going to end up building this weird bitmask that we
don't need and then getting the first set bit from it. The new code, while
more friendly for some targets, is less friendly to others. Why? We've thrown
away a useful piece of information, which is that we only care about the first
result. To a human, the way `countLeadingZeros` is used makes this clear, but
a computer would have a more difficult time understanding this. What if we
allowed what ISPC doesn't. What if we allowed breaking out of a loop? In the
absence of effects, this is not so bad. We only have to keep in mind that we
probably do not want there to be multiple matches since the match chosen will
be nondeterministic. Consider:

    let matchedIx : Int =
          foreach ix <- 0 ... 8, tetragram <- node.tetragrams, len <- node.lens:
            if (tetragram ==. gram) &&. (len ==. truncatedRemaining):
              break_with(ix);

This forces another question: what to do when nothing matches? One option
is to say that it's undefined behavior, that `matchedIx` could be anything.
That might sometimes be useful, but it is not useful in this situation.
The `foreach` could have a default:

    joinpoint followIndex(i : Int) = ...
    joinpoint notFound = ...
    foreach ix <- 0 ... 8, tetragram <- node.tetragrams, len <- node.lens:
      if (tetragram ==. gram) &&. (len ==. truncatedRemaining):
        jump followIndex(ix);
    default: jump notFound

This is getting closer to something that actually makes sense. Now, it is
abundantly clear what should happen when nothing matches. This is very similar
to the original C code, but the iteration order is now undefined. For simple
targets, it is possible to recover the original lowering of the C function.
For more complicated targets, while lowering the code to assembly, it should
be possible for the compiler to see that:

* Number of iterations is fixed. It's a multiple of two, and it is small
  enough that all elements can be processed in one pass. No real loop is
  needed.
* Conjunction is amenable to vectorization.
* Equality tests are amenable to vectorization.
* A single-cycle `foreach`-`jump` can be handled by testing the mask against
  zero (to see if there was any match), and if no match, then jump to default.
  Otherwise, CLZ to compute matching index and jump to `followIndex`.

It's worth considering how this could have been different. What if it was not
8 entries but 128. This means that we would need a loop in the generated
assembly. I don't think the assembly would be a whole lot different other than
that detail. On every iteration, you would check to see if the mask register
was zero, and CLZ and jump as before if needed.

Another variant is multiple exit points:

    foreach ix <- 0 ... 128, tetragram <- node.tetragrams, len <- node.lens:
      if (tetragram ==. gram)
        jump followIndex(ix);
      else if (len ==. truncatedRemaining)
        jump followIndex(ix);

Again, this doesn't seem bad. Rather than taking the conjunction of two
predicates up front, you have to do one, check for zero, possibly CTZ and
jump, do the other, check for zero, possibly CTZ and jump. Not difficult.
It is a rather "horizontal" use of SIMD, but horizontal operations on masks
look inexpensive. Also, on AVX512, this should be able to process 16 elements
at a time.

So jumping out of a `foreach` seems possible and useful as long as there are
not arbitrary effects going on in there. Maybe I should focus on my three
primary use-cases for built-in vectorization being:

1. Jumping out of `foreach` with undetermined order
2. Mapping to one or more target vectors (writes not explicit)
3. Commutative monoidal accumulators

Examples of 1 have already been shown. An example of 2 is:

    let twiceNumbers =
          map ix <- INDEX, n <- myNumbers:
            n * n + ix
     in ...

This construct could be combined with any abort-style effect, with the meaning
being that the (mutable, not yet frozen) array being built would be thrown
away. And 3 is exemplified by:

    let result : Int =
          foreach acc : Monoid{Int,Addition}, ix <- INDEX, n <- myNumbers:
            ix * n
     in ...

Above, the accumulation step (adding each result onto the accumulator) and the
final reduction step (horizontal add) are implicit. Here's another example of
this:

    let bigNumberCount : Int =
          foreach acc : Monoid{Int,Addition}, n <- myNumbers:
            if n >=. 1000
              then 0
              else 1
     in ...

In theory, it should be possible to do this for accumulators other than numbers
that are added up. Multiplication is possible and easy, but no one ever seems
to actually need to do that. Having multiple accumulators is possible and is a
good idea. (This would, for example, let you compute counts for multiple
predicates at the same time.)

Everything I care about is covered by these three. Clearly, ISPC's target audience
cares about other stuff. They've got things like `foreach_unique` and
`foreach_active`.
