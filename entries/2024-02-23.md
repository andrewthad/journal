# Reflections on Stack Allocation System

On 2024-02-22, I explored region types more deeply. I have convinced
myself (for at least the second time) that the user-facing ergonomics of regions
are unacceptable. Regions give users, especially library authors, too many
choices, and the types are difficult to understand.

On 2024-02-21, I explored a system that lets users control when certain
data is allocated on the stack. The type system was too complicated, but
there were some promising elements. The good:

* The frame that a stack-allocated objects lives in is syntactically implied
  even when recursive join points are present.
* A higher-level system that does not give users that ability to allocate
  on the stack can be lowered to the system I described. Optimization
  passes can reliably transform non-escaping heap allocations to
  stack allocations, even when the objects are passed to functions.
* Breaking field types and expression types apart is useful.

The bad:

* Ordered frames are complicated.
* The types of the ordered-map functions `union`, `lookup`, and `insert`
  were too complicated.

Other insights that drive simplifications:

* One important use case is syscalls. Many of these involve allocating
  a small, statically bounded number of structs on the stack, passing
  a pointer to the syscall, and then letting all of the structs
  go out of scope.
* Stack allocation of byte arrays is an important and common case.
* The ability to allocate ordered maps on the stack is not important in
  practice.

# Simplified Stack Allocation System

Every expression has a type that consists of a "base type" (no stack-vs-heap
distinction) and a region annotation. This is not the way the word region
is used when describing region types. It is much more simple:

    Region = Heap | Stack
    T Heap <: T Stack

Given an arbitrary expression of type `Foo Stack`, we do not actually know
that it lives on the stack. We only know that it might. This is possible
because an automatic memory management system that allocates into an arena
does not treat stack-allocated values and heap-allocated values any differently
when they go out of scope.

Here is what several functions that operate on ordered maps look like:

    member : Function(Map@S, Key@S)(Bool)
    union  : Function(Map@H, Map@H)(Map@H)
    lookup : Function(Map@H, Key@S)(Value@H)
    insert : Function(Map@H, Key@H, Value@H)(Map@H)

Functions can return objects that might live in stack frames, but they can
only do this when the object was an argument. Inside of each function,
all stack-allocated values have levels associated with them. Arguments
have level 0. Anything stack allocated has level 1 at the top level of
a function has level 1. When you enter a recursively bound group of
join points, the level increments by 1. When jumping to a join point,
you cannot pass a stack-allocated argument whose frame annotation is
greater than or equal to the level at which the join point was declared.

    function(a : Array U8 @ S, b : Array U8 @ S)(Bool)
    { // Arguments a and b at level 0
      x = allocate H { ... } 
    ; y = allocate S { ... } // y at level 1
    ; z = call foo(x,y,a)
    ; label finalize(r : Foo @ S) // Jumps to finalize may use stack levels 0 and 1  
      { // in here, allocations are at level 1
      }
    ; rec
      { label bip(k : Foo @ S) // Jumps to bip may use stack levels 0 and 1
        { // in here, stack allocations are at level 2
        } 
      , label bop(j : Foo @ S) // Jumps to bop may use stack levels 0 and 1
        { // in here, stack allocations are at: level 2
        } 
      }
    ; jump bop(y)
    }

We want to make sure `bip` and `bop` do not allocate on the stack and build
up an object of unbounded size by calling each other. I've always thought
about preventing this problem with levels. Levels are complicated, and they
do not even work particularly well. For example, if we introduced another
group of recursively bound join points, we would like for a join poin in
this later group to jump back into the first group, potentially even with
something that it allocated. But it's hard to see how this is compatible
with levels.

What is it that we are really trying to prevent? If a recursively bound
join point allocates on the stack, it cannot pass this object when jumping
to a neighbor. What if we abandon this rule? Both x86 and ARM have conventions
in place (including dedicated registers for SP and FP) that support growing the
stack in the middle of a function. What if we just decremented the stack
pointer (growing the stack) every time the programmer allocated an object
on the stack. This simplifies everything tremendously. All of the stack
space needed for spilling registers still has to be allocated up front
because all of those addresses have to be relative to the FP.

Also, functions should just not be allowed to return anything that might live
on the stack. This means that we cannot use `bool` and `id` on stack variables,
but I do not believe this is important.

What about arrays? If we index into a stack-allocated array of objects, we
do not know if the element lives on the stack or the heap. We must assume
that it might be on the stack. This result is not great, but I think the
loss of expressiveness is not too bad. Here is an example:

    // Assume that the person type has an integral ID field
    makeMap : Function(Array Person @ H)(Map Person @ H)

In theory, we ought to be able to accept stack-allocated arrays, but we cannot
because the annotation is pushed onto the element type as well. I think I am
willing to accept this shortcoming.

One thing worth mentioning about this strategy is that, when compiling,
we have to be able to detect when a recursive join point discards all of
its allocations. In that case, we need to increment the stack pointer and
reclaim that space. If we do not do this, then recursive join points that
allocate on the stack will leak stack space. More generally, we should
reclaim stack space as soon as it becomes possible to do so since this
improves memory locality. 

One last thing. It is still necessary to have two different constructed
types. We end up with:

* Boxed: immutable/mutable, constructed by writing fields one by one.
  Typically allocated on the heap but might be allocated on the stack.
* Unboxed: mutability inferred from fields, constructed by simultaneously
  assigning all fields, scrunity can only happen once. Certainly allocated
  on the stack.

Unboxed is always stack allocated. But it serves a different purpose from
boxed types. Unboxed types cannot be self recursive, but they can have
mutable fields. This is particularly important for Option/Result and also
for a WithStateToken type that is used when desugaring IO.

Hmmm... If our calling convention places return values on the stack, then what
if we required all functions to return an unboxed struct? This would mean that
the caller must always reserve space for the result at the bottom of its stack,
and then the callee could figure out where to write the result based on the
frame pointer. For example:

    unboxed constructed WrapInt { value : Int }
    foo : Function(...)(WrapInt)
    bar() = do
      ...
      x : WrapInt = foo(...)
      y : Int = x.value
      z : Int = foo(...).value

Does that actually simplify anything or not? The simplification is:

* The caller always does the same thing no matter what the callee's
  return type is.
* The types accurately reflect what is happening.

The drawback is that, somewhere, we are going to have to have a transformation
that turns functions returning Int into functions returning WrapInt. I do not
think that is a big deal though.

In fact, I think it makes sense to go one step further and transform function
arguments in the same way:

    Function(x : Int, y : Int)(Int)
    Function(unboxed constructed {x : Int, y : Int})(unboxed constructed {value : Int})
    // or more concisely, since only onboxed constructed types are allowed
    Function{x : Int, y : Int}{value : Int}

I like this system. I'm not sure at what stage a transformation like this
should be performed though.

I dislike the way that there are several constructs (heap-allocated types,
stack-allocated types) doing similar things.

One problem we run into if we try to perform the "do everything with stack
objects" strategy with our earlier stack-allocation scheme is that it doesn't
work well:

    Function(constructed {x : Int, y : Int} @ S, mutable constructed {value : Int} @ S)(constructed {value : Int} @ S)

Problems:

1. The function now accepts a pointer to object containing the original fields.
   Before, the frame pointer pointed directly to the object. So there is an
   extra indirection.
2. Returning a stack-allocated value is not allowed.
3. It is less clear what is happening. We have to write the return type twice.

Let's try something else. Let's say that constructed types can have mutable
fields, but the special "recurse" type always becomes the immutable variant
of the type. Now, whether or not a value of a constructed type can be freely
aliased depends on whether or not it has any mutable fields. Next, we have
to try to incorporate the ability to stack allocate into this. As before, we
may annotate any constructed type as being on the stack or on the heap, but
it is usually only an approximation. However, when we write:

    foo = function(args : {x : Int, y : Int})(retBuf0 : {value : Int})
      { ... // retBuf0 : mutable constructed {value : Int} @ S
      ; retBuf1 = write retBuf0 value 42
      ; freeze(retBuf1)
      }

It is not an approximation for the return type. It is precise. This still does
not work because we could just allocate a different return buffer and return
it. We need a special magic "return buffer" designation for where an object
lives. That's too complicated. An alternative is to just perform a memcpy at
the end. And an optimization pass at a lower level could probably remove that
in most cases.

Where does this leave us? Cleaning up the example from earlier, we arrive at:

    construction WrapInt { value : Int }
    foo : Function(...)(WrapInt)
    bar() = do
      ...
      x : WrapInt@S = call foo(...)
      y : Int = x.value
      z : Int = foo(...).value

We no longer have the boxed/unboxed distinction, which is good. Calling a
function implicitly allocates a structure on the stack for the return
value. That is disappointing, but I do not think it can be avoided.

Have S be a mere approximation feels weird because we are certain that
`x` lives on the stack. It doesn't seem like it is important for the
compiler to know this though. I cannot think of anywhere that this
acutally helps. Even when we are thinking about the arguments of `foo`,
the object could actually be heap allocated. It really doesn't matter.
It would be nice if we could get it to use the frame pointer, but it is
difficult to make sure the argument object is always at the bottom
of the stack. We could have Stack, Heap, and Any and do the subtyping
a little differently, but I cannot see what that buys us.

This all worked better when "unboxed constructed" was a separate construct.
In particular, it includes a feature that the object is not allocated
prior to its use. This is exactly what we need in order to be sure that,
in the callee, the frame pointer refers to the argument object.

What if we just do the memcpy for both the arguments and the result?
That solves the problem. And again, an low-level optimization pass should
be able to fix it most of the time.

I am starting to think there is real value in distinguishing between
Stack, Heap, and Any. For example:

* `IntList @Any`: Head could be on stack. The whole thing might be on the
  stack, but once we reach a cons cell on the heap, the rest of it is
  definitely on the heap.
* `IntList @Stack`: The whole thing is certainly on the stack
* `IntList @Heap`: The whole thing is certainly on the heap

The precise type for stack-allocated objects helps the user more than
it helps the compiler. In theory, it can be used instruct the compiler
that it does not need to scan an on-stack object, but large on-stack
structures (with many pointers into the stack) should be rare. But
for the human in the loop, it is nice to have a type that makes it
clear that an object was not allocated on the heap.

One final example of the resulting system:

    // Note: token is treated as mutable and has no representation
    posixReadAndShrink : Function
      {buffer : mutable Array U8 @Any, token : Token}
      {buffer : immutable Array U8 @Any, token : Token}
    posixWrite : Function
      {buffer : immutable Array U8 @Any, token : Token}
      {token : Token}
    echo = function(args : {value : Token})({value : Token})
      { t0 = args.value
      ; buffer0 = allocate.Array Stack 4096 (u8 0)
      ; readArgs0 = allocate.Object Stack ... // type description
      ; readArgs1 = write readArgs0 token t0
      ; readArgs2 = write readArgs1 buffer buffer0
      ; readArgs = freeze(readArgs2)
      ; readResult = posixReadAndShrink(readArgs)
      ; buffer1 = readResult.buffer // this was frozen and shrunk by the syscall wrapper
      ; t1 = readResult.token
      ; writeArgs0 = allocate.Object Stack ... // type description
      ; writeArgs1 = write writeArgs0 token t1
      ; writeArgs2 = write writeArgs1 buffer buffer1
      ; writeArgs = freeze(writeArgs2)
      ; writeResult = posixWrite(writeArgs)
      ; writeResult.token
      }

Notes from this exercise:

* The type of `posixReadAndShrink` is odd.
