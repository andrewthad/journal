# Moving and Nonmoving Collectors

The folklore is that copying collectors should outperform nonmoving collectors
for two reasons:

1. Bump allocation is cache coherent.
2. Defragmentation is built in.

However, the results in
[An Efficient Non-Moving Garbage Collector for Functional Languages](https://www.pllab.riec.tohoku.ac.jp/papers/icfp2011UenoOhoriOtomoAuthorVersion.pdf)
paint a different picture. As another data point, golang uses a nonmoving
collector, and that seems to have worked out well for it. There are also
things like [MESH](https://arxiv.org/pdf/1902.04738.pdf) that can defrag
while preserving addresses by playing with virtual memory. My point here
is not to say that one type of collection is better or worse than another,
only to say that there is more nuance than what the folklore suggests.

What I actually wanted to think about today was the intersection between
nonmoving GC and immutable (no old-points-to-new) data. With a copying
collector, here are some cool tricks:

* Minor GC uses the stack as roots. Pointers to old gen are ignored. (generational)
* Rollback discussed on 2020-06-25.

Nonmoving collection is amenable to generational collection. However,
rolling back allocations seems difficult or impossible. The only way
rollbacks can work is if nursery allocations are not mixed with old
data. So, maybe something like a rollback should be possible, but it
might be a little more expensive. The idea is that you could save all
the bitmaps (assuming Ueno's nonmoving collector) that tell you what
is and isn't live, and then you could restore them after performing
some action. The restore would only be valid if you hadn't GCed, which
is the space limitation that the copying collector would have. The
big difference here is that saving all those bitmaps is kind of
expensive. Assuming 16-byte objects, a 512KB heap needs 32K bits,
4KB of bitmap data. That's a big copy that might all be for naught.
But, it could also be a big win since correct placement might
eliminate nearly all minor collections. A different option here would
be to arrange for a bunch of empty blocks to be on the block list,
and then the bitmasks could just all be zeroed after running
some routine. It would be hard to get those empty blocks available
though. Rollback might just have to be abandoned.

Also, just to go back over this, what are the real problems with
old-points-to-new schemes. There are several problems I am aware of:

1. Remembered sets are required. Or all mutable variables are considered
   part of the nursery. Same idea.
2. Rollback becomes impossible
3. Concurrency: Minor GC sync when nurseries can point to each other

Issue 3 isn't really a problem if you prohibit mutable variables from
being shared across threads. Issue 2 is always a problem. Issue 1 is
not a huge problem because remembered sets should be small. If you
have millions of live mutable variables, you are hosed in any GCed
language.

Thinking about this a little more, nonmoving GC makes possible a certain
kind of rollback that copying GC cannot do. Suppose that you parse
data and then perform a series of transformations on different syntax trees.
The resulting allocations, marked for retention, might look like this:

    00000000000000000000000000000000111111111111

That is, everything retained will be at the end. Or maybe instead, we
might have:

    00000100000100000000000000000000111111111111

Similar, but some of the data (possibly strings) allocated as part of
some IR is shared. Since we are in the lucky position of being certain
that a lot of allocated data is unneeded, we can perform an ultra-minor
GC here that only traces the final value. We couldn't do this with a
copying collector because a copying collector does not allow things
to be allocated in the middle of the heap.

Mutable references can still really mess up rollback badly. The remedy
I am aware of is to only allow rollback for pure functions. You cannot
perform mutation in a pure function, so this guarantees soundness.

What about large mutable tree-like objects? This is a little trickier.
We want to be able to stop scanning when we encounter one of these.
These need to mark the bitmap in some way when they are allocated.
When the bitmap is zeroed before checking for reachability, we can
set everything mutable as able to be reached. Of course, at some
point, mutable objects get frozen (or discarded). That'll be tricky
to deal with. It is possible to just keep mutable things in separate
segments instead and then freeze the whole segment when you're done
with mutation. But that's basically just a bump allocator that's
less cache coherent. The idea of using the same segment as everything
else is appealing. It's just hard to do this in a way that is not
extremely costly.

Maybe it's better to just start looking at it differently. What is the
real goal here? If we have a large mutable map, we would like to be able
to avoid it negatively impacting GC times. That's the primary goal. We
could have C-style user-controlled allocate and free functions. But
what if the whole data structure goes out of scope? And what about
freezing? It would be nice if freezing wasn't a deep operation. How do you
go from "don't scan these" to "scan these please" with the flip of
a single bit? Additionally, how can we keep something live without
scanning it? Those are the important questions. The second question
is answered by "allocate it in a special place", which is somewhat
unsatisfying. The same question could also be answered by "track all
such allocations in a bitmap". Expensive.

Alright, here's a thought. This is just to solve the issue of large
mutable data structures. What if all `ST`-like regions (remember,
these can be nested, and about as deeply as the stack be) share
a tracker where you can push allocation information? Let's say I'm
in `ST` region number 42 and I allocate something. The allocation
proceeds just like allocating any ordinary value, but then I push
the allocated address (or maybe the index into a bitmap) onto the
tracker as `(42,0xABCD6354)` (it might be necessary to push the size
of the allocation as well). Such a tracker would support tracking
deallocations as well. Fortunately, the tracker cannot grow larger
than some constant factor of the nursery's size before a minor GC.
Then, on minor GC, we could roll up all of the information in the
tracker into updates on per-region per-size-class bitmasks. Deferring
this saves a ton of space because most regions will not use many size
classes.  The unused size classes are "compressed" by just not including
them. (Perhaps this whole thing could use roaring bitsets.) Then, we can
union all bitsets for the same size class to compute a base
bitset of things that are treated as live. If we encounter one of the
objects while scanning the heap, we simply don't follow it because
everything it points to has certainly already been marked as live.
Perfect! This is not quite right in a generational setting, but it
can be made to work there as well. You just need another (larger) bitset
for the old generation, and then you can similarly avoid scanning
large mutable data structure in the old generation. However, I am
not exactly sure how deallocation fits in with the old generation.
You might have to just apply those to the old generation's bit sets
during every minor GC. What is the cost of all of this? Building
bitsets from the tracker is certainly work, but I suspect that
it would be inexpensive. That's just a guess though. It is definitely
a bounded amount of work except in the case of a massive amount
of old-generation deallocations. Perhaps deallocation should be forbidden
for this reason. Nah. I really like the ability to deallocate like this.
Perhaps deallocations involving the old generation could just be
performed directly on the old generation's bitset. This makes
the deallocations a little more costly, but then the size of the
tracker becomes bounded.

Also, I figured out how to get GCC to emit `tzcntq` and `lzcntq`
instructions. It is with:

    __builtin_ia32_lzcnt_u64(arg1);
    __tzcnt_u64(arg1);

For some reason, the naming is not consistent.
