# Unique Data and Let Bindings

Just a few thoughts about linear data before getting the let-binding part.
Uniqueness types (related to linear types) are a decent abstraction for
several types of mutation. The classic example people go to is arrays of
unrestricted elements, but here I want to focus on key-value maps of
unrestricted elements. For example:

    insert : k -> v -> Map* k v -> Map* k v
    delete : k -> Map* k v -> Map* k v

Cool. This is fine, but there's a problem. If we are trying to use B Trees
or any kind of map with high-fan-out nodes, we cannot implement the maps
on top on any lower-level primitives. Why? Because unique arrays of unique
values do not work. Even functions like swap and insert-at-index have to be
built in as primitives.

The thought here was to just bite the bullet and say that, internally, the
key-value map might just not get to be implemented on top of linear primitives.
Internally, we could just do:

    insert : k -> v -> Map k v -> IO (Map k v)

And `Map` has to be some kind of reference type that has a notion of identity,
and the implementor of `insert` is responsible for freeing memory, but that's
all fine.

Now back to the title: Let Bindings. I've always found linear and unique data
troubling because of constructions like this:

    foo : Int -> Bool
    foo y =
      let x = mkEmptyMap () // creates a linear value
       in ...

In a total language, you should be able to float let bindings up, all the
way up to the top level if the RHS doesn't depend on any of the arguments
to the function. But if the RHS has a linear type, then you are in a weird
position. If it was something like this:

    ... assume that b is in scope
    let a = Map.insert 42 "secret" b

Then floating this up is totally fine. It cannot get any higher up than b,
so we're all good. But the functions for creating the value that you are
going to start with are troubling. You could do some weird CPS thing, but
no one wants that. What about just introducing a language-level construct
that roughly means "allocate a new linear value". This can float up
or down, but it cannot float past a closing context (a function declaration).
So, we have something like this instead:

    foo : Int -> Bool
    foo y =
      alloc x = mkEmptyMap
         in ...

You have to do something in the type or kind system (or maybe splitting the
environment) to make sure that the RHS of `alloc` is something that isn't
an ordinary value. The RHS has to be something that allocates and initializes
memory for linear use. From that point on, with maps at least, the user
probably wouldn't need to touch `alloc` again. It's just needed to seed
things, to get that first value that you then start modifying with `insert`.
You could do two `alloc`s and then merge the maps with a map-union operation.
Heck, you could even `alloc` multiple maps, build them in parallel, and then
merge them on the main thread after all the workers joined.

There needs to be a `free` routine for each linear type the releases
(possibly recursively) memory. Calls to it would be inserted by the
compiler, probably when compiling to a GRIN-like IR. So the compiler
would need to be able to count uses of a arguments even if this information
was not part of the type system.

One thing worth mentioning. Inlining suffers as a result of doing this.
Wrapping an impure core with uniqueness types is essentially building
your own primops. You cannot inline the primops until you get down to
a lower-level IR where allocation order is pinned. Anything comparable
to GRIN (from the GRIN project) would be an ok place to inline.

Last thought is about how to actually perform the allocations. This is
tricky. One really important question is "do we want to support freezing?"
If we do want to support freezing, then everything needs to be allocated
with space for the forwarding pointing needed for GC. For some things (maps),
freezing is important. For other things (union-find), freezing makes no
sense at all. Well, and also, if you point to anything unrestricted, then
the GC is going to need a way to look at that. So probably, unconditionally
setting things up so that the GC can look into them is a good idea. Although
if you knew that certain kinds of data only pointed to linear data, then
you could basically stop following them.

Certainly, mutable data should not be relocated. The difficult question is
how to go about allocation and reclaiming space when data is freed. If
you are just building something (never releasing memory), then you want
bump allocation. If you are modifying something aggresively, you would really
like to be able to give chunks of memory back. But then if you use them, you
won't be doing bump allocation anymore. There are other options though.
Calls to a `free()` function could just mark a table to communicate that
a certain part of a chunk of memory isn't being used anymore. If one bit
corresponds to eight bytes, then 4KB could be covered by 512 bits (64 bytes).
Then during some GC-like step, you could check entire pages to see if
they were empty and reclaim them. That strategy has some terrible worst-case
behavior, but maybe [MESH](https://arxiv.org/pdf/1902.04738.pdf) could help
out here. So maybe you could get bump allocation without fragmenting the
heap. Reclaimation of memory might not be prompt though. That is, if
something recently allocated is freed, it might not be in L1 by the time
you get a chance to use it. But that's ok. I think the other perf
characteristics of this are worth that trade, esp. since the common case
of not deleting data will be really fast.
