# Learning About x86 Calling Conventions

Example C code:

    #include <stdint.h>                            
            
    struct foo {
      uint64_t w;
      uint64_t x;   
      uint64_t y;
      uint64_t z;   
    };      
            
    uint64_t consumeFoo(struct foo a) {            
        return a.x + a.z + a.w;                    
    }       

I put the arguments in a struct to force GCC to pass them on the stack.
Compile with

    gcc -masm=intel -fno-stack-protector -O2 -S -fno-omit-frame-pointer -c structarg.c

To get this assembly (cleaned up a little):

    consumeFoo:
    .LFB0:
      endbr64
      push    rbp
      mov     rbp, rsp
      // Breakpoint A
      mov     rax, QWORD PTR 40[rbp]
      add     rax, QWORD PTR 24[rbp]
      add     rax, QWORD PTR 16[rbp]
      pop     rbp // restore old frame pointer
      ret

Because I set `-fno-omit-frame-pointer`, the frame pointer gets used.
At breakpoint A, this is what the stack looks like:

    +-------------+
    |      ?      |                0x200
    |     a.z     |                0x1F8
    |     a.y     |                0x1F0
    |     a.x     |                0x1E8
    |     a.w     |                0x1E0
    | return addr |                0x1D8
    |     FP'     | <- FP, SP      0x1D0
    |   red zone  |
    +-------------+

I tripped myself up on interpretting this for a while. Struct field layout
"grows up" (the first field is at the lowest address), but the x86 stack
"grows down". The struct looks backwards in this presentation, but this is
just down the stack is usually drawn in diagrams.

Anyway, I tried this out because I wanted to see if it was possible to
pass a struct argument to a C function to get a simple and predictable
calling convention. It looks like it is possible.

I need to think more about how to get a return value on the stack instead of
in `rax`. I think this should be possible, and I probably just need to pass
in an out-parameter pointer as an initial argument (and then return `void`
instead).

# Second Class Types for Regions

The article (Second-Class References)[https://borretti.me/article/second-class-references]
explains the tradeoffs associates with two different approaches to
borrowing. Here's my summary:

* First-class references are more expressive. They are also more difficult
  to implement and can have cognitive overhead for users since lifetimes
  cannot always be inferred. My own additional thought (not from the article)
  is that this kind of system can infect datatype and function definitions
  with region/lifetime annotations. Anything with a read-only view of data
  ends up accepting a region/lifetime argument. For example, in austral,
  the type of `length` is
  `generic [R: Region] function length(buf: &[ByteBuffer, R]): Index;`
  This happens in rust as well. The common solution to this problem is
  to have the compiler infer these annotations when possible (ellision).
  But the syntactic noise is still there, and it provides lots of
  opportunities to bikeshed.
* Second-class references are more simple. Effectively, there is a single
  lifetime annotation: borrowed. You cannot put borrowed data in a struct,
  and you cannot return a borrowed value. This makes it simple for the
  "borrow" construct to not let data escape. Functions that use data in
  a read-only way take borrowed arguments.

Here's my take: For a system that needs to support nonunique (immutable) data,
I don't like either of these. Why? Borrowing with first-class lifetimes is
unpleasant for the reasons that I already described. Second-class references
are simultaneously (1) not expressive enough to deal with common patterns
and (2) lead to redundancy. Consider ordered maps with integer keys:

    -- MapOfMut has unique elements
    -- Map has nonunique elements
    insertA : *MapOfMut a -> Int -> *a -> *MapOfMut a
    insertB : *Map a -> Int -> a -> *Map a
    insertC : Map a -> Int -> a -> Map a
    lookupA : &MapOfMut a -> Int -> &Option a -- does not typecheck
    lookupB : &Map a -> Int -> Option a
    lookupC : Map a -> Int -> Option a
    -- These last two are just for illustration
    -- They look up a single element from the unique map while deallocating
    -- the entire map.
    lookupD : *Map a -> Int -> Option a
    lookupE : *MapOfMut a -> Int -> *Option a

First let's talk about the difference between `MapOfMut` and `Map`. We really
do need different APIs for these types. Maps of unique elements and maps of
nonunique elements have different APIs, and I think it is ok for these to
be different types. The problems are with the variants of `insert`.
Variant A does not even typecheck because it returns a second-class value
(which is not allowed). The Second-Class References article talks about
this limitation in the Reference Transforms section. It is possible to
work around this somewhat, but this concession is detrimental to the
simplicity of the system. Let's look at variants B and C. What's weird
is that these are the same function. We should be able to take an nonunique
map and cast it to a borrowed one. So we would want some kind of subtyping
relation there. There no way to insert into a second-class map without
building a first-class copy of the map.

Anyway, I think it is more simple to just have the borrowed value be
indistinguishable from a nonunique value. For this to be sound, the borrow
construct needs some onerous rules (i.e. can only return nonoverlapping types
or primitive types).

# Strategy for Building Compiler

I would like to build a compiler for a monomorphic language. The language
should not support:

* Type abstraction
* Effects (maybe just IO, not sure)

The language neeeds to have at least these types built in:

* Ordered map with string keys
* Arrays

In theory, it is possible to handle IO (which must be sequenced) with a
unique token type. However, this makes it awful to actually do anything in
the language. It also complicates optimization by making it more difficult
for the compiler to recognize certain constructs. I think that it should
not be too difficult to include support for an IO effect.

As a shortcut, I would like to start by not implementing automatic memory
management for nonunique values. For unique values, things are easy. When
they go out of scope, they just get deallocated. But I would like to
design this in such a way that I can add support for nonunique values
(through reference counting) later. If a unique value can be upcasted
to a nonunique value as a no-op, the RC value for the unique value must
be set to 1 right when it is allocated. This would mean that no additional
action would need to be taken when an upcast happens (the RC value would
already be correct).

But already, there are some problems with this strategy. To start with,
how does borrowing work? If I go with the "borrowed values are treated
as nonunique" strategy, I'm going to end up performing a bunch of increments
and decrements in a borrow block.

But what if deferred RC is the plan for the longer term? This would
mean that we wouldn't need to update the RCs as we pass nonunique data
around. Longer term, we would be periodically scanning the stack to
perform these updates. But in the short term, if the only way that
nonunique data becomes available is through borrows, everything works
out fine.

# Upcasting Unique Values to Nonunique

In a system with uniqueness types, we should be able to use a unique
value any place that a nonunique value is expected. The interaction
with GC is somewhat complicated. The entry from 2024-05-13 has some
good notes about this (especially the four-bullet-point summary),
but I didn't come up with a full solution.

But right now, I don't need a full solution. I just need a foundation
that I can start with, and it needs to be possible to fill in the holes
later. Here's a puzzle. Consider this program:

    let x : *Map *Person = ...
    let y : *Map Person = x
    let z : Map Person = y
    ...

The language I'm trying to build does not have uniqueness polymorphism,
so this idea will not be expressible in a way that's this clean, but it
will still be possible. Here, we perform two upcasts. The first forgets
about the uniqueness of the elements. The second forgets about the
uniqueness of the map itself. If we didn't do either of these and `x`
just went out of scope, then we should get prompt deallocation. If we
just did the first upcast and then let `y` go out of scope, what would
happen? The spine of the map would get deallocated promptly, but the
elements would not. They would linger and be cleaned up at the next
nursery collection. It doesn't even matter what their RC is because they
simply are not reachable. The scenario where `z` goes out of scope is
similar to the scenary where `y` goes out of scope.

But now let's try something else:

    let x : *Map *Person = ...
    let z : Map Person = x
    let p = lookup(z,64)
    // z goes out of scope but p remains live

This is also fine. Person `p` is reachable from the stack. None of the
other objects are.

I think that the mutable-container-of-immutable-elements case is just
difficult to get good performance for in the general case. When the
container is frozen quickly (commonly the case for small arrays),
any time spent on dirty bits is wasted. When the container is large and
is never frozen, the user probably wants a different behavior. In
particular, if the data structure is updated infrequently, the scans
might be extremely wasteful. I wonder if we could fingerprint the payload
in a way that would show us places where changes might have happened.
This would still require scanning the payload at every GC. Which could
be gigantic.

I think it is better to just have different types for this purpose.
In particular, hash maps are an excellent candidate for this because:

* They are typically not frozen
* Insertion is already costly enough that setting a dirty bit is not a
  huge price to pay.

Let's move on from this. I'm still missing something. I can see that there
is a problem in the way that I am thinking about doing deferred RC. Let's
describe how deferred RC should work:

* If a new nonunique object is encountered, its children must have their
  RCs incremented. Rational: Creation of an immutable object causes its
  children to have their RCs incremented exactly once.
    * An object that did not exist when the stack was previously scanned
      is considered new.
    * An object that was mutable when the stack was previously scanned
      and is now immutable is considered new.

Every object, both mutable and immutable, needs two pieces of information:

1. A counter that tracks references from immutable objects
2. A bit that communicates whether or not the object is reachable from
   the stack and through mutable objects. We cannot use the counter for
   these cases because it's not possible to pair a decrement with each
   increment.

When both of these become zero, we deallocate the object. One difficulty
is knowing when they are actually both zero. If we are scanning the stack,
the nonexistence of something implies that it is zero. But checking for
nonexistence is difficult and expensive. Maybe while we scan the stack,
we should build a set of all pointers. We have to keep this around until
the next time we scan the stack. Then we build another set. What is the
meaning of various set operations:

* Intersection: Everything that was reachable from the stack both then
  and now.
* Difference (now minus old): Objects that have appeared on the stack.
  These are not necessarily newly allocated.
* Difference (Old minus now): Objects that were previously on the stack
  and are not any more.

This last category is pretty important. If anything is in the set, we need
to check its counter. If the counter is zero, the object needs to be
deallocated.

Notice that we can build these sets before doing anything with counters.
We actually have to do it this way.

1. First, we take the root set (now minus old). We walk through the
   elements, looking for anything that was allocated
   between the previous GC and now. When we encounter such an element, we
   increment counters for any child fields that are heap objects. Then, if
   any of these children are recently allocated, we have to trace them as well.
   If a child field is a heap object that isn't new, we still increment its
   counter, but we do not trace it.
2. Next, we consider the antiroot set (old minus now). We walk this set
   and check the counter for each element. If the counter is zero and if
   that element is not in the now set, deallocate the object. To deallocate
   an object:
    * Decrement the counter for each child field. 
    * If any children have their RC hit zero, check if they are in the now set
      and deallocate them if they are not. (This is recursive)
    * Reclaim the memory backing the object

This strategy would work if we only had immutable objects. Mutable objects
complicate matters. The most simple solution is to scan not just the stack
but also deeply scan all mutable objects on the stack. This would work, but
the performance would be awful. We would not even need to promptly reclaim
memory when unique objects went out of scope. We would find them all later
because they would all be part of the old set (but not the new set).

Even this simple (low performance) strategy for dealing with mutable objects
has a problem. How do we deallocate mutable objects in the right order?
When all objects are immutable, we know that if an object appears in the
old set, all of its children must have counters that are greater than or
equal to 1. This forces the runtime to recognize the deaths of the parent
and the child objects in the right order. But when mutable objects exist,
we lose this guarantee. We're scanning a set of antiroots, and they are
both members. Even if we had a guarantee about the ordering (e.g. parent first,
child first), we could not do anything with it. Maybe when we consider
an antiroot that was unique at the previous GC (it doesn't matter what
it is now, just what it used to be), we should ignore all of the children.
I think this actually works fine. It's weird because a child can get
deallocated before the parent that references it, but this does not cause
any problems.

So the naive strategy works. But can we do any better than that? Ideally,
if something is mutable "all the way down", we should not need to scan
it. Without deep scanning (meaning that we only scan the stack), we
do not have a way to acknowledge all the mutable subobjects (the mutable
children of a mutable object). These objects can appear to the GC in
several ways:

* Mutable and on the stack (child was extracted). This does not cause problems.
* Immutable and on the stack (child was extracted and frozen). Effectively,
  this object is "new". All of its children need to have their counters
  incremented. How can we tell that it is "new"? Normally, we try to figure
  out if an object is new by looking at what subarena it was allocated into.
  What if the GC itself used a bit (maybe the upper bit of the RC) to say
  "I have acknowleged this object and incremented the counters of its
  children?" That would work for everything. And it does not require extra
  loads and stores while the program runs. It only requires the GC to do
  something.
* Immutable and referenced by another immutable object. I think this can be
  handled the same way as the previous case.

# Carving Up Unique Arrays

One advantage of uniqueness is that we can reclaim memory promptly.
