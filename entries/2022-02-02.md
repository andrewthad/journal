# Decorate, Consume, Redecorate

Many optimizations passes on syntax trees can be understood as the composition
of two ingredients:

1. Annotate the tree with additional information. Examples: Which variables
   does this expression reference? How many times is this let-bound variable
   used (occurrence analysis)? What do we know about the range of values that
   an integer variable may hold?
2. Walk the tree, using the information to rewrite terms. This process might
   invalidate an annotation. For example, dead code elimination invalidates
   occurrence analysis since a variable that had been referenced by the dead
   code is no longer referenced by it.

This is probably related to the concepts of catamorphism and anamorphism, but
I do not understand those well and will not discuss them further here.
Annotations come in several flavors:

* Bottom-up. Example: Which variables does this expression reference?
  All you do is union the sets as you work your way up the tree, but
  there is no information pushed down. Another example is occurrence
  analysis.
* Top-down. Cannot think of any actual examples of this.
* Bottom-up and top-down. Any bottom-up annotation that propogates
  information through let-bound variables does this. Example:
  tracking information about range of values of a variable integer.
  The bottom-up part is the big series of arithmetic expressions
  that make up an expression, and the top-down part is that this
  information needs to be propogated.

Thinking about this more, it seems like the top-down information is
always just a context with information about let-bound variables. Here are
some features I would like in an optimizer. There are somewhat at odds
with one another:

* The user should be able to inspect just the result of the annotation
  pass without consuming the annotations. This gives the compiler author
  greater visibility into the behavior of the optimizer. 
* Fusing annotation with consumption in such a way that reannotation
  occurs after a term is rewritten. This improves performance.
* Unfused, single-step consumption that discards annotations. This
  is for visibility into the behavior of the optimizer, not for
  performance.
* Fuse unrelated optimization passes. For example, perform dead code
  elimination and constant folding at the same time.

Is it possible to write optimizations in such a way that all of these are
available? I think so. I believe that the crucial ingredients are:

1. Optimization pass must be able to operate on a single layer.
2. Annotations must be some kind of updateable monoid (like monoid with
   monus or what Kmett calls `MonoidAction`).
3. The only top-down part must be the context.

I think that a lot of common optimization passes can be described by
this structure. Of course, there's always going to be something out
there that cannot be represented this way (e.g. static argument transformation),
but I think that this will work for most of them. Even typechecking
can be represented this way, even though it's not an optimization.

Something that I have realized is not clear is how to get the single-layer
requirement working. You *must* be able to look down one level. Otherwise,
even constant folding wouldn't be possible. Not only that, you must be able
to graft the child into another expression. When floating in let bindings,
you need to be able to push a `let` onto the top of the child. So, what
exactly is the general interface to this kind of computation? Perhaps:

    signature Builder
      type Term
      type Anno
      type Context
      insertIntoContext :: Binder -> Context -> Context
      anno :: Term -> Anno
      constantInt :: Int -> Term
      prim :: Op -> [Term] -> Term
      ...
    signature function Pass(Builder)
      optPrim :: Context -> (Op,[Term]) -> Term
      optLet :: Context -> Id -> Term -> Term -> Term
    module function ConstantFoldPass(Builder b where type b.Anno = Shape)
      optPrim :: Context -> (Op,[Term]) -> Term
      optPrim _ (Multiply,[arg0,arg1])
        let shape0 = anno arg0
            shape1 = anno arg1
         in if | ShapeInt 0 <- shape0 = constantInt 0
               | ShapeInt 1 <- shape0 = arg1
               | ...
      optPrim _ (Add,_) = ...
      
      -- Do not do anything special for let binding.
      optLet :: Context -> Id -> Term -> Term -> Term
      optLet = let_

To run a pass over then entire syntax tree instead of just one level:

    module function WalkTree(Pass(BuilderInstantiation))
      walk :: Map Id Anno -> Term -> Term
      walk ctx t = case t of
        -- Variable lookup just steals annotations.
        Var v -> case lookup v ctx of
          Just AnnoTerm{anno} -> AnnoTerm{anno,term=Var v}
          Nothing -> error "whoops"
        Prim op args -> optPrim ctx op (map (walk ctx) args)
        Lit lit -> optLit lit
        Let var body expr ->
          let body' = walk ctx body
              expr' = walk (insertIntoContext body' ctx) expr
           in optLet ctx var body' expr'

To float in let bindings, we need to have the full binding available at
the use site:

    module function FloatInPass(Builder b where type b.Context = Map Id Binder, type b.Anno = IntSet)
      optPrim :: Map Id Binder -> (Op,[Term]) -> Term
      optPrim binders (Multiply,[arg0,arg1]) =
        let (only0, only1, both) = vennDiagram (anno arg0) (anno arg1)
            -- A litte bit fudged, but it's the general idea. Note that
            -- the implementation of letNoAnalyze must not break the let expression
            -- back apart for floating in. That will cause a loop.
         in letNoAnalyze (_ both) (prim Multiply [let_ (_ only0) arg0, let_ (_ only1) arg1])
      optPrim _ (Add,_) = ...
      
      -- This is wrong. We might need to move bindings inward
      -- with each other.
      optLet :: Map Id Binder -> Id -> Term -> Term -> Term
      optLet _ _ _ expr = expr

What did we end up needing:

* Subtracting out annotations was not actually needed
* Term is abstract but can be built with the functions in `Builder`. The
  implementations of these are responsible for combining annotations.
  Alternatively, we could just require the user to provide the annotation.
  That is a smarter option.
* For floating in, we need access to the context. This pass converts let
  bindings to a map and then moves them inward, node by node, until they
  reach a place where they cannot be moved in further.

For let floating, this appears to be falling apart fast. In particular,
there is a weird behavior going on where it needs to do a pass over child
expressions, and then it has to do them again after floating in a let
binding.

Conclusion: This idea does not work. Do not pursue it further.
