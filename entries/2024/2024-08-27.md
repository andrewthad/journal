# Stages of the Low-Level Language

I've been thinking about a low-level language. Eventually, I want to build
a high-level language that compiles to the low-level language, but it's
a lot of work to even build either of them. I realized that I want to be
able to write programs directly in the low-level language. This will be
a reward for implementing the language. And I've realized that even the
low-level language, which supports polymorphism, is expressive enough
to build interesting applications. And this would help shake out errors
in the implementation.

I realized at some point that using the low-level language directly is
too tedious. So I need a different high-level language on top of it in
order to build programs with it. The main difference between this high-level
language and the other one is that this one does not increase our abstraction
capabilities. The real (and more powerful) high-level language includes:

1. A module system with module functors
2. Terms that are not restricted to ANF
3. Light metaprogramming (regex, string builders)

The convenient high-level language includes:

1. Type-directed overloading (esp. for arithmetic)
2. Limited inference of type and region variables. If either appear
   in the type of a value argument, they can be inferred. They cannot
   be inferred from the type of the value result. It might be good to
   require that a region with the allocate capability always be visible,
   even if it could be inferred.
3. Syntactic sugar for recursive join point groups with a single member

# Top-Level Polymorphic Values

The `List` data type has a `Nil` constructor, which creates a list of any
type. But every `Nil` should be the same pointer. Just like all constant
data, it should live in the "primitive" region. I realized that top-level
constants need to be able to accept type arguments, like functions. But
unlike functions, these only need their type arguments to perform a coercion.
It's weird because it would look like their is a dependency, but there
is not actually a dependency. The alternative is to introduce a bottom
type. Then we could have:

    Nil : List ⊥

In a sense, this is cleaner. It's more clear what is actually going on.
We can even use top in certain polymorphic functions as well:

    length : List ⊤ -> i32[0..]

We can do this because polymorphic fields are guarantees to come *after*
monomorphic fields. After if arrays are implemented as a tuple including
a pointer and a length, this also works for arrays:

    lengths : Array (Array ⊤) -> Array i32[0..]

We cannot index into an `Array ⊤` because we do not know what to scale
the index by. Similarly, we cannot talk about values of struct-like types
(e.g. `Option`, `Result`) that have any of their type arguments instantiated
with ⊤. We cannot instantiate a type variable with ⊤ because we do not have
a size to pass as a witness. So we cannot specialize a polymorphic function
to work with ⊤ as one of the type arguments. This is fine.

We can even use this with ordered maps (assuming `u64` keys):

    size : Map ⊤ -> i32
    keys : Map ⊤ -> Array u64

So, what's slightly odd is that we can apply a type constructor directly
to ⊤ as though ⊤ were an ordinary type, but we cannot instantiate a type
variable with ⊤.

I think we probably want ⊥ (an uninhabited bottom) but not ⊤. Its size is
zero, and it implies that no fields of that type are present in the object.
An upcast will always be safe because field offsets are computed separately
for each data constructor. An array of type `Array ⊥` is an empty array,
and indexing into it at any index will crash at runtime because `ix * 0 >= 0`.
This means that we can instantiate type variables with ⊥.

One concern I had about this originally was that it would make it function
specializations less clear. I would like to be able to print out a list,
at compile time, that tells me every set of type arguments a function is
called with. My fear was misguided. If we have ⊤, we have more problems
with this because upcasting to ⊤ makes it impossible to tell what the original
type of the argument was. But with ⊥, all that happens is that we end up
learning about more specializations. That is, we might learn that we called
`length` on `List i64` and on `List u32` instead of on `List ⊥` (when the
argument to `length` was `Nil`). I do not think this is a problem.

# Type System

The type system looks like this:

    Type          : Kind
    Unrefined[_]  : Nat -> Class -> Kind
    Region        : Kind
    Width         : Kind
    Integer       : Kind
    Class         : Kind
    Integral      : Class
    Constructor   : Unrefined[n] -> Kind
    BoxedClass    : Unrefined[n] -> Class
    Boxed         : Kind
    List          : Unrefined[1] // Takes one type argument
    Nil           : List -> Constructor
    Cons          : List -> Constructor
    Refinement    : Class -> Kind
    Excludes      : (u : Unrefined[n]) -> Constructor u -> Refinement (BoxedClass u)
    0             : Integer
    [_ .. _]      : Integer -> Integer -> Refinement Integral
    i64           : Unrefined[0] Integral
    Apply         : (c : Class) -> Unrefined[1] c -> Type -> Unrefined[0] c
    Refine        : (c : Class) -> Unrefined[0] c -> Refinement c -> Type

Not quite right. I'll try again later. The problem I'm having is that I want
the type signatures of certain functions on integers to line up nicely:

    add.i16 : func{a0,a1,b0,b1 : Integer}(i16[a0..a1],i16[b0..b1])(i16[clamp16(a0+b0)..clamp16(a1+b1)])
    add.i32 : func{a0,a1,b0,b1 : Integer}(i32[a0..a1],i32[b0..b1])(i32[clamp32(a0+b0)..clamp32(a1+b1)])

We might be able to get away with having one refinement per unrefined type.
That is, `i16` predicates and `i32` predicates would have nothing to do with
one another:

    Type             : Kind
    Unrefined        : Kind
    Constructor      : Boxed -> Kind
    Refinement       : Unrefined -> Kind
    i8, i16          : Unrefined
    Object           : Boxed -> Type
    Refine           : (u : Unrefined) -> Refinement u -> Type
    BoundI8          : Integer -> Integer -> Refinement i8
    BoundI16         : Integer -> Integer -> Refinement i16
    I64List          : Boxed
    Nil              : Constructor I64List
    Cons             : Constructor I64List
    Exclude, Include : (b : Boxed) -> Constructor b -> Refinement (Object b)

This is better. We might want to be preserve a little bit more information
about the relationship between integral types though. This is not for the
benefit of the user but for the benefit of the compiler author:

    Signedness : Kind
    Width      : Kind
    Integer    : Signedness -> Width -> Unrefined
    Bound      : (s : Signedness) -> (w : Width) -> Integer -> Integer -> Refinement (Integer s w)
    i8  = Integer Signed W8
    i16 = Integer Signed W16

Now we can define primitives (but not user-defined functions) like this:

    add : func{s,w}{a0,a1,b0,b1 : Integer}(Integer s w [a0..a1],Integer s w [b0..b1])(Integer s w [clamp{s,w}(a0+b0)..clamp{s,w}(a1+b1)])

Now there's just one `add` primop. It's not even parametrically polymorphic
since the behavior depends on the sign and width. The uniformity is useful
for the compiler though. Several of the variants have similar lowerings
to assembly. And the same sets of optimizations are applicable to all of them.
Optimizations include constant folding and knowing that zero is the additive
identity. This function could be exposed to end users. We need a syntax for 
signedness and width arguments if we take this approach.
