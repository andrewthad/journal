# More Thoughts About Automatic Memory Management

Picking up from where I left off on 2024-12-04. I think I'm basically back
to the idea of using RC with a nursery. There are a few riffs on this idea
though:

* Moving: Copy out of the nursery before counting. Bump allocate into
  the nursery.
* Nonmoving: The nursery is comprised of type-specific 64-element blocks
  with mask indicating which slots are free. Some kind of commit phase
  traces from the stack and marks everything reachable as live (and updates
  its counter).
* Course-grained block tracking. The purpose of this is to reduce the cost
  of deallocation. If a whole block of allocations has a single inbound
  reference, we might be able to free the block more cheaply. A copying
  collector helps arrange data into blocks in such a way that this is more
  likely to be effective. This has several drawbacks. We don't want to put
  unrelated data into a block, but this causes us to miss out on opportunities
  to reuse memory. This encourages heap fragmentation.

I feel like I've gone in a giant circle. And this still feels unsatisfactory.
I still want to reclaim some of the what regions give us, even if I can't
get all of it. Let's say that we have a function that builds a big data
structure and that all of the function's allocations are reachable through
that data structure. This isn't totally unreasonable, and this is usually
how people want to write code when they are parsing something into a
syntax tree. We could track the bump allocator before and after the function
call and then reclaim that section after the identifier went out of scope
(assuming that nothing aliases it). This is kind of weird because it might
cut the nursery up in odd ways.

This is a lot like the ability to roll back a nursery pointer that I've
thought about for a long time. But it's different because it lets you roll
back a piece of the nursery. The old strategy is more simple, but it's
less effective. Consider some kind of deserialize-transform-serialize
operation. If we write to a file descriptor after the serial step, we
could almost certainly roll back the nursery pointer. But if we stored
the result in an array or a list, then we couldn't. The issue appears
to be that the most simple rollback approach interprets the escape of
*any* allocation to mean that *all* allocations might escape. But we can
be smarter about this. We can discover, for example, that all allocations
that occur between two program points are no longer live.

Recovering fragments of the nursery is odd. If we do this, the nursery
cannot be contiguous. It might make more sense to assemble the nursery
as a tree of blocks. Objects that might escape a function would be
allocated into one block (or a series of blocks). Objects that were
eligible for early reclamation would get their own blocks. The blocks
are arranged as a tree with the interpretation being that the lifetimes
of objects in a parent block dominate the lifetimes of objects in a
child block. Because of this, is it impossible for an object in a parent
block to reference an object in a child block.

This is moving in a very different direction. This is much more like a
system with regions. The regions are arranged as a list instead of
a tree, but that's not a huge difference. Even with no GC, this system
could handle some programs. But it's possible for a program with recursive
join points (loops) to allocate an infinite amount of possibly-escaping
memory. So it must be possible to clean each block. But how can we do
this. What can point into a block? The stack and the block's children.
Tracing the block's children is expensive. It we disallowed references
between blocks, this would help. In some cases, it would make us pack
all the objects from child blocks into the parent block. Let's think
through an example:

    bytes = readBytesFromFile()
    jsyntax = decodeJson(bytes)
    widget = parseWidget(jsyntax)
    score = computeScore(widget) // note: score is allocated, not primitive
    return score

Both `jsyntax` and `widget` are able to alias `bytes` because of how strings
are encoded in a JSON document. Additionally, `widget` can alias `jsyntax`.
So all three of these must be allocated into the same block. There are other
ways this could play out depending on whether or not a `Widget` has any string
fields. If it doesn't, then `widget` actually cannot alias `bytes` or
`jsyntax`. This would mean that it could live in a different block (region).
After `parseWidget` completed, the block containing `bytes` and `jsyntax`
could be freed.

Let us assume that the function `computeScore` allocates wastefully. This
means that we occassionally need to use some kind of tracing GC to figure
out what we need to keep around. We never need to trace `jsyntax` or `widget`
though.

I think this is just a combination of no-gc regions and gc regions. These
have some weird rules. It should be fine for no-gc region to point up the
tree of regions. Nothing outside of a gc region can point into the gc region
because that would make copying collection almost impossible.

In the above example, assuming that `widget` cannot alias `jsyntax`, we
would end up with these regions:

* no-gc: bytes, jsyntax
* no-gc: widget
* gc: score

The gc region for score would have to be passed in as an argument to
the function. We cannot return fresh regions, and we cannot have a
any kind of parent-child relationship between gc regions. We could,
however, in the body of a single function, create a fresh gc region,
use it, and free it. That would be fine.

A function that allocates non-wastefully should be able to accept either
a gc region or a no-gc region as its destination buffer. The caller
provides one of these depending on what it intends to do with the
result.

This scheme gives us a region system that is moderately expressive.
It can express parent-child relationships between regions, but it only
supports region annotations on binders, not on all types. So it is
not possible to have:

    Array(Widget@s)@r

In spite of its limitations, the system is a reasonable target for a high-level
language that knows nothing about regions. Non-wasteful computation can be
performed in a no-gc region.

I'm not sure what the gc strategy should be. Anything nonmoving is easier
to implement in C. I should probably start by just leaking memory and then
figure out something simple when I need it.

Also, I shouldn't compile the high-level language down this path first
anyway. I should probably start by targeting WASM now that WASMGC is available
somewhat widely.

# Rethinking High-Level Features

I've had a ton of trouble on the implementation side when lowering languages
supporting subtyping to C. I've had enough problems with this that I'm inclined
to say that it's not worth it.

Flexible array members and even fixed-length arrays inlined into data
constructors have at least two issues that I'm aware of. The first issue is
that high-level compile targets almost never support this. The second issue
is that it's kind of difficult to initialize the arrays. It's doable, but you
end up with a weird system where you want certain functions to be usable for
both ordinary arrays and for arrays that are inlined into data constructors.
Having to deal with this is annoying, and it makes me appreciate why many
languages choose not to offer this feature. This construct's most important
use is improving the performance of data structures. But certain
high-performance data structures, especially mutable ones requiring uniqueness,
are difficult to implement in the language anyway. Maybe it makes more sense
to have a fallback to a low-performance implementation written in the source
language. But then we could have high-performance variants that are backend
specific. For example, if the backend is JavaScript, then we might lower
the hashmap type (with string keys) to JavaScript's object type. If LuaJIT,
then a table. If native code, we would have some source of entropy available,
and we could use a C implementation of a hashmap. In any case, the
abstraction cannot support iteration since the iteration order is undefined.
Mutable maps sort of difficult to handle with uniqueness. It might be better
to represent them with second-class types instead. Suppose we have a primitive
that returns a second-class mutable array. This array cannot escape the
function in which it is defined. But we can mutate it in-place with all
of the usual operations. Actually, why does it need to be second class
at all? If we do not support freezing, then we do not have to scope it.
These are not great for GC, but they should not be common anyway. It's
more common to need to freeze an array, but uniqueness is more acceptable
for arrays. Alternatively, we could just have a compiler optimization
that returns an array in-place if it is statically determined that the
mutable array is dead after the freeze.

Being able to index arrays by their length is annoying. Without this,
there are a bunch of things that are difficult to express, or you end up
just introducing undefined behavior into the language (like GHC). It is
super helpful to have existential types if you are doing this. Type-level
naturals don't have to be witnesses of themselves since the array carries
around the length with it. The arrays have to carray around the lengths
so that they still work correctly if they are degraded to an array of
unknown length. This is one of those annoying ergonomic things, but the
user of the language must be able to freely upcast an array with a known
length to an array without a known length. This is a form of subtyping.
It's probably fine to require the cast to be explicit. This would make
the following conversion difficult though:

    Map (Array {12} U8)
    ==>
    Map (Array U8)

Here, we would like to forget that each element array has length 12. It's
not common to need to do this though. It's possible to provide primitives
for lifting casts over type constructors. Then we can get rid of all
implicit subtyping.
