# Kaitai Struct Overview and Thoughts

## Kaitai Struct Example

I learned about Kaitai Struct recently. It's a neat yaml-based format for
describing data serialization schemes. It only concerns itself with decoding,
not encoding. (There is some experimental encoding support, but the language
has a lot of features that don't make sense for encoding.) Every Kaitai Struct
description (a yaml file) can be interpreted by a hex dump viewer.
They can also be interpreted by code generators that produce deserialization
code for various programming languages. 

The [Quick Start](https://kaitai.io/#quick-start) on the website has an
example description of the GIF image format header:

    meta:
      id: gif
      file-extension: gif
      endian: le
    seq:
      - id: header
        type: header
      - id: logical_screen
        type: logical_screen
    types:
      header:
        seq:
          - id: magic
            contents: 'GIF'
          - id: version
            size: 3
      logical_screen:
        seq:
          - id: image_width
            type: u2
          - id: image_height
            type: u2
          - id: flags
            type: u1
          - id: bg_color_index
            type: u1
          - id: pixel_aspect_ratio
            type: u1

As this example shows, Kaitai Struct supports binding expressions to names
in the `types` section and then reusing them in the top-level `seq` section.
If we run `kaitai-struct-compiler -t java gif-header.ksy`, we get this Java code:

    import io.kaitai.struct.ByteBufferKaitaiStream;
    import io.kaitai.struct.KaitaiStruct;
    import io.kaitai.struct.KaitaiStream;
    import java.io.IOException;
    import java.util.Arrays;
    
    public class Gif extends KaitaiStruct {
        public static Gif fromFile(String fileName) throws IOException {
            return new Gif(new ByteBufferKaitaiStream(fileName));
        }
    
        public Gif(KaitaiStream _io) {
            this(_io, null, null);
        }
    
        public Gif(KaitaiStream _io, KaitaiStruct _parent) {
            this(_io, _parent, null);
        }
    
        public Gif(KaitaiStream _io, KaitaiStruct _parent, Gif _root) {
            super(_io);
            this._parent = _parent;
            this._root = _root == null ? this : _root;
            _read();
        }
        private void _read() {
            this.header = new Header(this._io, this, _root);
            this.logicalScreen = new LogicalScreen(this._io, this, _root);
        }
        public static class Header extends KaitaiStruct {
            public static Header fromFile(String fileName) throws IOException {
                return new Header(new ByteBufferKaitaiStream(fileName));
            }
    
            public Header(KaitaiStream _io) {
                this(_io, null, null);
            }
    
            public Header(KaitaiStream _io, Gif _parent) {
                this(_io, _parent, null);
            }
    
            public Header(KaitaiStream _io, Gif _parent, Gif _root) {
                super(_io);
                this._parent = _parent;
                this._root = _root;
                _read();
            }
            private void _read() {
                this.magic = this._io.readBytes(3);
                if (!(Arrays.equals(magic(), new byte[] { 71, 73, 70 }))) {
                    throw new KaitaiStream.ValidationNotEqualError(new byte[] { 71, 73, 70 }, magic(), _io(), "/types/header/seq/0");
                }
                this.version = this._io.readBytes(3);
            }
            private byte[] magic;
            private byte[] version;
            private Gif _root;
            private Gif _parent;
            public byte[] magic() { return magic; }
            public byte[] version() { return version; }
            public Gif _root() { return _root; }
            public Gif _parent() { return _parent; }
        }
        public static class LogicalScreen extends KaitaiStruct {
            public static LogicalScreen fromFile(String fileName) throws IOException {
                return new LogicalScreen(new ByteBufferKaitaiStream(fileName));
            }
    
            public LogicalScreen(KaitaiStream _io) {
                this(_io, null, null);
            }
    
            public LogicalScreen(KaitaiStream _io, Gif _parent) {
                this(_io, _parent, null);
            }
    
            public LogicalScreen(KaitaiStream _io, Gif _parent, Gif _root) {
                super(_io);
                this._parent = _parent;
                this._root = _root;
                _read();
            }
            private void _read() {
                this.imageWidth = this._io.readU2le();
                this.imageHeight = this._io.readU2le();
                this.flags = this._io.readU1();
                this.bgColorIndex = this._io.readU1();
                this.pixelAspectRatio = this._io.readU1();
            }
            private int imageWidth;
            private int imageHeight;
            private int flags;
            private int bgColorIndex;
            private int pixelAspectRatio;
            private Gif _root;
            private Gif _parent;
            public int imageWidth() { return imageWidth; }
            public int imageHeight() { return imageHeight; }
            public int flags() { return flags; }
            public int bgColorIndex() { return bgColorIndex; }
            public int pixelAspectRatio() { return pixelAspectRatio; }
            public Gif _root() { return _root; }
            public Gif _parent() { return _parent; }
        }
        private Header header;
        private LogicalScreen logicalScreen;
        private Gif _root;
        private KaitaiStruct _parent;
        public Header header() { return header; }
        public LogicalScreen logicalScreen() { return logicalScreen; }
        public Gif _root() { return _root; }
        public KaitaiStruct _parent() { return _parent; }
    }

That's a lot of code. But let's just look at the declaration of data types
and ignore functions, subclassing, and parent references:

    public class Gif {
        public static class Header {
            private byte[] magic;
            private byte[] version;
        }
        public static class LogicalScreen {
            private int imageWidth;
            private int imageHeight;
            private int flags;
            private int bgColorIndex;
            private int pixelAspectRatio;
        }
        private Header header;
        private LogicalScreen logicalScreen;
    }

This is more manageable. One thing that is surprising is that `magic`
exists. It's a 3-byte sequence that has to be equal to the ASCII representation
of the string "GIF", so why store it in the object? I suspect that it makes
the implementation more simple, but that's just a guess.

## Kaitai Struct Expression Language

In more complicated examples, description files make use of an expression
language that is embedded in YAML strings. From the
[description of bmp files](https://formats.kaitai.io/bmp/):

    is_color_mask_here:
      value: >-
        not _io.eof
        and header.len_header == header_type::bitmap_info_header.to_i
        and (header.bitmap_info_ext.compression == compressions::bitfields or header.bitmap_info_ext.compression == compressions::alpha_bitfields)
    is_color_mask_given:
      value: >-
        header.extends_bitmap_info
        and (header.bitmap_info_ext.compression == compressions::bitfields or header.bitmap_info_ext.compression == compressions::alpha_bitfields)
        and (is_color_mask_here or header.is_color_mask_here)
    color_mask_given:
      value: >-
        is_color_mask_here
          ? color_mask
          : header.color_mask
      if: is_color_mask_given
    color_mask_red:
      value: >-
        is_color_mask_given
          ? color_mask_given.red_mask
          : header.bits_per_pixel == 16
            ? 0b11111_00000_00000
            : header.bits_per_pixel == 24 or header.bits_per_pixel == 32
              ? 0xff_00_00
              : 0

This demonstrates a field (`color_mask_given`) whose existence is predicated
on the value of another field.
And here is the complete [description of `vlq_base128_be`](https://formats.kaitai.io/vlq_base128_be/):

    meta:
      id: vlq_base128_be
      title: Variable length quantity, unsigned integer, base128, big-endian
      license: CC0-1.0
      ks-version: 0.9
      bit-endian: be
    doc: |
      A variable-length unsigned integer using base128 encoding. 1-byte groups
      consist of 1-bit flag of continuation and 7-bit value chunk, and are ordered
      "most significant group first", i.e. in "big-endian" manner.
    
      This particular encoding is specified and used in:
    
      * Standard MIDI file format
      * ASN.1 BER encoding
      * RAR 5.0 file format
    
      More information on this encoding is available at
      <https://en.wikipedia.org/wiki/Variable-length_quantity>
    
      This particular implementation supports serialized values to up 8 bytes long.
    -webide-representation: '{value:dec}'
    seq:
      - id: groups
        type: group
        repeat: until
        repeat-until: not _.has_next
    types:
      group:
        -webide-representation: '{value}'
        doc: |
          One byte group, clearly divided into 7-bit "value" chunk and 1-bit "continuation" flag.
        seq:
          - id: has_next
            type: b1
            doc: If true, then we have more bytes to read
          - id: value
            type: b7
            doc: The 7-bit (base128) numeric value chunk of this group
    instances:
      last:
        value: groups.size - 1
      value:
        value: |
          (groups[last].value
          + (last >= 1 ? (groups[last - 1].value << 7) : 0)
          + (last >= 2 ? (groups[last - 2].value << 14) : 0)
          + (last >= 3 ? (groups[last - 3].value << 21) : 0)
          + (last >= 4 ? (groups[last - 4].value << 28) : 0)
          + (last >= 5 ? (groups[last - 5].value << 35) : 0)
          + (last >= 6 ? (groups[last - 6].value << 42) : 0)
          + (last >= 7 ? (groups[last - 7].value << 49) : 0)).as<u8>
        doc: Resulting value as normal integer

This demonstrates a repetition construct that is capable of decoding
variable-length integers.

## My Own Thoughts

Embedding ad-hoc expression languages (and variable binders) in YAML is hardly
new, but seeing it done again is unsatisfying as ever. There are languages
like Dhall that aim to provide a better foundation for this kind of thing.
I wonder how difficult it would be (or if it would be possible at all) to
model Kaitai Struct's expressions with Dhall (with types that prevent misuse).

Kaitai Struct's hex dump viewer is extremely cool. I feel like the language
is designed for it more than for code generation. Here are some examples
of unusual code generation that I have noticed:

* In the GIF header example, we could see where the Java code included a field
  for a constaint value. Including this is odd, and deserialization target types
  written by hand would not include it.
* In the generated Java code for `vlq_base128_le.ksy` (included at the bottom of
  this entry), the class `VlqBase128Le` includes both a nullable Java `Long` and
  an `ArrayList<Group>` that holds every original byte (each as a heap allocated
  object instance of class `Group`) originally used to represent the `Long`.
  The `Long` representing the true decoded value is computed lazily. This uses
  up to 10x more memory to represent 64-bit numbers than one would expect to
  be used.
* None of the target languages have support for tagged unions (i.e. algebraic
  data types). I've looked at how `google_protobuf.ksy`, which features a tagged
  union, is lowered to Java. I've included the full file at the end of this
  entry. Kaitai Struct represents that unknown part as a Java `Object`, which is
  common strategy in the Java ecosystem. But `fieldTag` are `wireType` are both
  computed lazily from the raw `key`.

Working through these examples, I'm getting a sense of what the code-generation
strategy is. Since Kaitai Struct doesn't know if an expression will
be cheap or expensive, it takes the easy route of lazy evaluation. The resulting
generated data types (at least for the Java backend) are predictable (good) but
are non-idiomatic (bad). That is, I don't think anyone writing these decoders
by hand would have written what Kaitai Struct generated.

I'm only able to pick on the protobuf and variable-length integer decoders
because I have written them by hand before. For protobuf, it makes sense for
the deserialized object to have `fieldTag` and a tagged union for the object.
Preserving the original integer that embedded both the field tag and the wire
type tag is just not useful. However, for other data formats, the redundancy
in the deserialized object might be desirable. It makes it impossible to update
the data, but that's often fine.

I guess what I'm trying to say is, if I were to design a similar system,
I would want better control over what fields actually appear in the heap
object. It is important to support ephemeral fields that exist only as
intermediate results, and a hex viewer may even want to present these.
But generated code doesn't need to include them as object fields.

## Full Description of BMP Files

I'm including this here just in case the Kaitai Struct website ever goes down:

    meta:
      id: bmp
      file-extension: bmp
      xref:
        forensicswiki: bmp
        justsolve: BMP
        loc: fdd000189
        mime: image/bmp
        pronom:
          - fmt/114 # Windows Bitmap 1.0
          - fmt/115 # Windows Bitmap 2.0
          - fmt/116 # Windows Bitmap 3.0
          - fmt/117 # Windows Bitmap 3.0 NT
          - fmt/118 # Windows Bitmap 4.0
          - fmt/119 # Windows Bitmap 5.0
          - x-fmt/25 # OS/2 Bitmap 1.0
          - x-fmt/270 # OS/2 Bitmap 2.0
        wikidata: Q192869
      tags:
        - windows
      license: CC0-1.0
      ks-version: 0.9
      endian: le
      # ks-opaque-types: true # uncomment this line and comment `/types/bitmap`,
                              # if you provide an opaque type `bitmap` for bitmap data
    doc: |
      The **BMP file format**, also known as **bitmap image file** or **device independent
      bitmap (DIB) file format** or simply a **bitmap**, is a raster graphics image file
      format used to store bitmap digital images, independently of the display
      device (such as a graphics adapter), especially on Microsoft Windows
      and OS/2 operating systems.
    
      ## Samples
    
      Great collection of various BMP sample files:
      [**BMP Suite Image List**](
        http://entropymine.com/jason/bmpsuite/bmpsuite/html/bmpsuite.html
      ) (by Jason Summers)
    
      If only there was such a comprehensive sample suite for every file format! It's like
      a dream for every developer of any binary file format parser. It contains a lot of
      different types and variations of BMP files, even the tricky ones, where it's not clear
      from the specification how to deal with them (marked there as "**q**uestionable").
    
      If you make a program which will be able to read all the "**g**ood" and "**q**uestionable"
      BMP files and won't crash on the "**b**ad" ones, it will definitely have one of the most
      extensive support of BMP files in the universe!
    
      ## BITMAPV2INFOHEADER and BITMAPV3INFOHEADER
    
      A beneficial discussion on Adobe forum (archived):
      [**Invalid BMP Format with Alpha channel**](
        https://web.archive.org/web/20150127132443/https://forums.adobe.com/message/3272950
      )
    
      In 2010, someone noticed that Photoshop generated BMP with an odd type of header. There wasn't
      any documentation available for this header at the time (and still isn't).
      However, Chris Cox (former Adobe employee) claimed that they hadn't invented any type
      of proprietary header and everything they were writing was taken directly
      from the Microsoft documentation.
    
      It showed up that the unknown header was called BITMAPV3INFOHEADER.
      Although Microsoft has apparently requested and verified the use of the header,
      the documentation on MSDN has probably got lost and they have probably
      forgotten about this type of header.
    
      This is the only source I could find about these structures, so we could't rely
      on it so much, but I think supporting them as a read-only format won't harm anything.
      Due to the fact that it isn't documented anywhere else, most applications don't support it.
    
      All Windows headers at once (including mentioned BITMAPV2INFOHEADER and BITMAPV3INFOHEADER):
    
      ![Bitmap headers overview](
        https://web.archive.org/web/20190527043845/https://forums.adobe.com/servlet/JiveServlet/showImage/2-3273299-47801/BMP_Headers.png
      )
    
      ## Specs
       * [Bitmap Storage (Windows Dev Center)](
           https://learn.microsoft.com/en-us/windows/win32/gdi/bitmap-storage
         )
          * BITMAPFILEHEADER
          * BITMAPINFOHEADER
          * BITMAPV4HEADER
          * BITMAPV5HEADER
       * [OS/2 Bitmap File Format](
            https://www.fileformat.info/format/os2bmp/egff.htm
         )
          * BITMAPFILEHEADER (OS2BMPFILEHEADER)
          * BITMAPCOREHEADER (OS21XBITMAPHEADER)
          * OS22XBITMAPHEADER
       * [Microsoft Windows Bitmap](
            http://netghost.narod.ru/gff/graphics/summary/micbmp.htm
         )
          * BITMAPFILEHEADER (WINBMPFILEHEADER)
          * BITMAPCOREHEADER (WIN2XBITMAPHEADER)
          * BITMAPINFOHEADER (WINNTBITMAPHEADER)
          * BITMAPV4HEADER (WIN4XBITMAPHEADER)
    
    seq:
      - id: file_hdr
        type: file_header
      - id: dib_info
        size: file_hdr.ofs_bitmap - file_hdr._sizeof
        type: bitmap_info
      - id: bitmap
        type: bitmap
        size-eos: true
    types:
      bitmap:
        doc: |
          Replace with an opaque type if you care about the pixels. You can look at
          an example of a JavaScript implementation:
          <https://github.com/generalmimon/bmptool/blob/master/src/Bitmap.js>
    
          There is a proposal for adding bitmap data type to Kaitai Struct:
          <https://github.com/kaitai-io/kaitai_struct/issues/188>
      file_header:
        -orig-id: BITMAPFILEHEADER
        doc-ref: https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapfileheader
        seq:
          - id: file_type
            -orig-id: bfType
            contents: "BM"
          - id: len_file
            -orig-id: bfSize
            type: u4
            doc: not reliable, mostly ignored by BMP decoders
          - id: reserved1
            -orig-id: bfReserved1
            type: u2
          - id: reserved2
            -orig-id: bfReserved2
            type: u2
          - id: ofs_bitmap
            -orig-id: bfOffBits
            type: s4
            doc: Offset to actual raw pixel data of the image
      bitmap_info:
        -orig-id: BITMAPINFO
        doc-ref: https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapinfo
        seq:
          - id: len_header
            type: u4
          - id: header
            -orig-id: bmciHeader
            size: len_header - len_header._sizeof
            type: bitmap_header(len_header)
          - id: color_mask
            type: color_mask(header.bitmap_info_ext.compression == compressions::alpha_bitfields)
            if: is_color_mask_here
            doc: Valid only for BITMAPINFOHEADER, in all headers extending it the masks are contained in the header itself.
          - id: color_table
            -orig-id: bmciColors
            size-eos: true
            type: 'color_table(not header.is_core_header, header.extends_bitmap_info ? header.bitmap_info_ext.num_colors_used : 0)'
            if: not _io.eof
        instances:
          is_color_mask_here:
            value: >-
              not _io.eof
              and header.len_header == header_type::bitmap_info_header.to_i
              and (header.bitmap_info_ext.compression == compressions::bitfields or header.bitmap_info_ext.compression == compressions::alpha_bitfields)
          is_color_mask_given:
            value: >-
              header.extends_bitmap_info
              and (header.bitmap_info_ext.compression == compressions::bitfields or header.bitmap_info_ext.compression == compressions::alpha_bitfields)
              and (is_color_mask_here or header.is_color_mask_here)
          color_mask_given:
            value: >-
              is_color_mask_here
                ? color_mask
                : header.color_mask
            if: is_color_mask_given
          color_mask_red:
            value: >-
              is_color_mask_given
                ? color_mask_given.red_mask
                : header.bits_per_pixel == 16
                  ? 0b11111_00000_00000
                  : header.bits_per_pixel == 24 or header.bits_per_pixel == 32
                    ? 0xff_00_00
                    : 0
            #         ^ uses fixed color palette, so color mask is N/A
          color_mask_green:
            value: >-
              is_color_mask_given
                ? color_mask_given.green_mask
                : header.bits_per_pixel == 16
                  ? 0b00000_11111_00000
                  : header.bits_per_pixel == 24 or header.bits_per_pixel == 32
                    ? 0x00_ff_00
                    : 0
          color_mask_blue:
            value: >-
              is_color_mask_given
                ? color_mask_given.blue_mask
                : header.bits_per_pixel == 16
                  ? 0b00000_00000_11111
                  : header.bits_per_pixel == 24 or header.bits_per_pixel == 32
                    ? 0x00_00_ff
                    : 0
          color_mask_alpha:
            value: >-
              is_color_mask_given and color_mask_given.has_alpha_mask
                ? color_mask_given.alpha_mask
                : 0
    
      bitmap_header:
        -orig-id:
          - BITMAPCOREHEADER
          - OS21XBITMAPHEADER
        doc-ref:
          - https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapcoreheader
          - https://www.fileformat.info/format/os2bmp/egff.htm#OS2BMP-DMYID.3.1
        params:
          - id: len_header
            type: u4
        seq:
          - id: image_width
            -orig-id: biWidth
            type:
              switch-on: is_core_header
              cases:
                true: u2
                false: u4
            doc: Image width, px
          - id: image_height_raw
            -orig-id: biHeight
            type:
              switch-on: is_core_header
              cases:
                true: s2
                false: s4
            doc: Image height, px (positive => bottom-up image, negative => top-down image)
          - id: num_planes
            -orig-id: biPlanes
            type: u2
            # valid: 1
            doc: Number of planes for target device, must be 1
          - id: bits_per_pixel
            -orig-id: biBitCount
            type: u2
            doc: Number of bits per pixel that image buffer uses (1, 4, 8, 16, 24 or 32)
          - id: bitmap_info_ext
            type: bitmap_info_extension
            if: extends_bitmap_info
          - id: color_mask
            type: color_mask(len_header != header_type::bitmap_v2_info_header.to_i)
            if: is_color_mask_here
          - id: os2_2x_bitmap_ext
            type: os2_2x_bitmap_extension
            if: extends_os2_2x_bitmap
          - id: bitmap_v4_ext
            type: bitmap_v4_extension
            if: extends_bitmap_v4
          - id: bitmap_v5_ext
            type: bitmap_v5_extension
            if: extends_bitmap_v5
        instances:
          is_core_header:
            value: len_header == header_type::bitmap_core_header.to_i
          extends_bitmap_info:
            value: len_header >= header_type::bitmap_info_header.to_i
          extends_os2_2x_bitmap:
            value: len_header == header_type::os2_2x_bitmap_header.to_i
          extends_bitmap_v4:
            value: len_header >= header_type::bitmap_v4_header.to_i
          extends_bitmap_v5:
            value: len_header >= header_type::bitmap_v5_header.to_i
          image_height:
            value: 'image_height_raw < 0 ? -image_height_raw : image_height_raw'
          bottom_up:
            value: image_height_raw > 0
          is_color_mask_here:
            value: len_header == header_type::bitmap_v2_info_header.to_i
              or len_header == header_type::bitmap_v3_info_header.to_i
              or extends_bitmap_v4
          uses_fixed_palette:
            value: not (bits_per_pixel == 16 or bits_per_pixel == 24 or bits_per_pixel == 32)
              and not (extends_bitmap_info and not extends_os2_2x_bitmap and (bitmap_info_ext.compression == compressions::jpeg or bitmap_info_ext.compression == compressions::png))
      bitmap_info_extension:
        -orig-id: BITMAPINFOHEADER
        doc-ref: https://learn.microsoft.com/en-us/previous-versions/dd183376(v=vs.85)
        seq:
          - id: compression
            -orig-id: biCompression
            type: u4
            enum: compressions
            if: not _parent.extends_os2_2x_bitmap
          - id: os2_compression
            -orig-id: Compression
            type: u4
            enum: os2_compressions
            if: _parent.extends_os2_2x_bitmap
          - id: len_image
            -orig-id: biSizeImage
            type: u4
            doc: |
              If biCompression is BI_JPEG or BI_PNG, indicates the size of the JPEG or PNG image buffer.
              This may be set to zero for BI_RGB bitmaps.
          - id: x_resolution
            -orig-id: biXPelsPerMeter
            type: u4
          - id: y_resolution
            -orig-id: biYPelsPerMeter
            type: u4
          - id: num_colors_used
            -orig-id: biClrUsed
            type: u4
          - id: num_colors_important
            -orig-id: biClrImportant
            type: u4
      os2_2x_bitmap_extension:
        -orig-id: OS22XBITMAPHEADER
        doc-ref: https://www.fileformat.info/format/os2bmp/egff.htm#OS2BMP-DMYID.3.2
        seq:
          - id: units
            type: u2
          - id: reserved
            type: u2
          - id: recording
            type: u2
            # valid: 0
            doc: |
              Specifies how the bitmap scan lines are stored.
              The only valid value for this field is 0, indicating that the bitmap is
              stored from left to right and from the bottom up.
          - id: rendering
            type: u2
            enum: os2_rendering
            doc: Specifies the halftoning algorithm used on the bitmap data.
          - id: size1
            type: u4
            doc: |
              rendering == os2_rendering::error_diffusion
                => error damping as a percentage in the range 0 through 100
              rendering == os2_rendering::panda or rendering == os2_rendering::super_circle
                => X dimension of the pattern used in pixels
          - id: size2
            type: u4
            doc: |
              rendering == os2_rendering::error_diffusion
                => not used
              rendering == os2_rendering::panda or rendering == os2_rendering::super_circle
                => Y dimension of the pattern used in pixels
          - id: color_encoding
            type: u4
            doc: |
              Specifies the color model used to describe the bitmap data.
              The only valid value is 0, indicating the RGB encoding scheme.
          - id: identifier
            type: u4
            doc: Application-specific value
    
      bitmap_v4_extension:
        -orig-id: BITMAPV4HEADER
        doc-ref: https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapv4header
        seq:
          - id: color_space_type
            -orig-id: bV4CSType
            type: u4
            enum: color_space
          - id: endpoint_red
            type: cie_xyz
          - id: endpoint_green
            type: cie_xyz
          - id: endpoint_blue
            type: cie_xyz
          - id: gamma_red
            -orig-id: bV4GammaRed
            type: fixed_point_16_dot_16
          - id: gamma_blue
            -orig-id: bV4GammaGreen
            type: fixed_point_16_dot_16
          - id: gamma_green
            -orig-id: bV4GammaBlue
            type: fixed_point_16_dot_16
    
      cie_xyz:
        -orig-id: CIEXYZ
        doc-ref: https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-ciexyz
        seq:
          - id: x
            type: fixed_point_2_dot_30
          - id: y
            type: fixed_point_2_dot_30
          - id: z
            type: fixed_point_2_dot_30
    
      bitmap_v5_extension:
        meta:
          encoding: windows-1252 # for the file name of linked profile (see profile_data below)
        -orig-id: BITMAPV5HEADER
        doc-ref: https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapv5header
        seq:
          - id: intent
            -orig-id: bV5Intent
            type: u4
            enum: intent
          - id: ofs_profile
            -orig-id: bV5ProfileData
            doc: The offset, in bytes, from the beginning of the BITMAPV5HEADER structure to the start of the profile data.
            type: u4
          - id: len_profile
            -orig-id: bV5ProfileSize
            type: u4
          - id: reserved
            -orig-id: bV5Reserved
            type: u4
        instances:
          has_profile:
            value: >-
              _parent.bitmap_v4_ext.color_space_type == color_space::profile_linked
              or _parent.bitmap_v4_ext.color_space_type == color_space::profile_embedded
          profile_data:
            io: _root._io
            pos: _root.file_hdr._sizeof + ofs_profile
            size: len_profile
            type:
              switch-on: _parent.bitmap_v4_ext.color_space_type == color_space::profile_linked
              cases:
                true: strz
            if: has_profile
            doc-ref: https://learn.microsoft.com/en-us/windows/win32/wcs/using-structures-in-wcs-1-0 "If the profile is embedded,
              profile data is the actual profile, and if it is linked, the profile data is the
              null-terminated file name of the profile. This cannot be a Unicode string. It must be composed exclusively
              of characters from the Windows character set (code page 1252)."
    
      color_table:
        params:
          - id: has_reserved_field
            type: bool
          - id: num_colors
            doc: |
              If equal to 0, the pallete should contain as many colors as can fit into the pixel value
              according to the `bits_per_pixel` field (if `bits_per_pixel` = 8, then the pixel can
              represent 2 ** 8 = 256 values, so exactly 256 colors should be present). For more flexibility,
              it reads as many colors as it can until EOS is reached (and the image data begin).
            type: u4
        seq:
          - id: colors
            type: rgb_record(has_reserved_field)
            repeat: expr
            repeat-expr: 'num_colors > 0 and num_colors < num_colors_present ? num_colors : num_colors_present'
        instances:
          num_colors_present:
            value: '_io.size / (has_reserved_field ? 4 : 3)'
      color_mask:
        params:
          - id: has_alpha_mask
            type: bool
        seq:
          - id: red_mask
            type: u4
          - id: green_mask
            type: u4
          - id: blue_mask
            type: u4
          - id: alpha_mask
            type: u4
            if: has_alpha_mask
      rgb_record:
        -orig-id:
          - RGB_TRIPLE
          - RGB_QUAD
        params:
          - id: has_reserved_field
            type: bool
        seq:
          - id: blue
            type: u1
          - id: green
            type: u1
          - id: red
            type: u1
          - id: reserved
            type: u1
            if: has_reserved_field
        -webide-representation: "rgb({red:dec}, {green:dec}, {blue:dec})"
    # Common types
      fixed_point_2_dot_30:
        -orig-id: FXPT2DOT30
        seq:
          - id: raw
            type: u4
        instances:
          value:
            value: (raw + 0.0) / (1 << 30)
        -webide-representation: "{value}"
      fixed_point_16_dot_16:
        seq:
          - id: raw
            type: u4
        instances:
          value:
            value: (raw + 0.0) / (1 << 16)
        -webide-representation: "{value}"
    enums:
      compressions:
        # https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapv5header (search for bV5Compression)
        0:
          id: rgb
          -orig-id: BI_RGB
          doc: Uncompressed RGB format
        1:
          id: rle8
          -orig-id: BI_RLE8
          doc: RLE compression, 8 bits per pixel
        2:
          id: rle4
          -orig-id: BI_RLE4
          doc: RLE compression, 4 bits per pixel
        3:
          id: bitfields
          -orig-id: BI_BITFIELDS
        4:
          id: jpeg
          -orig-id: BI_JPEG
          doc: BMP file includes whole JPEG file in image buffer
        5:
          id: png
          -orig-id: BI_PNG
          doc: BMP file includes whole PNG file in image buffer
        6:
          id: alpha_bitfields
          -orig-id: BI_ALPHABITFIELDS
          doc: only Windows CE 5.0 with .NET 4.0 or later
          doc-ref:
            - https://en.wikipedia.org/wiki/BMP_file_format#DIB_header_(bitmap_information_header) table of compression methods
            - http://entropymine.com/jason/bmpsuite/bmpsuite/html/bmpsuite.html q/rgba32abf.bmp
      os2_compressions:
        # https://www.fileformat.info/format/os2bmp/egff.htm#OS2BMP-DMYID.3.2
        0:
          id: rgb
        1:
          id: rle8
        2:
          id: rle4
        3:
          id: huffman_1d
          doc: Huffman 1D compression (also known as CCITT Group 3 One-Dimensional (G31D))
        4:
          id: rle24
          doc: RLE compression, 24 bits per pixel
      os2_rendering:
        0:
          id: no_halftoning
        1:
          id: error_diffusion
        2:
          id: panda
          doc: Processing Algorithm for Noncoded Document Acquisition (PANDA)
        3:
          id: super_circle
    
      color_space:
        # https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapv5header#members
      # For BITMAPV4HEADER:
        0:
          id: calibrated_rgb
          -orig-id: LCS_CALIBRATED_RGB
          doc: This value implies that endpoints and gamma values are given in the appropriate fields.
        0x73524742: # 'sRGB'
          id: s_rgb
          -orig-id: LCS_sRGB
          doc: Specifies that the bitmap is in sRGB color space.
        0x57696e20: # 'Win '
          id: windows
          -orig-id: LCS_WINDOWS_COLOR_SPACE
          doc: This value indicates that the bitmap is in the system default color space, sRGB.
      # For BITMAPV5HEADER:
        0x4c494e4b: # 'LINK'
          id: profile_linked
          -orig-id: PROFILE_LINKED
          doc: |
            This value indicates that bV5ProfileData points to the file name of the profile
            to use (gamma and endpoints values are ignored).
    
            If a profile is linked, the path of the profile can be any fully qualified name
            (including a network path) that can be opened using the Win32 CreateFile function.
        0x4d424544: # 'MBED'
          id: profile_embedded
          -orig-id: PROFILE_EMBEDDED
          doc: |
            This value indicates that bV5ProfileData points to a memory buffer that contains
            the profile to be used (gamma and endpoints values are ignored).
      intent:
        # https://learn.microsoft.com/en-us/windows/win32/api/wingdi/ns-wingdi-bitmapv5header#members
        8:
          id: abs_colorimetric
          -orig-id: LCS_GM_ABS_COLORIMETRIC
          doc: Maintains the white point. Matches the colors to their nearest color in the destination gamut.
        1:
          id: business
          -orig-id: LCS_GM_BUSINESS
          doc: Maintains saturation. Used for business charts and other situations in which undithered colors are required.
        2:
          id: graphics
          -orig-id: LCS_GM_GRAPHICS
          doc: Maintains colorimetric match. Used for graphic designs and named colors.
        4:
          id: images
          -orig-id: LCS_GM_IMAGES
          doc: Maintains contrast. Used for photographs and natural images.
    
      header_type:
        # https://web.archive.org/web/20190527043845/https://forums.adobe.com/servlet/JiveServlet/showImage/2-3273299-47801/BMP_Headers.png
        12: bitmap_core_header
        40: bitmap_info_header
        52: bitmap_v2_info_header
        56: bitmap_v3_info_header
        64: os2_2x_bitmap_header
        108: bitmap_v4_header
        124: bitmap_v5_header

## Generated VlqBase128Le Java File

This is the compilation of the description file `vlq_base128_le.ksy` to Java:

    import io.kaitai.struct.ByteBufferKaitaiStream;
    import io.kaitai.struct.KaitaiStruct;
    import io.kaitai.struct.KaitaiStream;
    import java.io.IOException;
    import java.util.ArrayList;
    
    
    /**
     * A variable-length unsigned/signed integer using base128 encoding. 1-byte groups
     * consist of 1-bit flag of continuation and 7-bit value chunk, and are ordered
     * "least significant group first", i.e. in "little-endian" manner.
     * 
     * This particular encoding is specified and used in:
     * 
     * * DWARF debug file format, where it's dubbed "unsigned LEB128" or "ULEB128".
     *   <https://dwarfstd.org/doc/dwarf-2.0.0.pdf> - page 139
     * * Google Protocol Buffers, where it's called "Base 128 Varints".
     *   <https://protobuf.dev/programming-guides/encoding/#varints>
     * * Apache Lucene, where it's called "VInt"
     *   <https://lucene.apache.org/core/3_5_0/fileformats.html#VInt>
     * * Apache Avro uses this as a basis for integer encoding, adding ZigZag on
     *   top of it for signed ints
     *   <https://avro.apache.org/docs/current/spec.html#binary_encode_primitive>
     * 
     * More information on this encoding is available at <https://en.wikipedia.org/wiki/LEB128>
     * 
     * This particular implementation supports serialized values to up 8 bytes long.
     */
    public class VlqBase128Le extends KaitaiStruct {
        public static VlqBase128Le fromFile(String fileName) throws IOException {
            return new VlqBase128Le(new ByteBufferKaitaiStream(fileName));
        }
    
        public VlqBase128Le(KaitaiStream _io) {
            this(_io, null, null);
        }
    
        public VlqBase128Le(KaitaiStream _io, KaitaiStruct _parent) {
            this(_io, _parent, null);
        }
    
        public VlqBase128Le(KaitaiStream _io, KaitaiStruct _parent, VlqBase128Le _root) {
            super(_io);
            this._parent = _parent;
            this._root = _root == null ? this : _root;
            _read();
        }
        private void _read() {
            this.groups = new ArrayList<Group>();
            {
                Group _it;
                int i = 0;
                do {
                    _it = new Group(this._io, this, _root);
                    this.groups.add(_it);
                    i++;
                } while (!(!(_it.hasNext())));
            }
        }
    
        /**
         * One byte group, clearly divided into 7-bit "value" chunk and 1-bit "continuation" flag.
         */
        public static class Group extends KaitaiStruct {
            public static Group fromFile(String fileName) throws IOException {
                return new Group(new ByteBufferKaitaiStream(fileName));
            }
    
            public Group(KaitaiStream _io) {
                this(_io, null, null);
            }
    
            public Group(KaitaiStream _io, VlqBase128Le _parent) {
                this(_io, _parent, null);
            }
    
            public Group(KaitaiStream _io, VlqBase128Le _parent, VlqBase128Le _root) {
                super(_io);
                this._parent = _parent;
                this._root = _root;
                _read();
            }
            private void _read() {
                this.hasNext = this._io.readBitsIntBe(1) != 0;
                this.value = this._io.readBitsIntBe(7);
            }
            private boolean hasNext;
            private long value;
            private VlqBase128Le _root;
            private VlqBase128Le _parent;
    
            /**
             * If true, then we have more bytes to read
             */
            public boolean hasNext() { return hasNext; }
    
            /**
             * The 7-bit (base128) numeric value chunk of this group
             */
            public long value() { return value; }
            public VlqBase128Le _root() { return _root; }
            public VlqBase128Le _parent() { return _parent; }
        }
        private Integer len;
        public Integer len() {
            if (this.len != null)
                return this.len;
            int _tmp = (int) (groups().size());
            this.len = _tmp;
            return this.len;
        }
        private Long value;
    
        /**
         * Resulting unsigned value as normal integer
         */
        public Long value() {
            if (this.value != null)
                return this.value;
            long _tmp = (long) (((long) ((((((((groups().get((int) 0).value() + (len() >= 2 ? (groups().get((int) 1).value() << 7) : 0)) + (len() >= 3 ? (groups().get((int) 2).value() << 14) : 0)) + (len() >= 4 ? (groups().get((int) 3).value() << 21) : 0)) + (len() >= 5 ? (groups().get((int) 4).value() << 28) : 0)) + (len() >= 6 ? (groups().get((int) 5).value() << 35) : 0)) + (len() >= 7 ? (groups().get((int) 6).value() << 42) : 0)) + (len() >= 8 ? (groups().get((int) 7).value() << 49) : 0)))));
            this.value = _tmp;
            return this.value;
        }
        private Long signBit;
        public Long signBit() {
            if (this.signBit != null)
                return this.signBit;
            long _tmp = (long) (((long) ((((long) (1)) << ((7 * len()) - 1)))));
            this.signBit = _tmp;
            return this.signBit;
        }
        private Long valueSigned;
    
        /**
         * @see <a href="https://graphics.stanford.edu/~seander/bithacks.html#VariableSignExtend">Source</a>
         */
        public Long valueSigned() {
            if (this.valueSigned != null)
                return this.valueSigned;
            long _tmp = (long) (((long) ((((long) ((value() ^ signBit()))) - ((long) (signBit()))))));
            this.valueSigned = _tmp;
            return this.valueSigned;
        }
        private ArrayList<Group> groups;
        private VlqBase128Le _root;
        private KaitaiStruct _parent;
        public ArrayList<Group> groups() { return groups; }
        public VlqBase128Le _root() { return _root; }
        public KaitaiStruct _parent() { return _parent; }
    }

## Generated GoogleProtobuf Java File

Compiling `google_protobuf.ksy` to Java:

    import io.kaitai.struct.ByteBufferKaitaiStream;
    import io.kaitai.struct.KaitaiStruct;
    import io.kaitai.struct.KaitaiStream;
    import java.io.IOException;
    import java.util.ArrayList;
    import java.util.Map;
    import java.util.HashMap;
    
    
    /**
     * Google Protocol Buffers (AKA protobuf) is a popular data
     * serialization scheme used for communication protocols, data storage,
     * etc. There are implementations are available for almost every
     * popular language. The focus points of this scheme are brevity (data
     * is encoded in a very size-efficient manner) and extensibility (one
     * can add keys to the structure, while keeping it readable in previous
     * version of software).
     * 
     * Protobuf uses semi-self-describing encoding scheme for its
     * messages. It means that it is possible to parse overall structure of
     * the message (skipping over fields one can't understand), but to
     * fully understand the message, one needs a protocol definition file
     * (`.proto`). To be specific:
     * 
     * * "Keys" in key-value pairs provided in the message are identified
     *   only with an integer "field tag". `.proto` file provides info on
     *   which symbolic field names these field tags map to.
     * * "Keys" also provide something called "wire type". It's not a data
     *   type in its common sense (i.e. you can't, for example, distinguish
     *   `sint32` vs `uint32` vs some enum, or `string` from `bytes`), but
     *   it's enough information to determine how many bytes to
     *   parse. Interpretation of the value should be done according to the
     *   type specified in `.proto` file.
     * * There's no direct information on which fields are optional /
     *   required, which fields may be repeated or constitute a map, what
     *   restrictions are placed on fields usage in a single message, what
     *   are the fields' default values, etc, etc.
     * @see <a href="https://protobuf.dev/programming-guides/encoding/">Source</a>
     */
    public class GoogleProtobuf extends KaitaiStruct {
        public static GoogleProtobuf fromFile(String fileName) throws IOException {
            return new GoogleProtobuf(new ByteBufferKaitaiStream(fileName));
        }
    
        public GoogleProtobuf(KaitaiStream _io) {
            this(_io, null, null);
        }
    
        public GoogleProtobuf(KaitaiStream _io, KaitaiStruct _parent) {
            this(_io, _parent, null);
        }
    
        public GoogleProtobuf(KaitaiStream _io, KaitaiStruct _parent, GoogleProtobuf _root) {
            super(_io);
            this._parent = _parent;
            this._root = _root == null ? this : _root;
            _read();
        }
        private void _read() {
            this.pairs = new ArrayList<Pair>();
            {
                int i = 0;
                while (!this._io.isEof()) {
                    this.pairs.add(new Pair(this._io, this, _root));
                    i++;
                }
            }
        }
    
        /**
         * Key-value pair
         */
        public static class Pair extends KaitaiStruct {
            public static Pair fromFile(String fileName) throws IOException {
                return new Pair(new ByteBufferKaitaiStream(fileName));
            }
    
            public enum WireTypes {
                VARINT(0),
                BIT_64(1),
                LEN_DELIMITED(2),
                GROUP_START(3),
                GROUP_END(4),
                BIT_32(5);
    
                private final long id;
                WireTypes(long id) { this.id = id; }
                public long id() { return id; }
                private static final Map<Long, WireTypes> byId = new HashMap<Long, WireTypes>(6);
                static {
                    for (WireTypes e : WireTypes.values())
                        byId.put(e.id(), e);
                }
                public static WireTypes byId(long id) { return byId.get(id); }
            }
    
            public Pair(KaitaiStream _io) {
                this(_io, null, null);
            }
    
            public Pair(KaitaiStream _io, GoogleProtobuf _parent) {
                this(_io, _parent, null);
            }
    
            public Pair(KaitaiStream _io, GoogleProtobuf _parent, GoogleProtobuf _root) {
                super(_io);
                this._parent = _parent;
                this._root = _root;
                _read();
            }
            private void _read() {
                this.key = new VlqBase128Le(this._io);
                {
                    WireTypes on = wireType();
                    if (on != null) {
                        switch (wireType()) {
                        case VARINT: {
                            this.value = new VlqBase128Le(this._io);
                            break;
                        }
                        case LEN_DELIMITED: {
                            this.value = new DelimitedBytes(this._io, this, _root);
                            break;
                        }
                        case BIT_64: {
                            this.value = (Object) (this._io.readU8le());
                            break;
                        }
                        case BIT_32: {
                            this.value = (Object) (this._io.readU4le());
                            break;
                        }
                        }
                    }
                }
            }
            private WireTypes wireType;
    
            /**
             * "Wire type" is a part of the "key" that carries enough
             * information to parse value from the wire, i.e. read correct
             * amount of bytes, but there's not enough informaton to
             * interprete in unambiguously. For example, one can't clearly
             * distinguish 64-bit fixed-sized integers from 64-bit floats,
             * signed zigzag-encoded varints from regular unsigned varints,
             * arbitrary bytes from UTF-8 encoded strings, etc.
             */
            public WireTypes wireType() {
                if (this.wireType != null)
                    return this.wireType;
                this.wireType = WireTypes.byId((key().value() & 7));
                return this.wireType;
            }
            private Integer fieldTag;
    
            /**
             * Identifies a field of protocol. One can look up symbolic
             * field name in a `.proto` file by this field tag.
             */
            public Integer fieldTag() {
                if (this.fieldTag != null)
                    return this.fieldTag;
                int _tmp = (int) ((key().value() >> 3));
                this.fieldTag = _tmp;
                return this.fieldTag;
            }
            private VlqBase128Le key;
            private Object value;
            private GoogleProtobuf _root;
            private GoogleProtobuf _parent;
    
            /**
             * Key is a bit-mapped variable-length integer: lower 3 bits
             * are used for "wire type", and everything higher designates
             * an integer "field tag".
             */
            public VlqBase128Le key() { return key; }
    
            /**
             * Value that corresponds to field identified by
             * `field_tag`. Type is determined approximately: there is
             * enough information to parse it unambiguously from a stream,
             * but further infromation from `.proto` file is required to
             * interprete it properly.
             */
            public Object value() { return value; }
            public GoogleProtobuf _root() { return _root; }
            public GoogleProtobuf _parent() { return _parent; }
        }
        public static class DelimitedBytes extends KaitaiStruct {
            public static DelimitedBytes fromFile(String fileName) throws IOException {
                return new DelimitedBytes(new ByteBufferKaitaiStream(fileName));
            }
    
            public DelimitedBytes(KaitaiStream _io) {
                this(_io, null, null);
            }
    
            public DelimitedBytes(KaitaiStream _io, GoogleProtobuf.Pair _parent) {
                this(_io, _parent, null);
            }
    
            public DelimitedBytes(KaitaiStream _io, GoogleProtobuf.Pair _parent, GoogleProtobuf _root) {
                super(_io);
                this._parent = _parent;
                this._root = _root;
                _read();
            }
            private void _read() {
                this.len = new VlqBase128Le(this._io);
                this.body = this._io.readBytes(len().value());
            }
            private VlqBase128Le len;
            private byte[] body;
            private GoogleProtobuf _root;
            private GoogleProtobuf.Pair _parent;
            public VlqBase128Le len() { return len; }
            public byte[] body() { return body; }
            public GoogleProtobuf _root() { return _root; }
            public GoogleProtobuf.Pair _parent() { return _parent; }
        }
        private ArrayList<Pair> pairs;
        private GoogleProtobuf _root;
        private KaitaiStruct _parent;
    
        /**
         * Key-value pairs which constitute a message
         */
        public ArrayList<Pair> pairs() { return pairs; }
        public GoogleProtobuf _root() { return _root; }
        public KaitaiStruct _parent() { return _parent; }
    }
