# Closures in Low-Level Direct-Style IR

I have considered several options for adding closures to a low-level IR.
I do not want them to be first class, and I want them to always live on
the stack. At first, I was hoping that I could bind the closure to an
identifier and then pass that identifier as an argument to a function.
But this requires a type system supporting second-class types, and there
are difficulties with recursive join points. So instead, I settled on
this: closures cannot be bound to identifiers. They are written out
inline during function application. For example:

    num : S64 = ...
    newArray = update(oldArray,ix,func(x) {r = x + num; return r})

Or maybe this could be a nice syntax as well:

    newArray = update(oldArray,ix,f) with f(x):
      r = x + num
      return r

Something like that would let us define a multiline closure without
having to cram the function body onto a single line.

On the other side, in the implementation of `update`, the callback
is a second-class value. It cannot be returned or even bound to another
identifier. It can be applied or passed to additional function calls.
Closures support both linear and nonlinear consumption. Only a linearly
consumed closure can close over linear values.

What about inlining? When we inline a function, we have to duplicate
the definition of the closure into all use sites (since closures cannot
be bound to identifiers). This is fine when there is at most one use
site. When there is more than one use site, this could lead to problems.
One solution to this issue is to split up closure definitions and
evaluations. For example:

    closure IncrementBy : Closure(S64)(S64) = closure
      envr
        num : S64
      eval(x : S64) =
        r = x + num
        return r
    
    num : S64 = ...
    newArray = update(oldArray,ix,IncrementBy(num))

This solves two problems:

1. We do not need a multiline syntax anymore
2. Inlining results in a duplication of the stack-allocated `IncrementBy`,
   but it does not duplicate the closure body.

Next, let's consider a polymorphic closure:

    func replicate : Function{a}(S64,a)(List a) = ...
    clsr ReplicateN : Closure{a}(a)(List a) = closure
      envr
        count : S64
      eval(e : a) =
        r = call replicate(count,e)
        return r

And a polymorphic closure with no value argument:

    clsr Identity : Closure{a}(a)(List a) = closure
      envr {}
      eval(x : a) =
        return x

Both of these example are unary functions closing over an environment.
How do we lower these to C? Let's do `IncrementBy` first:

    struct opaque { unsigned char contents[32]; }
    struct UnaryClosure {
      void* envr;
      struct opaque (*eval)(void* envr, struct opaque);
    }
    struct opaque evalUnaryClosure(struct UnaryClosure* clsr, struct opaque arg0) {
      return (*(cslr->eval))(clsr->envr, arg0);
    }

Now let's look at the environment and evaluation for `Identity`:

    struct EnvrIdentity {
      uint8_t typeA;
    }
    struct opaque evalIdentity(void* envr, struct opaque arg) {
      // We do not need to use typeA in this particular instance,
      // be we do in other situations.
      return arg;
    }
    
And for `ReplicateN`:

    struct EnvrReplicateN {
      uint8_t typeA;
      int64_t count;
    }
    struct opaque evalReplicateN(void* envr0, struct opaque arg) {
      struct EnvrReplicateN* envr = (struct EnvrReplicateN*) envr0;
      return replicateN(envr->typeA, envr->count, arg);
    }

The example lowering of `ReplicateN` shows why we have to store the type
variable in the environment. It doesn't really show how it is ultimately
used. Somewhere in the unshown implementation of `replicateN`, we allocate
cons cells, but we only want to perform a `memcpy` that populates the
right number of bytes in the cell, and the number of bytes depends on the
size of the element type. When we deal with values of abstract types on
the stack, we can just inflate them to 32 bytes. We waste some stack space
this way. This is acceptable because the stack should always be small anyway.
It would be much worse to pad data on the heap.

Finally, let's get to `IncrementBy`:

    struct IncrementBy {
      int64_t num;
    }
    struct opaque evalIncrementBy(void* envr0, struct opaque x0) {
      struct IncrementBy* envr = (struct IncrementBy*) envr0;
      int64_t x = 0;
      memcpy(&x, &x0, 8);
      int64_t r = x + envr->num;
      struct opaque dst = {0};
      memcpy(&dst, &r, 8);
      return dst;
    }

Now we see an example of having to extract and deposit 64-bit integers.
Why do we have to this? It's so that the type signatures of `evalIncrementBy`
and `evalIdentity` are the same. The only way to even define `evalIdentity`
is to use the version with an opaque argument and result type. It ends up
being `evalIncrementBy` that has to contort itself to make this possible.

We could push every function in this direction. That is, all of the
C lowerings of top-level functions could just accept `struct opaque` arguments
and return results in the same way. But I don't think that it's a good idea
to do that. It would make it easier to use the functions as closures. But,
a simple alternative is to just define wrapper function for each top-level
function. This makes closures a little more expensive to use, but it cuts
down on overhead imposed on every direct function call. Hopefully, direct
function calls are the much more common case.

The good thing about this plan is that I can start by not supporting closures,
and then I can just add them later. Having that flexibility is nice.

# Tags for Search

tag:secondclass, tag:closures

