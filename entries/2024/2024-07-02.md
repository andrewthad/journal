# Linear Types vs Ownership Types

Note: All the way at the bottom of this, I find an acceptable solution
to my problem.

I found a good StackOverflow answer to a
[question](https://cstheory.stackexchange.com/questions/12426/ownership-types-and-separation-logic)
about how substructal type systems contrast with ownership types.
This answer is from Neel Krishnaswami, who coauthored a great paper on
bidirectional type systems:

> The way I understand the difference is that ownership types constrain the
> shape of the object graph, and substructural systems (like separation
> logic) manage permissions to access the heap.
>
> In the original work on ownership types, the idea is to maintain the
> invariant of owners as dominators. An object o is dominated by an object d,
> if every path from the root set to o contains d. So o is only reachable
> from d. So the system is designed so that class declarations are parameterized
> by their owners, and then this fact gives you a derived frame condition
> for o: its state cannot change unless a method on its owner d is invoked.
>
> In contrast, substructural systems like linear types and separation logic
> rely on the idea of resources. Each region of the heap is a resource,
> and if you don't possess the resource you can't touch it. This makes
> frame conditions very easy: they always hold.
>
> One superficial difference (which nevertheless confused me for a long
> time) was that ownership types were types, and separation logic was a
> program logic. Luckily, while ownership types were born in a
> type-theoretic setting, people have applied these ideas to program
> logics as well.
>
> The two main pieces of theoretical work I know on this are Kassios's work
> on dynamic frames, which Bannerjee and Naumann (and their students)
> systematically exploited in their work on regional logic.
>
> As I understand it, their basic approach is to take Hoare logic, and then:
>
> 1. Add a new type of region variables, which you use to associate objects and regions.
> 2. Add an effect system to Hoare logic to track the regions reads and writes touch.
> 3. Use the effects to determine if an assertion is frame-respecting or not. If it is,
>    you can frame it, and if it isn't, you can't.
>
> Each approach has benefits and weaknesses.
>
> Ownership makes frame properties significantly less convenient to use than
> in substructural approaches, since you have to compute frame conditions.
>
> On the other hand, algorithms on DAGs support prettier inductive proofs
> in an ownership style, since you can decouple the footprint from the
> pointer structure. In a separation-style spec, the natural thing is to give
> an inductive invariant on a spanning tree. But if the spanning tree
> the algorithm computes is ever different than the one your invariant has,
> you're in for a world of hurt.
>
> My general sense is that separation is easier to use than ownership,
> since we need frame properties for nearly every command in an imperative
> program. (Dave Naumann argues that region logic is more amenable
> to automation, since the assertion logic remains plain old FOL,
> and so you can use off-the-shelf theorem provers and SMT solvers.)

# Austral's Linear Types

The documentation for the Austral programming language claims that Austral
has a linear type system, but it actually does something a bit more complicated
than linear types. There are ways to use a value of a linear type without
actually consuming that value. But then once it is consumed, even these
"zero consumption" uses cannot be used anymore. This is not like the zero
multiplicity from QTT (which Idris 2 uses) because there is an implied order
to everything.

# Build, Freeze, Deallocate

Yesterday (2024-07-01), I thought about two different ways to describe
reading from a mutable array:

    read : MutableArray a {1} -> S64 -> (MutableArray a {1}, a)
    read : MutableArray a {0} -> S64 -> a

The ergonomics of the second one are undeniably superior, but it requires
a type system with more than just linear types.

For lots of data though, we do not need to read from it while it is mutable.
We can build up a data structure (requires mutation), freeze it, read from
it freely, and then deallocate it. How difficult is it to support this pattern?

Consider building an ordered map. When we deallocate it, we probably want to
deallocate all the elements as well. The elements might end up shared by
whatever consumes the map, but in many cases, they do not need to be shared
in this way. This suggests:

    // The elements of this map are always consumed linearly
    MutableMap : Type -> Type
    // This variant of insert crashes the program if an element
    // is already present at the key.
    insert : Key {*} -> a {1} -> MutableMap a {1} -> MutableMap a {1}
    lookup : Map a {*} -> Key {*} -> Option a {*}
    withFrozen :
         (a {1} -> Unit {*})  // how to destroy an element
      -> MutableMap a {1}     // the mutable map
      -> (Map a {*} -> b {*}) // use an immutable borrow 
      -> b {*}

This does not work though. Here are the problems:

1. The types `a` and `b` must be disjoint in some way. We cannot allow an
   element to escape, and we cannot allow the map to escape.
2. This does not work correctly when the element is a file descriptor. In
   that case, we are able to freely duplicate the file descriptor, and then
   we can call close on it twice.

One solution to this problem is to require the elements of `MutableMap` to
be nonlinear. Then, escape is safe, and the file descriptor problem goes
away because we cannot put file descriptors in the mutable map (or the
immutable one). But the cost of this is expressivity. We need a tracing
collector to reclaim the elements.

A different solution is second-class types. I explored this in an update
to the 2024-05-06 entry. Here is what it would look like in this context:

    insert : Key {*}{2nd} -> a {1}{1st} -> MutableMap a {1}{1st} -> MutableMap a {1}
    lookup : Map a {*}{2nd} -> Key {*}{2nd} -> Option a {*}
    withFrozen :
         (a {1}{1st} -> Unit {*})  // how to destroy an element
      -> MutableMap a {1}{1st}     // the mutable map
      -> (Map a {*}{2nd} -> b {*}) // use an immutable borrow 
      -> b {*}

The second-class nature of the borrowed map cannot be deep since `lookup`
returns first-class elements. So this does not solve either problem.
Regions do a much better job of solving this problem. With regions, we
would have something more simple:

    // Key is an int-like type that can be copied cheaply
    insert : Key -> a {1}{r} -> MutableMap a {1}{r} -> MutableMap a {1}{r}
    lookup : Map a {*}{r} -> Key -> Option a {*}{r}
    freeze : MutableMap a {1}{r} -> Map a {*}{r}
    withRegion : forall a. (forall (r : Region) -> a) -> a

This solves problem 1. Nothing allocated in a region can escape it.
But problem 2 is unresolved because we are still able to disregard the
linear consumption guarantee that the elements expect. The issue is that
`freeze` is unsound. But maybe we should solve this problem with a different
type of map. Now that regions are in play, why do we even need to bother with
promising linear consumption of the element:

    insert : Key -> a {*}{r} -> MutableMap a {1}{r} -> MutableMap a {1}{r}

Now we have to freeze all the elements before we insert them. So this
map type cannot be used with file descriptors. Which is fine because it's
not even possible for a "linear file descriptor" API to work in this
context. How could we consume file descriptor returned by a read or write
function? We couldn't, so this doesn't even work.

Region types come with their own issues. This biggest problem is that they
complicate the type signatures of tons of functions. So I'm not sure that
I would even be willing to entertain this approach. What about introducing
a zero multiplicity:

    insert : Key {*} -> a {1} -> MutableMap a {1} -> MutableMap a {1}
    lookup : Map a {0} -> Key {*} -> Option a {0}
    withFrozen :
         (a {1} -> Unit {*})  // how to destroy an element
      -> MutableMap a {1}     // the mutable map
      -> (Map a {0} -> b {*}) // use an immutable borrow 
      -> b {*}

What does it mean to use something zero times? It probably means just
reading from it. That's strange though because it makes zero and many
seem like the same thing. It has another problem too. We need for it to
be impossible to use a binder at multiplicity zero after the corresponding
resource has been destroyed. This means that the binder needs to not be
in the context, so we have to CPS more things. Let's try:

    new   : S64 {*} -> a {*} -> MutableArray a {1}
    write : MutableArray a {1} -> S64 {*} -> a {*} -> MutableArray a {1}
    with  : MutableArray a {1}
         -> (Array a {0} -> b {*})
         -> (MutableArray a {1}, b)
    index : Array a {0} -> S64 {*} -> a {0}

The looks like it would actually work. Now let's go a step further. What
if everything in the array is linear?

    // The new function is now more like a generator.
    new   : S64 {*} -> (S64 {*} -> a {1}) -> MutableArray a {1}
    write : MutableArray a {1} -> S64 {*} -> a {1} -> MutableArray a {1}
    with  : MutableArray a {1}
         -> (Array a {0} -> b {*})
         -> (MutableArray a {1}, b)
    index : Array a {0} -> S64 {*} -> a {0}

Now we make a promise as we write an element to a mutable array. That
promise is: "This element will be consumed exactly once." And remarkably,
we API uploads that promise. When we call `with`, we get a view of the array
that allows us to access elements, but the contract of `index` is that we
can only consume the element zero times.

This is a neat result, and it feels like a step in the right direction.
Still, it has its limitations. It feels like a hack to make `MutableArray`
and `Array` different types. But it is necessary. If we instead have:

    // This API is unsound
    new   : S64 {*} -> (S64 {*} -> a {1}) -> MutableArray a {1}
    write : MutableArray a {1} -> S64 {*} -> a {1} -> MutableArray a {1}
    with  : MutableArray a {1}
         -> (MutableArray a {0} -> b {*})
         -> (MutableArray a {1}, b)
    index : MutableArray a {0} -> S64 {*} -> a {0}

Then we can freely index into mutable arrays while we are writing to them
or even after they are explicitly deallocated. This is not sound.

So having a separate Array type keeps things sound, which is good. But having
them be separate types leads to an unsatisfactory result when we nest arrays.
If we have a value of type `MutableArray (MutableArray Foo){1}`, then our
borrowed array has type `Array (MutableArray Foo){0}`, and when we index
into it, we get a value of type `MutableArray Foo{0}`, and this is unusable.
That is, there are no function that "zero consume" a mutable array. And there
cannot be any such function because it would lead to unsoundness.

We could just define some extra copies of `with`:

    with  : MutableArray (MutableArray a) {1}
         -> (Array (Array a) {0} -> b {*})
         -> (MutableArray (MutableArray a) {1}, b)

This isn't very principled. A little better would be:

    with  : MutableArray (Heap m obj) {1}
         -> (Array (Heap Immutable obj) {0} -> b {*})
         -> (MutableArray (Heap m obj) {1}, b)

And now we can handle all user-defined types as well. We probably need
something for recursively defined types as well, but I think that is
doable. Then, getting back to maps, we could have:

    insert : Key {*} -> a {1} -> MutableMap a {1} -> MutableMap a {1}
    lookup : Map a {0} -> Key {*} -> Option a {0}
    withMap :
         MutableMap a {1}     // the mutable map
      -> (Map a {0} -> b {*}) // use an immutable borrow 
      -> (MutableMap a {1}, b {*})

Technically, we want the flexibility to handle mutable elements here
as well. I do not want to expose type variables for mutability to
users, but it might be necessary.

With the system that I have described today, it is possible to do
something like:

1. List the files in the current working directory (`opendir`)
2. Learn the name of each file (`readdir64`) and write these file names
   into an array.
3. Sort this array of strings.
4. Collect information about each file with `stat` or `fstat`. Print
   the file name and the size of each file.
5. Deallocate the array and the strings.

It should be possible to do this without leaking memory. What do we need
in order to build this:

* Some plan for dealing with the types of effectful IO operations
* Wrapper functions for several posix functions
* A function to sort a mutable arrays of strings in place (probably
  just bubble sort)

I think that the sorting function can be built in the language itself.
It should look like this:

    sort : MutableArray String {1} -> MutableArray String {1}
    sort strs = :
      strs', len = mutableArrayLen(strs)
      sortHead(len,strs')
    sortHead : S64 -> MutableArray String {1} -> MutableArray String {1}
    sortHead n strs = compare n 1:
      LE -> strs
      GT -> :
        strs' = sortLoop 1 n strs
        sortHead(n - 1, strs')
    sortLoop : S64 -> S64 -> MutableArray String {1} -> MutableArray String {1}
    sortLoop i n strs = compare i n:
      LT -> :
        strs', a = read(strs,i - 1)
        strs'', b = read(strs',i)
        compareStrings a b:
          LE -> strs''
          GT -> swap(strs'', i - 1, i)
      GE -> strs

# Other Thoughts

## Affine Types

I keep thinking "if I had affine types instead of linear types, it would let
me index into mutable arrays more easily". But this is not true. With affine
types, I could get rid of the explicit deallocate, so I wouldn't have to worry
about indexing (a "zero consumption" operations) after deallocation. But I
would still have to worry about indexing into something after it has been
destructively modified. So this does not work.

## Uniqueness Types

The way I am talking about mutability is basically just uniqueness types.
I might should just use uniqueness types instead. But I'm not sure.

## Freezing and Letting the GC Take Over

We can borrow an immutable array using `with`:

    index : Array a {0} -> S64 {*} -> a {0}
    with  : MutableArray a {1}
         -> (Array a {0} -> b {*})
         -> (MutableArray a {1}, b)

But what should it look like to mark an array as being eligible for garbage
collection? Probably one of these:

    freeze : MutableArray a {1} -> Array a {*}
    freeze : MutableArray a {1} -> Array a {0}

But which one? The contract for `write` indicates that the element is consumed
exactly once. Neither of these `freeze` variants result in that promise being
kept. If the elements were supposed to be consumed nonlinearly, this would be
fine. We could just use the first one in that case. But I think that supporting
a deep freeze is important. Especially in the case where we are building up
a syntax tree while parsing something, we will not know in advance how a caller
will want to consume the data. They may want to freeze the whole thing or they
might perform a single pass over the syntax tree that converts it to some
other representation, moving and deallocating as it goes. It would be nice
to be able to use the same function to satisfy both cases.

Maybe the first variant of `freeze` above is not so bad. If the children are
just in-memory objects (not file descriptors), then they all have their own
freeze functions as well. It's like we called freeze on everything, and that's
a sound thing to do.

File descriptors are a problem though. There isn't supposed to be an operation
that results in file descriptors with unrestricted use.

What about this:

    freeze : (a{1} -> b{*}) -> MutableArray a {1} -> Array b {*}

I don't like this at all, but it captures the idea of pushing the freeze
for the element type down onto each element. It's like there needs to be
some notion of "freezable type". This is sort of like what Rust's `Copy`
and `Drop` traits are, but it's not the same thing as either of them.
And I don't love the idea of using traits or typeclasses or anything like
that for something like this.

The problem though, is that if type abstraction is supported, then we
cannot just claim that an abstract type was used linearly when it really
wasn't. Maybe the problem is that I am trying to use linear types for
two different things. One of them is dealing with mutation, freezing,
and borrowing. And then other one is providing an extension point for
a user to create their own abstractions for escape prevention. The
zero-multiplicity thing was a clever trick. It works by exploiting
a distinction in how objects and arrays works (reading without
consuming is allowed) and how user abstractions work (only linear
consumption is possible). A user could create an abstraction that involves
function arguments of an abstract type with the zero multiplicity. But
the abstraction would not work correctly because you could perform a
use-after-close.

But we cannot exploit this when we attempt to freeze instead of borrow.
With borrowing, if you had an array of file descriptors, the callback
could not do anything useful with the array. But the function dumped
the original array back in your lap after the callback completed, and
then you still had to do something with those file descriptors. Freezing
just lets us throw everything away, which is no good.

# More Thinking

I thought about this more, and I do not see any obvious improvements.
One possibility is a proof language that establishes that two types have
equivalent runtime representations and only differ in their mutability.
Let's say that we have something parameterized by a map type:

    functor
      (MutMap : Type -> Type)
      (ImmMap : Type -> Type)
      (m : Module
        { freeze : forall t0 t1. ProveFreeze t0 t1 -> MutMap t0 {1} -> Map t1 {*}
        }
      ):
    module JsonModule
      { proof : ProveFreeze MutJson Json
      , freezeJson : MutJson {1} -> Json {0}
      }

An alternative is to have the module signature express the connection as
a function instead:

    Module
      { freeze : forall t0 t1. (t0 {0} -> t1 {*}) -> MutMap t0 {1} -> Map t1 {*}
      }

I don't like having two versions of every type.

# Pushing Down Mutability

What if all types were defined to accept a mutability argument:

    Type = (Mutability, Base)
    Tree : Base -> Base = functor(a : Base) Object:
      Branch $0 $0 
      Leaf a

If we do this, the mutability gets pushed down. Every base can be interpreted
in a mutable fashion or an immutable fashion. You do not specify the linearity
or the mutability of fields because the base determines it. Now, we get:

    // This formulation of with works with arrays and any other object
    with   : forall (b : Base) (c : Type).
             Type Mutable b {1}
          -> (Type Immutable b {0} -> c {*})
          -> (Type Mutable b {1}, c {*})
    freeze : forall (b : Base).
             Type Mutable Base {1}
          -> Type Immutable Base {*}

This operation is O(1). If we do this, we cannot reference immutable data from
a mutable value. This is a serious restriction, and it limits how the system
can be used:

* Works well: Parse wire format into structured data and then freeze it. No need
  for any shared data here.
* Works well: Borrowing
* Does not work: Mutable map with immutable elements

What about file descriptors. The signature would be:

    Module
      { Fd : Base
      , withFile : String {*} -> (Type Mutable Fd {1} -> b {*}) -> b {*}
      , writeFile : Type Mutable Fd {1} -> String {*} -> Type Mutable Fd {1}
      , closeFile : Type Mutable Fd {1} -> Unit
      } 

But this does not work anymore. We can use `freeze` to drop the file descriptor
without closing it. But if we instead claimed that the file descriptor was
immutable (and it actually is immutable), then we couldn't call freeze on it: 

    Module
      { Fd : Base
      , withFile : String {*} -> (Type Immutable Fd {1} -> b {*}) -> b {*}
      , writeFile : Type Immutable Fd {1} -> String {*} -> Type Immutable Fd {1}
      , closeFile : Type Immutable Fd {1} -> Unit
      } 

Technically, this works. But it only happens to work because we cannot freeze
values with immutable types. It is unintuitive that the "linear consumption"
guarantee for a mutable type is not a real guarantee, but for an immutable
type, it is a real guarantee.

Also, this approach makes it impossible to store file descriptors in either
mutable containers or immutable containers. We cannot put them in a mutable
container because the file descriptors are immutable, and we cannot put them
in an immutable containers because doing so is nonlinear consumption.

# The Fundamental Problem

Maybe I should just give up on the file descriptor thing. It just seems too
difficult. Here's the problem, more concisely:

* We need to be able to deep freeze mutable containers of mutable data.
* We should not be able to deep freeze a mutable container with file
  descriptors.

It is difficult to build an API for arrays with a single `freeze` operation
that has these two properties. In theory, it should be possible to divide
data into two different kinds, and the kind of the element infects the
containers. Any type that contains non-data values does not support freezing.
But this is a huge pain for a relatively small feature that I'm trying to get.

Let's try something else. What if mutability directly determines linearity:

    Module
      { Fd : Base
      , openFile : String -> Type m Fd
      , writeFile : Type m Fd -> String -> Unit
      , closeFile : Type m Fd -> Unit
      } 

This is too weird.

# Uniqueness Types

What if we use uniqueness types instead? Let's look at `Tree` again:

    Tree : Base -> Base = functor(a : Base) Object:
      Branch $0 $0 
      Leaf a

Uniqueness is inherited. The file descriptor API looks like this:

    Module
      { Fd : Base
      , openFile : String -> Fd*
      , writeFile : Fd* -> String -> Fd*
      , closeFile : Fd* -> Unit
      } 

This does not prevent file descriptor leaks, but it does prevent double free.
If we weaken a file descriptor (for example, when freezing an immutable data
structure), we will certainly leak it. Freeze is now simple. We don't even
really need to do it explicitly because it's just weakening, but:

    freeze : a* -> a

What about borrowing an immutable reference:

    // First variant deallocates argument after running.
    with_ : a* -> (a -> b*) -> b*
    with  : a* -> (a -> b*) -> (a*, b*)

That was surprisingly simple, and it works. Nothing boxed can escape the
callback. Let's look at what works and what doesn't (like before):

* Works well: Parse wire format
* Works well: Borrowing
* Works well: Mutable map with word-like elements (no pointers in elements)
* Does not work: Mutable map with immutable boxed elements
* Does not work: API for file descriptors that prevents leaks

There are a few thorny parts to this:

* Uniqueness types have a weird interaction with lambdas. If a lambda closes
  over something unique, we need to only use the lambda at most one time.
  It's weird because it suggests a little bit of linear types sprinkled into
  a system that otherwise only uses uniqueness.
* The compiler **must** annotate where weakening happens. It is not a no-op.
  The runtime needs to mark the object in some way because it is now the
  job of a garbage collector to scan it.
