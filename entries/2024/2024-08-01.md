# The Mutable Map Problem

## Problem Description

I have been trying to figure out how I think mutable maps ought to be
implemented. In a system with uniqueness types, we can do something
like this:

    insert : Map* -> Key -> Value -> Map*

With B+ trees, the result might be the same pointer as the argument,
but it might also be a pointer to a newly allocated root node. This
might it difficult to represent B+ trees with traditional in-place
mutation:

    insert : (Map, Key, Value) -> Unit

One simple way to work around this is with an indirection. Instead of
having a pointer to the root node, we have a pointer to a pointer to
the root node, and then we can update the second pointer. But I don't
like this solution.

## Solution

I have thought of a better solution: always use the same node as the
root. I had a hard time seeing that this is possible because I think
of B+ trees as increasing their height by allocating a new root node.
Allocation of a new root node results in a root with two children.
Traditionally, the old root becomes one of the children (probably
the left child). But we don't have to do things this way. We could
instead create new nodes for the left and right child. And the root
node could be the same node as it was before. This requires a little
more `memcpy`, but splitting the root node is rare.

One common insertion optimization for B+ trees involves splitting nodes
while descending. I think this approach is required if we want the
root node to always stay the same.

# Sharing Regions Across Threads

If we pass a region from one thread to another, it has to be read-only.
Not just in the receiving thread but also in the sending thread. There is
no mechanism for synchronization, so we cannot have any writers. It is
hard to do this because I do not have a way to destroy the write and
allocate capabilities. They can be hidden, but there is no way to get
a guarantee that they no longer exist. A dynamic check would be too
expensive. Using `mmap` to revoke write permission is also too expensive.

What about (and I've thought about this before but in a different context) 
a join-point like construct that exposes something in the environment?
Here is an example:

    createThenFreeze{s}:
      create: // here we have rwa capabilities on s
        z = allocate(s)(MyData)
        ...
        jump afterFreeze(z)
      afterFreeze(x : MyData{s}): // here we have r capability on s
        ... here we know that region s cannot be written to

The syntax of this is awful, but `afterFreeze` is basically a join point
that changes the capabilities on `s`. One problem with this strategy is
that we can pack `s` (with full capabilities) in `create`, which lets us
subvert the system. A solution to this problem is to only allow packing
with the read capability. In fact, we could go one step further and only
allow packing when we know that no write capabilities exist.

For any of this to be sound, we need two different kinds of read capabilities.
One of them means "we are only reading from the data". The other one means
"no one can write to the data". Thinking about it this way, the primitive
we need, expressed as a higher-order function, is:

    packed : ({s=rwa} -> b{s}) -> Pack b

As a join-point-like construct:

    initThenPack{s}(MyData):
      init{s=rwa}:
        z = allocate(s)(MyData)
        ...
        // Special construct, not a function or even a primop.
        // Here, pack takes an argument of type MyData@s.
        pack(z)
      post(x : Pack MyData):
        ...

Note that `init` does not actually have to call `pack`. It is free to jump
to any other in-scope join point or to return. These other forms of control
flow cause the region to be discarded.

One other note. This makes it impossible to create a cycle between two
packed regions. I consider this a good thing. We may need to add the
additional constraint that a region that is created in order to be
packed cannot have a parent. I think that is reasonable.

# Deallocating Packed Regions

I thought about this a little on 2024-07-30, but I didn't come up with
a solution at that time. How do we figure out when a packed region
becomes unreachable? Ordinary reference counting doesn't because we
are not able to decrement correctly when an region goes out of scope.
I've also thought about using a bitmask as an overapproximation of which
regions refer to other regions. When you write a packed region j as a field
of some object in another region k, you would set `k.references[j] = true`.
But this doesn't work because it's an overapproximation. If we were building
a queue of packed requests, we would never free the requests because
we would never learn that the queue's region no longer references
the request's region.

The straightforward solution is to track a reference count per region.
We would perform a `k.references[j] += 1` operation on assignment
and a `k.references[m] -= 1` as well to remove the previously
referenced element. If region `k` went out of scope, we would reset all
of its reference counts: `k.references[..] = 0`. Every time we change
a counter, we have to check to see if the total count for the referenced
region is zero. And if it is, we free the region. This could get pretty
expensive. Space to store the counters scales quadratically with the number
of regions. We probably need to use a sparse data structure instead of
an array, but this would make the reference-count tracking more
computationally expensive.

What about weighted references? The weight would be tracked for the entire
region referencing the packed region. This does not solve the problem of
figuring out where the weights are supposed to be stored though. Normally,
weighted reference counts are supposed to be stored with the pointer,
not somewhere else, so this does not help here.

We need each region to somehow be aware of every packed region that it
references. The region itself needs a total count for each outbound
packed reference. That way, we can decrement appropriately if the entire
region goes out of scope.

How many regions can one region reference? Using the queue as an example,
we should be able to handle at least 1000. Already, this number is too
large for anything that involves a linear scan. It's probably reasonable
to use something like 4B as an upper bound. That is, each region can be
represented as 32-bit number.

We could use a qptrie with a fanout of 16 to represent this. It's sparse,
and we can dynamically grow it as we need to, and it rewards us for using
region numbers clustered near zero. Updating counts is expensive though.
Both incrementing and decrementing require us to perform a lookup. But
what if we could make it less expensive? What if the representation
of the pointer to the packed region included another pointer to the
local region's reference count for the packed region? This would make it
less expensive for a region to shuffle around a reference to a packed
region as long as it shuffled it around inside of itself. But copying
the reference into a different region would still be expensive.

Another approach (and I hate to suggest this) is to ignore the problem.
We could just do the normal reference counting for this, and if any of
your data points to packed regions, you have to make sure you delete
those references before the region you are in goes out of scope.
This works for the bounded queue because it is mutable. But it does
not work for several kinds of immutable data. But data can only be
immutable if it has been packed. Maybe it is possible to exploit
this somehow.

Nevermind. I think I have a solution. Whenever we allocate anything
into a region, we can store pointers to its packed region references
(so, a double indirection) in a growable buffer. When the region
goes out of scope, we walk this buffer and decrement the counters
associated with each packed region by one. This is simple, and it
does not require fiddling with anything extra when we mutate.
Mutation does still require adjusting counters elsewhere, but
I think that is an acceptable trade. This strategy exploits the
expected behavior that everything in a region stays live until the
entire region goes out of scope. So this strategy can only leak memory
if the user was already using regions in a way that leaked memory.
Also, instead of using a growable buffer, we could actually just
store these references as a singly linked list and allocate them
alongside the actual data.
