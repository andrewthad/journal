# High-Level Languages vs Domain-Specific Languages

Programmers typically define high-level languages as languages that feature
automatic memory management. That is, the languages abstracts away memory
management (usually with a garbage collector) so that the user does not have
to think about it. The term "domain-specific language" (DSL) is used to describe
languages that abstract away more than just memory management. In order:

* Low-level languages: C, Zig, Rust. User is keenly aware of where allocation
  and deallocations happen.
* High-level languages: Java, Go, Haskell. User is typically aware of where
  allocation happens but not where deallocation happens.
* Domain-Specific languages: Parser generators (e.g. Bison), SQL, Regex,
  bidirectional parsers, Kaitai Struct. Users might have a general idea
  of how the translation works, but even users with no understand are able
  to use the abstraction. Typically, the abstraction is translated to a
  lower-level representation that would have been very difficult or
  impossible for a user to write by hand.

It's DSLs that I want to talk about. They are powerful, but DSL-based
solutions to many problems never seem to gain the traction that they would be
expected to gain. Languages like Haskell and Lisp have strong support
for DSLs, but neither of these languages are particularly popular. As
a long-time Haskell user, I have observed that it's not even very common
to solve problems in Haskell with DSLs. Haskell is very different
from other high-level languages in ways that I like, but its edge
in embedding DSLs is mostly unused. This might look different in the
Lisp world. I've not used any Lisp dialect, so I don't know.
In the rest of this entry, I'll look at characteristics of different
DSLs that inhibit adoption.

## Pseudoproblem: Restricted Domain 

Each DSL can only solve one particular problem. This is both a strength
and a weakness. It is a strength for several reasons:

* The DSL can have a syntax that is bent toward that particular problem.
* Since DSLs are not general purpose, the shape of a program is restricted,
  which makes more static analysis possible.

It is a weakness because a DSL cannot express as many things as a high-level
language. Often, it must be used in conjunction with a high-level language.

## Code Generation Outside of the Build Tool

DSLs that are lowered with code generation often require running a separate
program outside of the build tool. For example: Golang's `sqlc`. Sometimes,
this is remedied by making a build tool aware of code generators. For example,
in the Haskell ecosystem, `cabal` knows about `alex` and `happy`, and it
uses them to compile (to Haskell source) files with appropriate extensions.

This is important. Users of programming languages want to run `mylang build`
in a project root and have the whole thing get built. Chaining steps together
with makefiles or with a polyglot build tool introduces complexity and
opportunities for cache invalidation to fail.

## Type Systems

### SQL

Even an expressive type system like GHC Haskell's has a hard time with
important DSLs. Relational algebra is cleanly compositional. However, all of the
projects that embed SQL queries in GHC's type system are pretty gross. And they
result in terrible error messages. The problem is that GHC cannot represent
type-level maps or sets well. And even if it could, error messages might
still be bad. What even is the sweet spot for this? It's hard to say. Some
people want a more algraic SQL-like language that they can write queries in.
But the problem with this is that it's hard for anyone to read those queries
unless they've learned how to read the special language. Another solution
is to just reuse SQL. This is what `hasql-th` (in Haskell) and `sqlc` (in Golang)
both do. The two projects work very differently, but the general idea is to
just have people write queries in SQL. Then you do some amount of build-time
analysis (`sqlc` actually talks to the database for this step) that checks
if the query is well formed. And then you end up with a function in the target
language where the input and output marshalling dealt with in the generated
function body.

This gives us everything except composition. That is, neither `hasql-th` nor
`sqlc` work well when we want to glue an additional filter or project on top
of an existing query. To recover composition, we need a type system that
understands relational algebra. It's possible to do this, but we might need
to stratify programs into fragments based on what language they are written
in. This makes separate compilation tricky because a query might need to
to expose its unfolding (i.e. the raw SQL). But maybe not. Maybe everything
could be neatly tucked away into distinct object files, and then at load
time, we could perform the concatenation (or even something more complicated)
needed to build the queries.

### Parser Generators

These are weird because LL(1) grammars are compositional, but all of the more
powerful ones are not. That is, we can do this:

    MyRule
      | TokenRun RunRule
      | TokenAct ActRule

These productions start with distinct tokens. If the entire grammar that
this rule is a part of is a LL(1) grammar, the rules `RunRule` and `ActRule`
could be anything (as long as they themselves were LL(1)) and it would not
cause problems. Meaning that to decide whether or not the grammar as a whole
is LL(1), we do not have to peer into the unfoldings of `RunRule` and `ActRule`.

LALR grammars do not have this property. The entire grammar must be analyzed
as a whole. There is no way to isolate a fragment of a LALR grammar, check
its properties, and then graft it into a bigger grammar that contains it.

In spite of this difference, all CFGs that I am aware of are compatible
with types. That is, every symbol (terminal and nonterminal) can be annotated
with a type, and every production can be annotated with an expression that uses
composes values of the types associated with each symbol into a value of
the rule's type.

This is a powerful tool, but there are serious ergonomic defects in most
implementations. One common problem is the use of positional arguments.
Look at this exmaple from bison's documentation:

    exp:
      NUM
    | exp '+' exp        { $$ = $1 + $3; }
    | exp '-' exp        { $$ = $1 - $3; }
    | exp '*' exp        { $$ = $1 * $3; }
    | exp '/' exp        { $$ = $1 / $3; }
    | '-' exp  %prec NEG { $$ = -$2; }
    | exp '^' exp        { $$ = pow ($1, $3); }
    | '(' exp ')'        { $$ = $2; }
    ;

Using `$1` and `$3` is fine when there are a small number of matched symbols,
but as productions grow, it becomes more difficult to figure out what position
each symbol is in. Additionally, adding a symbol near the beginning means that
all of the numbers have to be updated. Here is an alternative:

    exp:
      NUM
    | exp:a '+' exp:b { $$ = a + a; }
    | exp:a '-' exp:b { $$ = a - b; }
    | ...

Surely someone has built a parser generator with named arguments instead of
positional arguments. I'm just not aware of any examples.

Another common problem is that error messages are terrible. Parser generators
like Bison and Happy output source code, which is then fed into a compiler.
This means that type errors are accompanied by source code that the user
did not write. What's strange is that it's actually possible to typecheck
the annotation on each production *before* doing any analysis on the grammar
and before lowering the grammar to a lower-level language. But compilers
are seldom built with this kind of modularity in mind. This would immensely
improve the quality of error messages though.
