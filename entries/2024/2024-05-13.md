# Defaulting Uniqueness

In the entry from 2024-05-10, I suggested a way to extend uniqueness
to deal with cons lists. Here are a few thoughts about defaulting.

In argument position, we always want to default to nonunique. Suppose
that we have:

    List : {Uniqueness} -> BaseType -> BaseType

If the uniqueness argument is not supplied, we want to assume that it
is nonunique. For example:

    sum : List * Int @ * -> Int @ 1
    ==>
    sum : List Int -> Int @ 1

What about the return value here? It is helpful for this to be unique
since it helps when we abstract over `Int`. But it might be best to
default this to nonunique as well just so that the defaulting rules are
more simple. So we would actually write `sum` as:

    sum : List * Int @ * -> Int @ *
    ==>
    sum : List Int -> Int

For the few cases where we are likely to create an abstraction over the
integer, we could be explicit:

    open : Function{IO}(Path)(S32 @ 1)

# Lazy Deep Freeze

When we freeze a unique object, the garbage collector needs to know about it.
It needs to know because it has to start counting references to it. The type
system I suggested on 2024-05-10 hints that deep freezing should be a no-op.
Subtyping makes it difficult to determine exactly when freezing should happen.
This should be alright. When tracing, the GC knows the types (including
uniqueness annotations) of everything on the stack and on the heap. If
a nonunique object has appeared since the last time the stack was traced,
it should be possible to just start reference counting during that collection.
There might be lots of child objects that have recently become nonunique
as well. While objects are unique, should they have a count associated with
them? Possibly. A unique object on the stack would have a count of 0, and
a unique object referenced by a (unique) heap object would have a count of 1.
No other counts are possible. So the information is nearly redundant.
It is preferable for the GC to not scan unique objects that only have unique
children. Perhaps, whenever a unique object is allocated, the count
could be set to a magic value that indicates that the object is unique.
When tracing to update counts, if the GC sees a nonunique object with
the magic value, it means that the object was frozen recently (in the
interval between the current GC and the previous GC). The GC just needs
to set the count to 0 or 1 depending on whether the object was referenced
by the stack or the heap. And then the GC must examine the immidiate
children of the object. If a child object was already nonunique (even before
the freeze), nothing needs to be done. But if the child was previously unique,
then it is now unique, and it's count must be set to 1.

This is pretty tricky, and it's got some edge cases that I know I am not
handling correctly. For example, what if something is deeply frozen and then
a child object starts being shared with something else, and the GC sees the
new reference to it first (instead of the reference through the parent that
was originally unique). The system I suggested results in an incorrect
reference count.

We definitely have to keep track of whether or not boxed types are unique
(and consequently mutable). We may need to rescan an object every cycle if
it is mutable.

I'll try summarizing what appears to be the heart of the issue:

* The advantage of RC schemes on immutable data for GC is that, if you
  aren't creating new references to old data, the GC never has to scan it.
* Mutable data interferes with this and there are two cases to consider.
* Mutable-to-mutable data (all unique) doesn't need reference counting
  because the counter is always 1. But we do have to be diligent about
  tracking when a reference to a unique object goes out of scope. We
  must free immidiately and cannot wait for GC.
* Mutable-to-immutable data (mutable data is unique) requires rescanning
  the mutable part of the data structure every GC cycle. It's possible
  to help this out by setting a dirty bit when writing.

The combination of these possibilities is tricky.
What if we allocate a deeply mutable data structure, freeze the whole
thing, then let it all go out of scope? When does the memory get reclaimed?
When immutable objects go out of scope, nothing happens immidiately.

I had been thinking of having two bit sets for heap objects. One tracks
if memory was used at the end of the most recent GC. Let's call this set A.
The other tracks if memory has been used to satisfy an allocation since then
or if it was already used. Let's call this set B. So set B includes everything
in set A. During GC, we scan the stack. We look for anything that is in set B
but not in set A and treat those as roots as well. We update RC numbers as
we work through the roots. Let's make a mutable copy of set B called set C
and then work through the roots:

* References from the stack do not contribute to RC values.
* If a new object (in set B but not in set A) is encountered, increment the
  RC on each of its children. If any of the children are new, they get scanned
  as well, and so on.
* If something was referenced on the old stack (taken at the time of set A),
  and is unreferenced from the heap, but it is not referenced by the new stack
  (taken at the time of set C's initialization), it is dead. This is an antiroot
  set. Mark these positions in set C as unused. Scan their children and decrement
  their reference counters. If an RC reaches 0, that object is also considered
  dead.

This is more complicated than I remember it being. I'm going to need to think
hard about how to incorporate unique objects into this.

# Uniqueness Types and Mapping Over Array

Here are all the possibilities:

    map : (a @ 1 -> b @ v) -> Array 1 a @ 1 -> Array v b @ 1
    map : (a @ * -> b @ v) -> Array * a @ 1 -> Array v b @ 1
    map : (a @ * -> b @ v) -> Array * a @ * -> Array v b @ 1

For the output array, the decision is clear. The array its is certainly
unique, and the element's uniqueness depends on whatever the function argument
is able to offer. What's strange is that we do not actually need the second
variant, but we do need the first one. Which means we can use a single type
to handle this:

    map : (a @ u -> b @ v) -> Array u a @ u -> Array v b @ 1

We don't need the second variant because we can freely cast a unique array
to a nonunique array. But we need the first variant because we might want
to map a function that only works on unique element.

# Tags for Search

tag:gc, tag:uniqueness, tag:rc
