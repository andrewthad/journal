# Problems With Contiguous Regions

A problem with backing regions with contiguous virtual memory is that
it's easy to leak memory. By that, I just mean that we can end up with
mapped pages that do not ever get touched again. It's a strange defect
because if we used a naive approach and just split the heap up into
blocks, we wouldn't have this problem. But if we split the heap into
blocks, I don't see how we can recover cheap allocation. I want allocation
to have no branching and use some kind of fault handler to fix up the
problematic cases. When we are always bumping in the same direction,
this is easy: just map the missing page. Userfaultfd makes this simple.
But if we carve the heap into blocks, we might need to satisfy a request
for memory with a noncontiguous block.

I thought that it might be possible to use userfaultfd for this purpose,
but userfaultfd really wants to map that missing page. And we don't want
to do that. We want to use the page fault to change the memory we are
trying to write to.

What if we let the blocks expand a little bit on demand, but then we
try to shrink them back down later? Meaning that once we expand a block,
we mark something that says "start using a different block". This way,
we could keep all the blocks reasonably small. But this would waste nearly
a full page at the end of each block. What about arrays? We could expand
as much as we wanted, so they should be fine.

How do we shrink back down? We could do it right after a region is deallocated,
or we could defer this and try to unmap pages in bulk. For large arrays, this
is more tricky. We might want to try allocating these into a special area, but
that requires branching to check the size.

Also, it looks like userfaultfd does not even work like I thought that it did.
You cannot start with a giant region unmapped with `PROT_NONE`. You usually
start out with a region mapped as read-write and then you layer the fault
handler on top. So you cannot handle a giant, mostly unmapped, virtual address
range with this.

# Different Strategy

I learned about a GCC function attribute: `no_caller_saved_registers`. This
results in a function that can be called without having to spill anything
to the stack. That keeps code bloat down.

Notes about things that work differently:

* It's better to bump down since we can compare the desired start of
  the object against the lowest address inside the block. This also
  makes arrays easier.
* Bumping down makes POSIX `read` more difficult. It's nice to be able
  to overallocate and then give back the unused space. We might just want
  to use different blocks for these.
* Array builders are also tricky. I'm not really sure what to do about
  this case, but I would like strong support from the allocator. One simple
  option is to just provide a large upper bound. But that can be wasteful.
  Maybe an array builder could be a special kind of region (there cannot be
  anything else in the region with it) that grows upward and is chunked.
  Then, at the end, we perform the copy. It would be nice to just share
  the memory if possible though, which would be a common case. Maybe if
  it's small (and did not end up chunked), we could get away with linking
  the block back into the region (as a block that grows from low to high).
  We probably do not want the array build to be its own region. Maybe it's
  part of the region, but it requires linear consumption. That way, we are
  pushing onto it element by element, incrementing a pointer. When we
  finalize it, we checked to see if it all fit it one block or not. If it
  was all in one block, we do not need to do anything. But if it spanned
  multiple blocks, we need to copy it into a correctly sized destination
  buffer and then free all of the block that were used for it. I think
  that this is doable. It's just a little tricky to think through.

