# Memory Allocation Inhibits Program Composition

Programs that allocate memory are more difficult to compose than programs
that do not allocate memory. This is evident when calling C code through
an FFI. Let's consider three cases:

1. The C code does not allocate anything. This is super easy assuming
   that the FFI is designed well.
2. The C code allocates but none of the allocations escape into the
   return value. This is almost just as easy, but the program now probably
   needs to be dynamically linked against libc (and it probably already
   had to do that). Note that, in this case, it's possible to adapt the
   C code to use a custom allocator and eliminate the dependency on libc.
   The function is a kind of memory-object boundary.
3. The C code allocates and returns the allocated memory. This is the
   worst possible case. The calling context has to be aware of the allocator
   that the C code uses. Or the C code has to be parameterized by an
   allocator. I think zig support parameterizing functions by an allocator.
   Still, I don't love this approach. Functions that act as memory-object
   boundaries.

There is special case of 3 where the function returns a pointer to some
memory that it has allocated, but the object is totally opaque. There is
no way to extract a pointer from the object, and a single call to a
`free`-like function causes all of the memory to be released. Essentially,
it returns an existentially quantified region and a pointer into that region.
We can deal with this with any traditional RC or nonmoving GC technique.

What kinds of allocation can we do inside of C code?

* Allocate onto the stack. There are restriction on how much memory can
  be allocated this way. Also, this memory cannot be returned. But it's
  really simple to do this, and it composes well.
* Allocate onto the heap with `mmap`. This composes well with other code
  because we are getting the memory directly from the kernel. The bad part
  of this is that it involves a syscall, which is slow, and it messes
  with virtual memory, which is extra slow (tons of page faults).
  It's better to reuse existing mapped blocks of memory. However, reusing
  available memory requires some mechanism for coordinating access to that
  memory, which inhibits reuse.
* Allocate onto the heap with a global allocator like `malloc`. This is
  ok, but it requires some amount synchronization between threads. It would be
  nice if there were something like `malloc` but in the kernel instead. Then
  we would have a nice universal "give me a big block of memory" construct
  that was less likely to result in page faults. Maybe it's possible to build
  something like this. The coarse granularity would make it a very simple
  allocator. You only get to perform "bulk free" operations.
