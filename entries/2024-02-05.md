# Application Developers and Library Developers

For most programming languages, there are two (overlapping) groups of
developers:

* Application developers. The software they write is compiled to executables.
* Library developers. More commonly called library authors. They write
  libraries that are typically redistributed through a package manager
  or a git forge.

Mostly library authors also write applications. Libraries are often developed
for the purpose of being used in a particular application. Most application
developers do not write libraries.

When laying the foundations for a programming language ecosystem, which group
should be prioritized? A poor experience for library authors negative impacts
application developers as well. So things should not be too difficult for
library authors. But certain flexibilities for library authors can negatively
impact application developers. Let's consider a few specifics. Some of these
are purely technical, and some of them involve the intersection of technology
and people:

* Unchecked array access. A library author might want this because it improves
  the library's performance. And for the same reason, it would be good for
  the application developers that uses the library. However, the failure mode
  (undefined behavior, often SIGSEGV) is terrible. So if a library mistake
  bleeds into the application developer's world, the application developer
  gets stuck with the bill of a difficult-to-diagnose failure instead of a
  stack trace. If unchecked array access is forbidden entirely, the application
  developer cannot encounter this problem unless the compiler itself has a
  mistake. And in that case, it's clear where the bug report should be filed.
* Standard library. Is there a standard library, available without pulling
  in any extra dependencies, that has high quality and well documented
  data structures and functions for performing common tasks (maps, arrays,
  json, etc.)? If there isn't, then the ecosystem ends up with
  either (1) competing implementations of these things leading to interop
  difficulties or (2) defacto standard libraries (e.g. Haskell's `containers`
  library) for certain critical data structures. People have a lot of
  different thoughts on this. It is commonly argued that a standard library
  should be minimal. My experience is that a minimal standard library is
  a hindrance to application developers. I'm not even sure that it's helpful
  to library authors though. I think that it's just bad for everyone. The caveat
  is that the standard library has to actually be held to the golden standard.
  If this can be accomplished, it makes is possible to coordinate changes
  that are more difficult to coordinate when there are separate maintainers
  for the affected modules.
* Package repository barriers to uploading. How hard is it
  to publish a library to a package repository? If there are no barriers
  of any kind in place, the the package repository fills up with low quality
  libraries that are not fit for use (and sometimes malware). This makes it
  more difficult to find high quality libraries, which is bad for application
  developers.
* Package repository pruning. Is anyone allowed to remove packages from
  the package repository? Most package repositories have a laissez faire
  approach to this. Malware and copyright violations are taken down, but
  anything else is permitted. Even libraries that fail to build and those
  with serious security vulnerabilites are allowed to stay. This
  doesn't harm library authors, but it makes application developers have
  to wade through more garbage to find what something that works.
* Flat package repository namespace. I won't go into detail on this right now,
  but I think that namespace in a package repository are useful.

# Two Approaches to Scrutiny and Destructuring

I prefer that the destructuring of ADTs expose a binder from which we project
labeled fields:

    case x of
      [Foo] y -> ... y.children ...
      [Bar] y -> ... y.value ... y.height ...

This constrasts with Haskell's approach:

    case x of
      Foo children -> ... children ...
      Bar value height -> ... value ... height ...

I prefer the former because:

1. In a low-level language, it lets us see where dereferences happen.
2. When paired with data-constructor refinements, it makes it possible to
   plumb the object with the refined type (in the example, `y`) though
   functions rather than passing all the fields around individually.

I have come across a situation where this does not work: ADTs that include
affine/linear/unique data. In the language I am working on, such ADTs only live
on the stack or in registers. They are never allocated on the heap. Here
is an example that illustrates the problem:

    // Supposing that mutable arrays have affine types
    type Foo = {names : MutableArray String, ages : MutableArray Int}
    myFunc(n : Int):
      foo = mkFoo(n)
      theNames = foo.names
      theAges = foo.ages
      ...

Intuitively, this should be fine. Mutable arrays cannot alias, and we have
not projected the same field from `foo` twice. But it's difficult to actually
build a type system that does this. Here are some examples of programs that
should and should not typecheck:

    // Bad
    myFunc(n : Int):
      foo = mkFoo(n)
      fooAlias = foo
      theNames = foo.names
      theAges = foo.ages
      ...
    // Good
    myFunc(n : Int):
      foo = mkFoo(n)
      fooAlias = foo
      theNames = fooAlias.names
      theAges = fooAlias.ages
      ...
    // Bad
    myFunc(n : Int):
      foo = mkFoo(n)
      names1 = fooAlias.names
      names2 = fooAlias.names
      ...

I have no desire to write a typechecker that can figure this out. So instead,
I think it is easier to use the classical approach for these types. Let's
say that we have a "boxed object" ADT and a "unboxed object" ADT. The unboxed
variant must have affine use regardless of its fields. Now we can define even
types like `Option`:

    // Note: We should be able to instantiate this type variable with boxed
    // and unboxed types.
    type Option a = unboxed { Some {value : a}, None }
    example(xs : Array Int):
      r = findNegativeNumber(xs)
      case r of
        None -> ...
        Some { value => v } -> ... v ...

It's a little restricting that we cannot scrutinize `r` twice even though
`Option` was applied to `Int` here. Actually, now that I think about, we need
to have the affinity of the fields bubble up to the unboxed type itself.
There is a common case involving arrays of keys and values:

    type KeyValueArray = Array (unboxed {Element {key : String, value : S64}})

Here, the unboxed type must be non-affine. Otherwise, we couldn't put it in
the array.
