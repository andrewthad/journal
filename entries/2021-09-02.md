# Type Reconstruction and Pointer Compression

If you want to compress pointers on a per-type basis (a 4GB slab for each
type), you must know the type of every object. Goldberg and Gloger's paper
Polymorphic Type Reconstruction for Garbage Collection without Tags outlines
a way to do this. The focus of the paper is eliminating the object-identifying
tags needed by most garbage collectors. However, it should be possible to
adapt this same approach to reconstruct full pointers to objects in a runtime
where only the offset is stored. The idea would be to store `Expr Foo` and
`Expr Bar` in the same slab but to figure out from context what types the
inner pointers have.

# Byte Arrays and Slicing

Interior pointers into byte arrays are useful. However, they degrade alignment
guarantees and make pointer compression less effective. You cannot do 32GB of byte
arrays if interior pointers are supported. You can only do 4GB. I am unsure
what the best solution is here. I guess that whether or not this is a problem
depends a lot on how much of your data is strings.

# Arrays Unpacked into Data Constructors

Interior pointers into data constructors are most commonly used to store arrays.
However, once you take the pointer to this array, you have lost the base pointer
to the object. We then have a full pointer to the array. We cannot ever throw
away the top bits of this pointer because there is no way to reconstruct it.
We cannot figure out what data constructor it was inside of.

One solution to this is making all array pointers 64 bits. A different solution
is to break up the array type into several different subtypes. One of these
could be a more primitive array type, always represented by 64 bits when
being manipulated, that cannot be stored inside of objects:

    data RawArray : Nat -> Type -> RawType
    data BTree a
      = Leaf (RawArray 8 String) (RawArray 8 a)
      | ...
    data Array a = Array (n : Nat) (RawArray n a)
    foldRawArray : (b -> a -> b) -> b -> RawArray a -> b
    offsetRawArray : Int -> RawArray a -> RawArray a

Crucially, we cannot instantiate a type variable `a` with `RawArray`.
Additionally, `RawArray` has unusual sharing properties. It must be
copied when it is pulled from one object to another. Also, functions
that create `RawArray` are all primitives. This is weird but somewhat
important to get right. Now, our `Array` type is able to be represented
by a 4-byte pointer. We can also take interior pointers into a `RawArray`,
safe in the knowledge that no one can install these pointers into any
other data structures. What we lose though is the ability to slice into arrays.
We need this:

    data Array a = Array (n : Nat) (RawArray n a)
    data ArraySlice a = ArraySlice
      (Array {n} a)
      (i : Nat | i < n) 
      (m : Nat | i + m < n) 

This is, of course, no better than GHC's representation of arrays. In fact,
it's the same exact thing except that we gain the power to put arrays
directly into data constructors. Which is not nothing. The type `Array`
is, of the three types, the least useful.

Now, let's do the same with byte arrays:

    data RawByteArray : Nat -> RawType
    data ByteArray = Array (n : Nat) (RawByteArray n)
    data ByteArraySlice = ByteArraySlice
      (ByteArray {n})
      (i : Nat | i < n) 
      (m : Nat | i + m < n) 

Space-wise, a `ByteArraySlice` adds two `Nat`s of overhead. Let's say that
these are just 4 bytes each and that we disallow massive (4GB) byte arrays.
So, when you use `ByteArraySlice`, you'll be using a pointer to a 12-byte
type, which has a `ByteArray` member that points to the actual array.
Since `ByteArray` is 8-byte aligned, we can have 32GB of them.

I really dislike the `ByteArraySlice` data type because of its poor use
of cache lines. It should be possible to unpack this into data constructors
in many situations.

# Recap

Why are we doing this again? The difficulty with true interior pointers
is that they allow you to install a pointer to the inside of one object
in another. If we want 32-bit pointers, then we have to be able to
reconstruct full pointers from offsets, and this means knowing what
slab each offset lives in. The solution proposed above was to disallow
type variables from being instantiated with raw types and to introduce
special primitives for building raw types (building and assigning to
a data constructor member happen simultaneously).

What we get from this is:

* The ability to store up to 32GB of byte arrays
* A principled way to unpack arrays into data constructors

# An arrow type for building raw types

When working with raw arrays, what should `cons` look like?

    cons : (a, RawArray a) -> RawArray a

This is a special type of function, one that creates a raw type. We do not
need to annotate the arrow because the specialness can be figured out just
by looking at the argument type's kind. Any application of a function like
this must be directly to the member of a data type. For example:

    addElement : Number -> Node -> Node
    addElement e n = Node
      { greatest = max(e, n.greatest)
      , values = cons(e, n.values)
      }

These can get trickier. For example, consider filtering in a monadic context
(only linear monads like state, reader, writer, exception):

    filter : (a ->{m} Bool) => RawArray a ->{m} RawArray a

This filter function should be able to handle any combination of these
effects. It must be able to deal with the possibility of GC during the
computation of the result. I think this is as simple as just relocating
the incomplete result to the new nursery. The one advantage we have
is the it's not possible for any object to refer to an incomplete object.
Only the stack can refer to an incomplete object, and only a single
place in the stack can do so. So, relocation should be easy.
