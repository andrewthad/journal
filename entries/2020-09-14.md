# Integers: Signed vs Unsigned and bit widths

Unsigned integers are best used as a "bucket of bits", and signed
integers are best used as numbers. Practically, what might this
mean:

* With refinement types, there is no need for `I8`, `I16`, etc.
  It is sufficient to have one signed 64-bit `Int` type with refinements
  (less than 256, less than 1000, etc.), and the bit width is just
  a space optimization when storing integers on the heap.
* Unsigned integers are needed for some kinds of arithmetic, like
  computing hashes that require multiplication. They can also be
  used for flags, although a good language/compiler should obsolete
  this use.

For example:

    data TimeOfDay =
      { hour : Int | >=0 && <24
      , minute : Int | >=0 && <60
      , second : Int | >=0 && <60
      , nanosecond : Int | >=0 && <1000000000
      }

If `TimeOfDay` is stored on the heap, the bit width of each field
can be chosen based on the refinements (e.g. hour can fit in an
8-bit integer). This only works when a data type is not polymorphic
in the field.

I think that follow C's footsteps and saying "signed arithmetic overflow
is UB" is the only approach that makes sense here. Unlike C, we can have
a more generous upper bound on signed numbers (`2^63`). But all the cool
proof-related stuff that refinement types can help with really needs
to assume no overflow. Basically any law concerning inequality needs
this. Consider:

* `x < x + 1`
* `x > 0 ==> (x * 2 > x)`
* `x >= 0 ==> (x * 2 >= x)`

None of these work when integers are a ring. The would all have additional
obscure qualifications, which I suspect would make them difficult to use.
