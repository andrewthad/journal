# Random Thoughts

* I wish that cabal featured a way to require the latest version of
  a dependency. This is nearly always what I want when I leave the bounds
  off of something, but cabal interprets this to mean "any version". There
  is no way to express "only the latest version".
* If higher-order functions are either disallowed or syntactically punished,
  a bidirectional type system might have an easier time with a lot of things.

# Existential Sugar

Let's check on some equivalences with existential types:

    forall a. (a -> Int)
    ===
    (exists a. a) -> Int

In GHC, we can only write the first one. In a language that supported
existentials, we could write the second one, but now we'd have two types
that mean the same thing. This is kind of bad. It gets worse if we allow
a braces syntax for variables that will be implicitly existentially
quantified if they are not specified. Consider:

    Vec {n} a // A vector of n elements
    Vec a // A vector of an unknown number of elements
    Vec a === (exists n. Vec {n} a)

So, the type signature of `sum` would be:

    sum : Vec Int -> Int
    ===
    sum : (exists n. Vec {n} Int) -> Int
    ===
    sum : forall n. Vec {n} Int -> Int

Universal quantification could possibly be restricted to prenex. What
about existential quantification? It has to be allowed on the RHS of
a function arrow. Any existential quantification on the LHS could be
converted to universal quantification. What about HOF?

    fold : forall a b. (b -> a -> b) ~> (Vec a, b) -> b
    ===
    fold : forall a b. (b -> a -> b) ~> (exists n. Vec {n} a, b) -> b
    ===
    fold : forall n a b. (b -> a -> b) ~> (Vec {n} a, b) -> b

If arguments always have types available, then a fully applied function
should not need annotations. For example, if the argument to `sum` has
type `Vec 5 Int`, then `n = 5`. Similarly, a function passed to `fold`
must synthesize a type, so:

    plus : Int -> Int -> Int
    fold @plus : forall n. (Vec {n} Int, Int) -> Int

This seems alright.

# Universal Hashing, 8 bits at a time

Most tricks to speed up universal hashing of strings involve pretending
that a sequence of 8-bit words is a sequence of 64-bit words. This is not
without problems. Notably:

* Alignment issues. Strings are often fragments of larger documents,
  so guaranteeing 8-byte (or 16-byte, 32-byte, or even 64-byte) alignment
  is not possible. Unaligned loads still cause performance penalties on all
  modern processors.
* Endianness issues. This is of less importance and can be resolved with a
  byte swap operation. If you want your hash function to have a well-defined
  behavior, you need to perform a byte swap operation on certain platforms.

One way to get around the alignment issues is to treat every byte as separate
but multiply them each by a 32-bit random number. On AVX512, there is no
operation for multiplying 16-bit or 8-bit numbers. You only get to choose
32-bit multiply or 64-bit multiply. If we load 16 1-byte words and then
zero-pad the result to a 64-byte register, then we multiply by our 4-byte
words. This is unsatisfying because will be 4 times slower than the state
of the art. Is does, however, not have any weird alignment or endianness
issues.

We really want to be able to handle a full 64 bytes at a time, not just
16 bytes at a time. Maybe there is a way to get multiply to work better.
The biggest problem is addressing unaligned input. AVX512 makes it possible
to mask out certain bytes, which helps.

      00 00 00 00 00 00 eb 31 
    x 57 f0 5c c3 a9 56 38 07
    -------------------------
      7a 29 5d e5 8e ef 26 57


      00 00 00 00 00 00 00 eb 
    x 57 f0 5c c3 a9 56 38 07
    -------------------------
      b9 a5 27 9c 72 25 6e 6d

The problem is that all remaining input will be shifted over and will end
up multiplied by different numbers. In particular, the `0x31` above would
end up being part of a different computation.

Why does multiplication work so well for this? It blends the bits of numbers
very well. An operation like xor does not have this property. How many ways
are there to permute 8 bits? It's 8 factorial, or 40320. That's a lot. There
is an old technique called tabulation hashing, where you treat each 8-bit
number as an index into a separate table, and the contents of each table
is random. If we are only trying to create an 8-bit output hash, then for
each input word, we would require a 256-byte table. That's terrible.

I think the solution is to just not care about alignment. I cannot see any
way to do better.

Actually, there is one simple option, but it would almost certainly harm
performance. You could store multiple copies of your random byte sequence,
each one aligned differently, and then choose which one to use based on
input alignment. That's going to kill cache though, so I don't think it's
worth considering further.
