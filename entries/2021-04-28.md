# Join Points and Functions

Consider this function:

    define foo : (Int,Int) -> Int as \(x,y) ->
      let z = calculation x 5
      let w =
        ( join finish (a : Int) = case a of
            60 -> z + y
            42 -> z + (12 * x)
            _ -> x
          in case z of
               12 -> finish (8 + x)
               14 -> finish y
               _ -> y + 2
        )
      let r = w + 55
      in r

This function is contrived, but it should help illustrate how join points
interact with scheduling. What are the basic blocks in this program?

1. A block for where `r` is calculated and `ret` is called.
2. Blocks 2a, 2b, and 2c, which all put something in the register
   that backs `r` and then jump to (1). Block 2H (pneumonic is "header")
   scrutinizes `a` and jumps to 2a, 2b, or 2c. Note that block 2H has
   multiple exit points, which might not be acceptable.
3. Blocks 3a and 3b, which both prepare an argument for `finish`
   and then jump to (2). Block 3c just prepares a result directly and then
   jumps to 1. Block 3H scrutinizes `z`. It has multiple exit points.
4. A block that calls `calculation` (doing any needed stack manipulation)
   and then jumps to 3H.

Since (4) always jumps to (3H), these will be coalesced when blocks are actually
scheduled. That is, the jump instruction will not actually appear in the
output assembly. (In fact, I shouldn't have even written these out as separate
blocks.) There are a few other opportunities for this kind of thing. One of the
jumps to (1) can avoid the `jmp` instruction, but which one it is depends on how
the blocks are ordered.

The question of multiple exit points is interesting. In most compilers, basic
blocks are forbidden from having multiple exit points. But this is only
done to facilitate analysis of the basic blocks. Such analysis should not
be necessary here since the primary purpose of these blocks is to avoid
committing to a total ordering before doing so is necessary. So, perhaps
what should be generated is basic blocks that contain assembly (either
x86-64 or some kind of generalized assembly) but that have one bonus
exit point instruction, case-on-int, that accepts multiple jump targets.
The lowering of case-on-int is decided a little later, but it should
have no impact on register allocation, so deferring this is ok.

It might also be desirable to have a loop-over-array construct as a special
kind of basic block. Again, the important question is "does this affect
register allocation". If it doesn't, then deferring the lowering of
such a block would be possible.

When should register allocation happen? How should spilling be accomodated?
The classical (simple) approach to register allocation is to assign a virtual
register to everything and then reuse a virtual register for something
that's dead. If your total number of virtual registers is less than your
number of physical registers (usually 16 or 32), then you do not need
to do any spilling. Cool. But, if you do need to do spilling, then
you're in a little more trouble. There's a different way to go about this
that might help.  What if each vreg is assigned to a stack slot instead of
a physical register? Now, the physical registers are a view into the stack.
You still have to figure out which stack slots should be loaded into
physical registers at any given point in time, but at least your count
of stack slots should be somewhat minimal. Also, since everything starts
out SSA, a spill of a value should only happen at most once. Loads
might be more common though. There is a question of where to perform
the spills though. They could happen immidiately after a variable is
declared and assigned, or they could be deferred. Deferring is certainly
better if the variable is only spilled in a single path. If it
is spilled in every path, then prompt spilling is better.

Perhaps the basic block representation should also abstract certain
stack operations. Then, certain spill questions could be answered
later. Specifically, deferring (sinking) spills could improve performance
when a spill was moved into another uncommonly-traverse block. It would
be nice to do this in later pass though.

Maybe it is best to do spill stuff on a per-block basis. But making a
good decision about what to evict requires looking at all successor
blocks and knowing which ones are likely. There are things that can
help figure out which successors are likely:

* Explicit looping construct
* Recursive join point is likely to take path that recurses
* User-provided annotations about most likely case arm to be taken

This doesn't seem too terrible. How many phases should actually be
needed for this kind of thing though? We must start with some kind
of ANF-with-case-and-join-points representation. From there, we
need to move to basic blocks at some point and then schedule the
blocks to produce actual assembly. So, three phases:

* ANF
    - Let-bound expressions are partially ordered.
    - Heap pointer is implicit
* Basic Blocks with Abstraction (Like hoopl+cmm, ordered, explicit heap)
    - Join point blocks have arguments
    - Has case-on-int multiple exit points
    - Abstracts stack to make sinking spills easy
    - Instructions within basic block are ordered 
    - Heap pointer is explicit (main difference from ANF)
    - Writes to header words in allocations are tracked
      (these may raise SIGSEGV, handled by either userfaultd or
      traditional signal handler). We must know what is live at
      each initialization site.
* Basic Blocks Lowered
    - Stack is explicit but still special (we know that function calls
      will preserve it, for example)
    - Registers are decided
    - Still has case-on-int multiple exit points
    - Still needs to have blocks scheduled (eliminates a few jumps)
* Assembly (x86-64, etc.)

Let's think about when to perform certain operations:

* Most optimization: ANF
* Virtual register allocation: Basic Blocks with Abstraction or
  perhaps interleave with lowering from ANF to Basic Blocks with Abstraction.
  Note that this refers to choosing stack slots.
* Register allocation: Maps each stack slot to a physical register at
  every point in the program. Do this on Basic Blocks with Abstraction.
* Sinking Spills across block boundaries: Basic Blocks Lowered

Really, ANF and Basic Blocks with Abstraction are starting to feel
very similar. The main issue is ordering. Calculating interference
requires a total order. So, we have to commit to a total order before
we pick stack slots, or we have to do it simultaneously. The obvious
heuristic here is "minimize the amount of time any value is live".
It's probably easier to pick a total order first. Interleaving
makes it possible to do clever things with simultanous initialization
of multiple allocated constructors.
