# Request Oriented Collection and Bump Allocation Rollbacks

What if you could just roll back a bump allocator's heap pointer at
certain points in time? In a language that severely restricts mutation
and inter-thread communication, you can do this. Let's say that you
have some top-level function `handleRequest :: Socket -> Foo -> IO ()`.
Since `handleRequest` is top-level, it cannot close over any other
variables. The only things it can see are its two arguments. Equally
important is that, since mutation is restricted, it is not possible
for `handleRequest` to allocate something in the nursery and then
make a mutable reference point to it. Maybe the top-level thing is not
actually that important here. But anyway, after calling `handleRequest`,
it is safe to roll back the heap pointer as long as a collection has
not occurred since `handleRequest` started running. In practice, what
this means is that the generated code for `handleRequest` would look
like this (using C pseudocode):

    void handleRequest(int socket, void* foo){
      void* heap0 = getHeapPtr();
      int collections0 = getTotalCollections();
      handleRequestGo(socket, foo);
      int collections1 = getTotalCollections();
      if(collections0 == collections1) {
        setHeapPtr(heap0);
      }
    }

Pretty cool. This actually works even if the `IO` action returns something
other than unit. As long as the return type does not have anything boxed
in it, this optimization is valid. One important question is "where should
we actually do this?" since it might not make sense to do this on every
single IO function. At the least, we do not want to do this to IO functions
that are known to not allocate anything.

This is a natural thing to do when we are working in `IO` because the
nature of request handling is read-process-write, and after writing (to
a socket or to disk or wherever), you are usually left with a unit value.
But non-effectful code never returns unit. Let's consider parsing JSON
and then doing some analysis on the result:

    decode : Bytes -> Maybe Value
    parse : Value -> Maybe Foo
    analyze : Foo -> Stats
    pipeline : Bytes -> Maybe Stats
    pipeline a =
      let b = decode a in case b of
        Nothing -> Nothing
        Just c -> case parse c of
          Nothing -> Nothing
          Just d -> let e = analyze d in
            Just e

Here, `pipeline` is written out verbosely to help think about where rollbacks
might be possible. The tricky thing is that only subcomputations with an
entirely unboxed result type are eligible for some kind of heap pointer
rollback. So, for example, if `Foo` is an unboxed type, then the expression
`decode >=> parse` would allow a rollback to happen. But this is unlikely
to be the case. It is likely that `Foo` is boxed.

What about giving the user some amount of control here? For example, if
`Foo` only uses a small subset of the data in the JSON file, it may be
prudent to force a micro-copying-collection. Whether or not this is
advantageous is very application specific:

* Advantage: Nursery GC is delayed. Better use of L1 and L2 cache since
  recently used memory will be used again. Makes the heap feel more stack-like.
* Disadvantage: We are copying a value that was not going to survive the
  next collection.

My gut feeling is that such a micro-collection would only improve performance
in cases where a very small subset of the total data was being copied out.
Also, it couldn't be copied into the normal nursery because then you would
be overriding the memory that you were copying from. It would need to go
into a separate auxiliary region. The user would need to explicitly request
this behavior.

On auxiliary nursery regions. This are needed to support mutable memory that
might get frozen. I spy a problem here though. These auxiliary regions
would make rollback trickier since there would effectively be multiple
nurseries, each of which would need to be potentially rolled back. This
is a problem since it makes the whole rollback mechanism more expensive.
Rather than just pushing the collection count and the heap pointer onto the
stack, we now have to push a variable amount of data onto the stack. This is
the case even in the `IO` variant of the nursery rollback.

Maybe it is not so dire. Consider that every frozen mutable region can
actually be described by when it was created:

    Heap: -----*-------*--------*-----*---*-------------------------
               ^       ^        ^     ^   ^
               A      Old       B     C  Now

If we are trying to roll back from "Now" to "Old", several things help
us out:

* `A` cannot point to anything past `Old`. Even if `A` is not yet frozen,
  the rollback primitive would not support running in `ST`.
* `B` and `C` are definitely frozen. They may even be next to one another
  if `B` was frozen before `C` was created.

So it is a little tricky, but it is not too bad. Basically, every mutable
region that was created after heap position `Old` would be guaranteed
to be frozen and could be deleted without inspection. With this in mind,
let's revisit an earlier claim about the `IO` variant of this. It is
actually very important that the expression be top level. Otherwise, a
mutable region could be in scope and could point forward. In non-effectful
code, we do not have to worry about this because we cannot mutate. Let's
revisit the C code again with freezable regions in mind:

    void* parseAndDecode(void* bytes){
      void* heap0 = getHeapPtr();
      int regionIndex = getLowestAvailableRegionStackIndex();
      int regionTop = getHighestRegionPosition();
      int positions[n] = slice(regionPositions,regionIndex,regionTop); // Requires C VLAs
      int collections0 = getTotalCollections();
      void* result = parseAndDecodeGo(bytes);
      int collections1 = getTotalCollections();
      if(collections0 == collections1) {
        // traceAndCopy does not copy older memory. Also, for a non-boxed
        // result, tracing would not be needed.
        copiedResult = traceAndCopy(result,heap0); 
        restoreRegionPositions(regionIndex,positions);
        setHeapPtr(heap0);
      } else {
        return result;
      }
    }

Here is how mutable regions are supposed to work. Every nursery needs a stack
of regions. If the one on the top is frozen, you can reuse it starting at the
end of it. Otherwise, you have to request a new one and it gets pushed onto
the stack. This makes since because `runST` requires nesting. Actually, it
is not quite a stack, but it's close. You need to go down as many levels as
are immutable to pick out the region you are using for mutation. Everything
in all of these regions (frozen or not) is part of the nursery.

This introduces considerable complication. Rolling back is a bit more expensive.
If the number of regions was hard-coded (say, to something like 128), this would
perhaps be a little less bearable. Going that 128 levels down into nested `runST`
would be uncommon, but it would be a bummer to have your JSON parser crash if you
got some input with a deeply nested map or array. I'm just not sure what the
right thing to do here is. History compels me to believe that local mutation is
important. The rollback stuff is more of a novelty, but I'm curious about the
kind of impact it could have in immutable languages. But it does not seem to
play super nicely with local mutation. Local mutation makes it a little more
expensive, but maybe that extra cost is not actually all too bad. The extra
bookkeeping is all very cache coherent. Would the benefit of getting to reuse
that 20KB of memory be worth the cost of tracing and restoring region
positions? It just might be.

One thing I did not address. Where does `traceAndCopy` actually copy the
memory? It cannot use the nursery proper. And it cannot use any of the regions
since it might need to inspect them. I believe that the bookkeeping would
actually need to go ahead and reserve the lowest frozen region on the stack
prior to running `parseAndDecodeGo`. It would reserve it by marking it as
mutable. Then, the memory could be copied to this region, which would
be marked as frozen again after the copy was complete.
