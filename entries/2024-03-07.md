# Think Through Second-Class Values

## Extending with Let Bindings

Here is how let bindings desugar:

    let x = y in z
    ==>
    (\x -> z) y

This suggests that constructs producing a second-class result should be
admissible as the RHS. For example:

    let x = case k of { ... } in z

The arms of the case statement may return second-class values.

## Binding Allocated Mutable Arrays

Going one step further, we may have a bind construct which is like let
but for sequenced operations (requiring mutation). For example:

    bind a <= read(myMutableArray, 0)
    bind b <= read(myMutableArray, 0)

Mutable arrays are always second class. Ordinarily, a function cannot
return a second-class value. However, it appears to be sound for the
result of array allocation to be mutable:

    newArray : (Int, a) => MutableArray* a
    ---
    bind myArrA <= newArray 100 elemA
    bind myArrB <= newArray 50 elemB

These arrays cannot ever be frozen. But this way of allocating them is
syntactically more lightweight than using a bracketing construct. 

    withMutableArray(100,elemA)(myArrA):
      withMutableArray(100,elemB)(myArrB):
        ...

Perhaps the rule is simply that a sequenced function is allowed to return
a second-class value. Or maybe first-class mutable arrays should exist.
This way, we would have:

    newMutable   : (Int, a)                          => MutableArray a
    newImmutable : (Int, a, MutableArray* a => Unit) -> Array a

A first-class mutable array cannot be frozen since its lifetime is
not tracked by the type system. I am not sure how I feel about this
solution. It is simple, but it means that mutable arrays could appear
as object fields and as type-variable instantiations. This makes the
runtime more complicated.

## Second-Class Integers

Primitive types like integers have strange behaviors in this system just like
they do in Linear Haskell. Let's say that we write first-class integers as
`Int` and second-class integers as `Int*`. Suppose that addition is typed:

    add : Function(Int*, Int*)(Int)

This means that the second-class restriction on any integer `x` is trivially
subverted by

    add(x,0)

We could fix this by making `add` accept only first-class integers. But it's
worth consider what the purpose of this is. Consider an implementation of
UNIX file operations that hides the representation of file descriptors:

    signature Unix {
      type Fd
      -- | Takes a path and a callback as arguments.
      withFile : (Array* U8, Fd* => a) => a
    } 

This signature ultimately gets filled in with `Fd = Int32` on most systems.
But anyone using this signature cannot access that. Since the user has no
access to any operations on file descriptors (like `add`), they cannot
subvert the restriction. An implementation of `withFile` make ignore the
restriction:

    module UnixImpl {
      type Fd = Int
      withFile = function (path : Array* U8, callback : Int* => a)(a) {
        bind fd <= posixOpen(path)
        // Note: fd is a first-class Int, but we can pass it to the callback
        // because of subtyping.
        bind result <= callback(fd)
        bind _ <= posixClose(fd)
        pure result
      }

In fact, we can build `withFile` even without knowing the concrete type
backing `Fd`. We just need a `posixOpen` and `posixClose`.

Whenever `Int` appears as a function argument, there is no difference
between it being first-class and second-class. If it is first-class,
then we get a second-class integer from it because of subtyping. But if
it is second class, we can add zero to it to get a first-class version.
For this reason, I think that the convention should be to always use
first-class integers. And primops should require them except for a single
primop used to recover a first-class integer:

    replicate : Function(Int, a)(Array a)
    add       : Function(Int, Int)(Int)
    cast      : Function(Int*)(Int)

## Second-Class Constructed Objects

User-defined ADTs should be treated like integers are. There is no value
in a second-class version of a type that the user to can "see into".
If there was a second-class Widget, the user could just project out all
of the fields and rebuild it as a first-class Widget.

Really, the whole thing is only useful for situations where the type
is sufficiently opaque. This includes:

* Mutable arrays (freezing and borrowing)
* Opaque types (from module signatures)

## Types for Primops

Consider this example:

    linuxReadFile : Function(S32*)(Array U8) = ... builtin ...
    module UnixImpl {
      type Fd = S32
      readFile : Function (Fd*)(Array U8) = linuxReadFile
    }

If the builtin `linuxReadFile` required the file descriptor to be first-class,
then we could not use it as an implementation of `readFile`. So we should
probably just use second-class integers as all primop arguments. It might
be beneficial to just default all function arguments to second class and
have a special syntax for first class. No, that doesn't work right. Boxed
data typically needs to be first class so that it can be embedded in other
boxed data. So we kind of want a different default for different types.
We could have:

* Arguments with numeric types default to second class
* Arguments with boxed types default to first class
* Arguments with mutable or immutable array types default to
  second class (they usually do not escape)
* Arguments with struct-like unboxed types (Option, Result) default to
  second class

Actually, it seems like second class is just pretty common. Maybe simplify
and make this the default for everything.

## Inhibiting Optimization

Consider:

    function(p : Person*)(Person) {
      case p of
        Person age name -> Person age name
    }
      
In a language without second-class types, a trivial optimization is to make
this return `p`. However, here we cannot do this. We have to allocate space
for a new person and then copy the fields into it. Or, perhaps, maybe we
could do this:

    function(p : Person*)(Person) {
      toFirstClass(p)
    }

Where `toFirstClass` is a no-op. We can do the same thing for numbers too.
We cannot do this for arrays (mutable or immutable) because then they
could escape. It would be nice if there was a typing rule that said
"if a second-class value has certain types, we can use it as though
it were first class". Maybe the way to do this is to say that only certain
types even support a class distinction: variables and arrays. Let's try
this out:

    linuxReadFile : Function!(S32)(Array U8) = ... builtin ...
    module UnixImpl {
      read : Function!(S32)(Array U8) = linuxReadFile
    }
    functor
      (Fd : Type)
      (unix : Module
        { read : Function!(Fd*)(Array U8)
        , open : Function!(Array* U8)(Fd) 
        , close : Function!(Fd)(Unit)
        }
      )
      { withFile = function[a](path : Array U8, callback : Function!(Fd*)(a))
        { fd <= open(path)
        ; r <= callback(fd)
        ; _ <= close(fd)
        ; pure r
        }
      // Program entrypoint
      ; function!()(Unit)
        { withFile("foo.txt"){f}:
          { data <= read(f)
          ; ...
          }
        }
      }
    }

Here, the type signature of the `unix` functions is cleverly designed so
that downstream users can build bracketed functions on top of them. If we
instantiate `functor` with `S32`, the type required of the `unix` module
is weakened to 

    Module
      { read : Function!(S32)(Array U8)
      , open : Function!(Array* U8)(S32) 
      , close : Function!(S32)(Unit)
      }

And now the linux implementation of `read` has the right type. I don't
particularly like this extension to the second-class type system though.
It is more simple to treat every type the same way. Unfortunately, it
just doesn't actually make sense to distinguish between first-class values
and second-class values for certain types.

# Tags for Search

tag: secondclassint
