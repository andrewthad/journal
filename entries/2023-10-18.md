# Passing Modules Around

For certain uses of module functors, it seems to make the
most sense to package up a ton of functions together. For
others, it feels like it makes more sense to just pass
modules around. Packaging up tons of functions is better for:

* Ordered maps
* Finger trees
* Data types where the representation is either hidden or is
  so difficult to use that no one will use it.

Passing modules around as arguments to functions works
better for:

* Monad/Applicative/Functor
* Foldable
* Traversable

For example, when building an ordered map type, it makes
sense to have this:

    functor MapFunctor (ord : Ordering) where
      type Key = Ord.T
      data Map : * -> * where ...
      singleton : Key -> a -> Map a
      insert : Key -> a -> Map a -> Map a
      updateM : (m : Monad)
        => Key -> (a -> m.M a) -> Map a -> m.M (Map a)
      equal : (eq : Eq)
        => Map eq.T -> Map eq.T -> Bool

Putting the update function in a separate module would be a pain.
It's better to just have it there with everything else where we
can find it. The alternative would be doing this:

    functor MapFunctor (ord : Ordering) where
      type Key = Ord.T
      data Map : * -> * where ...
      singleton : Key -> a -> Map a
      insert : Key -> a -> Map a -> Map a
      functor MapM (m : Monad) where
        updateM : Key -> (a -> m.M a) -> Map a -> m.M (Map a)
      functor MapEq (eq : Eq) where
        equal : Map eq.T -> Map eq.T -> Bool

This works, but it's inconvenient. It is weird to group various functions
inside of `Map` just based on their module arguments. It is more natural
to make these arguments of the function. Additionally, it should be
possible to use some form of modular implicits with the first one:

    textMap := MapFunctor(textOrdering)
    x := textMap.singleton("hello",55)
    y <= textMap.updateM{@IO}
      ( "hello"
      , \n -> print(n); pure (n + 1);
      , x
      )

The at-sign symbol means "use the default instance for IO where m.M = IO".
In this case it's not that helpful because we are not able to infer `m.M`
from context. Maybe we could though. It just depends on how clever the
type system is.

# Module Functor Instantiation Inside Functions

If we allow passing modules to functions, then we need to also make it
possible to instantiate module functors inside a function:

    findMax : (ord : Ordering) => [ord.T] -> ord.T
    findMax{ord}(xs) =
      set := Set(ord)
      ys := set.fromList(xs)
      ...

The only restriction is that we have to do all the module functor instantiation
upfront. There is nothing computed in the function's that can be passed to the
module functor anyway. In fact, the whole thing could be elaborated to
a system that doesn't let you pass modules to functions:

    functor FindMax (ord : Ordering) where
      set = Set(ord)
      func : [ord.T] -> ord.T
      func(xs) =
        ys := set.fromList(xs)
        ...

Maybe we just need syntactic sugar for using the `FindMax` module functor
without having it feel like you are instantiating a module functor.

# Related Work

In the Modular Type Classes paper, I found this:

> Under the Harper-Stone interpretation of Standard ML (hereafter,
> HS) [9], polymorphic functions in the external (source) language
> are elaborated into functors in an internal module type system.
> Specifically, a polymorphic value is viewed as a functor that takes
> a module consisting only of type components (representing the
> polymorphic type variables) as its argument and returns a module
> consisting of a single value component as its result.

This is a fascinating interpretation of SML. You get to lower polymorphism to
modules. For example:

    identity : forall (a : *). a -> a
    ==>
    functor identity(a : *) where
      [[ a -> a ]]

The double brackets means that the module of the module functor is a single
definition. Because of that, it doesn't get a name. This notation is borrowed
from the paper. If we do this kind of thing, then class constraints are
handled as I suggested earlier in the post today:

    nub : forall (a : *). Eq a => a -> a
    ==>
    functor num(a : *)(eq : Eq where eq.t = a) where
      [[ List a -> List a ]]

Some questions I have:

* How does interact with strategies for runtime representation polymorphism?
  Can we get a single lowering for all boxed types?
* What about the interaction with subtyping and refinements?
* Not directly related to this, but I find the `using` construct in the paper
  unsatisfying. Nonmodular, canonical instances, like what Haskell does, are
  what I really want. It's nice to have a mechanism for building instances
  by hand, and that's what I like about the paper. But having the behavior
  of implicits be governed by a `using` clause makes them less predicatable.
  I want to define a signature `Eq` and then say "here's the instance for
  `Int`, and the same one is the default everywhere".
  
