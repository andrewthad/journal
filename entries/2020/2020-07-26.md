# ANF Lambda Calculus to LLVM

I played around with trying to compile ANF lambda calculus to LLVM today.
These are a few observations.

I think that LLVM support multiple return values from functions, but it
is not documented clearly. In the LLVM 2.3 release notes, there is a
mention of a `getresult` function. This was later replaced by
`extractvalue`. I think the way to return multiple values is to return
a struct and then call `extractvalue` on it.

Wikipedia describes ANF as:

    EXP ::= VAL 
          | let VAR = VAL in EXP
          | let VAR = VAL VAL in EXP
    VAL ::= VAR
          | Î» VAR . EXP   // Note: not present in my language.

In the toy language I was playing around with, lambda abstraction is
not possible at this stage. To me, the big unknown here is how `case`
should be added. It certainly cannot be added to `VAL` because that
would imply that a function could be applied to an unknown. What about
adding it to `EXP`? That's a problem because then we cannot actually
bind a variable to the result of a `case` expression. What I want is
something like this:

    data Expr
      = Val Value
      | Let Ident Assignment Expr
    data Value
      = Literal ...
      | Constant ...
    data Assignment
      = Application Function [Value]
      | CaseInt
          Value -- scrutinee
          Expr -- default
          [Alternative] -- alternatives
    data Alternative = Alternative
      Int -- pattern
      Expr -- arm

Functions can be applied only to values and literals. Similarly, only
values and literals can be scrutinized. Scrutinizing a literal is
ridiculous and should never really be happening since optimizations
should have already simplified that, but allowing it should not hurt
and I think LLVM allows you to `switch` on a constant.

There is a problem with this. We would like to be able to end an
expression by casing (without naming the result of the case expression).
At the moment, the only issue is that the generated LLVM IR incurs an
unneeded phi node, something that probably gets optimized away. It makes
the generated IR more difficult to read (for a human) than it needs to
be. A bigger problem is that join points, once added, will be incorrect.
Let's look at what GHC does (STG is in ANF). Here are some of the data
types and constructors from `compiler/GHC/Stg/Syntax.hs`.

    data StgArg
      = StgVarArg  Id
      | StgLitArg  Literal
    data GenStgExpr pass
      = StgApp
          Id       -- function
          [StgArg] -- arguments; may be empty
      | StgLit      Literal
      ...
      | StgCase
            (GenStgExpr pass) -- the thing to examine
            (BinderP pass) -- binds the result of evaluating the scrutinee
            AltType
            [GenStgAlt pass]
                        -- The DEFAULT case is always *first*
                        -- if it is there at all
      ...
      | StgLet
            (XLet pass)
            (GenStgBinding pass)    -- right hand sides (see below)
            (GenStgExpr pass)       -- body
  
      | StgLetNoEscape
            (XLetNoEscape pass)
            (GenStgBinding pass)    -- right hand sides (see below)
            (GenStgExpr pass)       -- body

In the full source, GHC includes a large note titled
`GenStgExpr: let(rec)-expressions`. This is worth reading. Also, the
`StgLetNoEscape` data constructor is used for
[joint points](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/join-points-pldi17.pdf).
Notably, GHC's construction does not prevent expressions like this:

    let x = (let y = ... in w) in z

Ideally, this should always be rewritten to:

    let y = ... in z[x/w]

I'm not sure about that notation, but it means "replace every occurence of
`x` with `w` in `z`". If we do not prevent this in the syntax tree, we
need to make sure there is a good way to compile it. I suspect that there
is, but I need to think about it more.

# Thoughts About Targetting LLVM.

LLVM IR needs types written everywhere in an unusually verbose way.
Before compilling to LLVM IR, it would be prudent to decorate the syntax
tree with types. That way, you do not have to look variables up in a
context while compiling. Effectively, such a decoration would split
a complicated single-pass algorithm into a more simple two-pass algorithm.

Casing on the RHS of a let binding is accomplished with LLVM phi nodes.
For example, consider:

    let x = ( case y of
                True -> ...
                False -> ...
            ) in
    let z = x + x

Here, `z` must begin a new block, and the block needs to start with a phi
node to check whether it came from the True arm or the False arm. I think
that it is easiest to generate the blocks for the case arms first, additionally
returning the (unique) identifiers corresponing to the results in each arm.
I do not think that LLVM has a way to just assign a new identifier to an
existing one. I could be wrong though. Even if there is a way, it is less
verbose to just reuse the identifiers from the blocks rather than attempting
to make them more uniform. So we want something like this:

    toBlocks :: Expr -> [(Block,[Variable])]

Note that the result identifier is actually a list. This is needed since
tuples can be returned. We actually need a slightly different way to
invoke this that creates blocks that have LLVM `ret` instructions instead
of just assigning result to identifiers:

    toBlocksRet :: Expr -> [Block]

Finally, I'd like to have a better way to come up with LLVM identifiers. The
easiest option is just to have an incrementing number, but if you do that,
the generated IR does not resemble the expression it was built from. I'd
like to try to do something where you just add an incrementing number to
the original identifiers. Something like this:

    // In LLVM IR, x becomes x.8.
    let x = ( case y of
                True  -> let p = 1 + q  // p.6
                          in p
                False -> let p = q * q  // p.7
                          in p
            ) in
    let z = x + x  // z.9

So now we would have numbers to make sure everything is actually unique, but
we would also have human-readable identifiers to make things easier to debug.

Also, the GRIN project compiles a lambda calculus to LLVM. It is worth looking
at how they do it there.
