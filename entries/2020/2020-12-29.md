# Monomorphization and Tagless Garbage Collection

In Benjamin Goldberg's Incremental Garbage Collection Without Tags,
he lays out a way to perform tagless GC in the presence of polymorphism.
One very different approach would just be to aggresively monomorphize
a program. That means that if a polymorphic function were instantiated
at several different boxed types, there would be one copy of essentially
identical code for each boxed type. This is wasteful but perhaps not
as wasteful as it might seem. Polymorphic code tends to be small functions
that are usually inlined anyway. Such a system would need to accept the
restrict that higher-rank polymorphism is forbidden.

In this hypothetical system, it might even be possible to do away with
user-facing kinds. However, supporting SIMD properly nudges us in the
direction of keeping a kind system. What should it look like? Maybe
we can preserve the "one specialization per representation" property.

    data Rep
      = Basic Atom
      | Vec Count Atom
      | Tuple (List Rep)
      | Sum (List Rep)
    data Atom
      = Word Size   -- 8, 16, 32, 64
      | Bytes
      | Box ?     -- The ? is an open type, one constructor per data type

What kind of types signatures would this lead to in programs:

    findPerson : PersonId -> List Person -> Option Person
    reverse : rep %a. forall (a : %a). List a -> List a
    reversePeople : List Person -> List Person
    reversePeople = reverse @%(Basic Person) @Person

    Person : Basic %Person
    PersonId : Basic (Word 64)

The idea here is that it is possible to recover sharing for functions
polymorphic over integral types. For example:

    IntSet : Basic (Word 64) -> Basic %IntSet
    member : forall (a : Basic (Word 64)). IntSet a -> a -> Bool

However, the similar `IntMap` type would suffer greatly (concerning codegen)
since it would need a copy of all function per boxed element type that it
was used with.

# Explicit Polymorphism

Let's consider a different approach. What about just passing types around at
runtime in an application every time a polymorphic function is used. This is
similar to Olle Fredriksson's [sixten](https://github.com/ollef/sixten)
project. In `sixten`, you pass around sizes at runtime. For example, consider:

    map : (a -> b) -> List a -> List b

At runtime, this function takes four arguments: the size of `a`, the size of `b`,
the function, and the list. What I'm thinking about is a different from this.
I want boxed and unboxed types to be treated completely differently, but boxed
types imply an extra argument. Here's the same example but in the system I'm
describing:

    map : rep %a %b.
      forall (a : %a) (b : %b). (a -> b) -> List a -> List b
    map @[%a = Basic (Word 64), %b = Basic Box] :
      forall (a : Basic (Word 64)) (b : Basic Box). (a -> b) -> List a -> List b
    map @[%a = Basic Box, %b = Basic Box] :
      forall (a : Basic Box) (b : Basic Box). (a -> b) -> List a -> List b

The first function is essentially a template. It makes use of representation
polymorphism, so it is impossible to generate code for it. The second function
is a specialization. Since `b` is a `Box`, it is passed in at runtime. That is,
there are three arguments to this specialization of `map`. The third function,
another specialization of `map`, takes four arguments at runtime.

There are several important questions that must be answered:

* How can type constructors be implemented? We must somehow combine all
  of the type arguments into a single word. This must be cheap.
* How does subtyping of polymorphic functions work? For example, we
  cannot have `(∀(a : Basic Box). a -> Nat) ≤ (Foo -> Nat)` since
  the function on the left takes two arguments at runtime and the
  function on the right takes only one.

The second problem does not seem terribly difficult to solve. It should
be possible to η-expand terms to make things work out. For example:

    foo : forall (a : Basic Box). a -> Nat
    bar : (Foo -> Nat) -> Nat
    baz : forall (a : Basic Box). (a -> Nat) -> Nat

    bar foo
    ==>
    bar (\x -> foo @Foo x)

    baz @A foo
    ==>
    baz @A (\x -> foo @A x)

Passing a polymorphic function as an argument ends up creating a
closure for the argument. This is unfortunate, but it seems unlikely to
lead to performance issues in most programs. The functions that will
suffer will be `id`, `const`, etc. However, passing these as arguments
to functions is seldom necessary. And also, it is possible for the
compiler to generate specializations of `id` since the implementation
is tiny.

The second problem (type constructors) seems more difficult. In the
presence of polymorphic recursion, there are an infinite number of
types that may appear in a program, and I would like to support polymorphic
recursion if possible. Let's say that there are 2^16 ground types and 2^8
unary type constructors. If we didn't have type constructors, it would be
easy. But the runtime representation of type constructors need to take
the argument and then shove 8 bits representing the type constructor on
the end. We might try to accomplish this by bitshifting the argument and
then ORing it with the type constructor's bit pattern. But what do we
do when we run out of bits? (With polymorphic recursion, we will
definitely run out of bits.) It's worth mentioning that Goldberg does not
have to deal with this problem in Polymorphic Type Reconstruction because
his system does not pass types around on the stack explicitly. However,
his system encounters a serious implementation difficulty detailed in
section 6 of the paper. Plus, it has some trickiness around walking up
the stack far enough to figure out the types of everything. I'm trying
to trade stack space in exchange for an easier implementation, but this
problem with composing type representations is gnarly.

One possible solution is a type stack. All ground types are constants.
Applications of type constructors push a description of the application
onto the type stack. Let us assume (foolishly perhaps) that there are
at most 2^16 types. Let's say that we call `map` with two boxed ground
types: `Foo` and `Bar`. We do not have to push anything onto the type
stack. The numbers for `Foo` and `Bar` are passed are arguments to `map`.
But what if instead we pushed a type like `List a` (where `a` was an
argument we ourselves received) to `map`. We must push `Apply1-List-a`
onto the type stack and then feed its index into `map` as the type
we are passing. It is possible to integrate the type stack with the
normal stack (resulting in 64-bit pointers rather than 16-bit indices):

    myFunc(typedescr* aTy, void* a) {
      listOfBox* myList = buildListOfA(...);
      typecon1 listOfATy;
      listOfATy.ctor = listTy;
      listOfATy.arg1 = aTy;
      map(fooTy,&listOfATy,someClosure,myList);
    }

Everything being a pointer rather than an index makes these bigger than
they would otherwise be. And it makes PIE harder since the pointers for
ground types are not actually known at compile time. So indices rather
than pointers is probably the way to go. Also, keep in mind that the compiler
could figure out lots of constant types (e.g. `List Baz`) at compile time
and go ahead and build them in the constant area. It would be awesome if
it were possible to get by with 16-bit integers here, but I suspect that
will not be possible. I think what will actually need to happen is that
everything is 32 bits. The bottom of the type stack is all the stuff
known at compile time (`Foo`, `Bar`, `Apply1-List-Foo`), and then you
start out right above that. So the constant stuff is actually part of
the stack and is referenced in the same way that everything else is.
Since the language I envision does not support higher-kinded types,
type constructors would live somewhere else, not in type stack, since
they are not really the same kind of thing. (You cannot pass a type
constructor to a function.) Ultimately, all ground types are pointers
to some other table that describes, for each data constructor, how their
fields are laid out. Type constructors work exactly the same way.

That seems like a satisfactory solution. Now let's get back to the bigger
picture. Representation polymorphism means that it is possible for multiple
copies of functions and data types to be produced. In particular, specializing
a function with `Basic (Word 64)` and with `Basic Box` results in different
copies of a functions existing. The boxed variant will end up taking an
extra argument (a type description), but the word variant will not. This
is because the garbage collector does not need to know what newtyping we
have done to a word. It's just going to ignore the value regardless.
At some point in the compilation pipeline (after monomorphization of
representations), we need to drop all type lambdas for word-like types,
replacing them all with a single `Word` type (or with one of the `Word 64/32/16/8`
types). At this point, all type variables will have kind `Box`.
