# Thoughts on Ponylang and Rust and Actors

Today, I read a description of the actor model, and what problem it
solves, that I understood. It is
from Jessica Hilbert's
[A Comparison of the Capability Systems of Encore, Pony and Rust](http://uu.diva-portal.org/smash/get/diva2:1363822/FULLTEXT01.pdf):

> The actor model uses actors as the universal primitive. An actor is
> an encapsulated object with their own memory storage and thread.
> Actors communicate with each other through asynchronous message passing.
> The actor has a mailbox and reads potential messages which may not be
> the order they were sent. In this model there is no need to use mutex
> locks, because the actor has full control over its own memory, and what
> to do with the data when it receives a message.

Splendid. This is succinct and clearly explains the whole purpose of actors
moreso than anything I've ever read. After reading this, I took a look at
ponylang, a niche language that puts the actor model at the center of
everything. After reading through the documentation and some of the standard
library, I'm convinced that this is a good way to solve certain kinds of
problems, but I'm unconvinced that it is something that needs to be at
the forefront of a language in the way Pony has it. Why? Two reasons:

1. Many applications do not need concurrency. Very few libraries need
   concurrency. Actors solve a problem that only exists in a concurrent
   setting.
2. Pony takes very object-oriented (rather than data-oriented) approach
   to structuring things. I suspect that this is done because actors are
   objects. (I fully believe that actors really are best represented as
   objects.) Look at files like
   [`json_type.pony`](https://stdlib.ponylang.io/src/json/json_type), and
   you see goofy classes like `JsonArray`. My understand is that functions
   must live in classes rather than existing at the top level in a package.
   I'm not sure if this is essential to Pony or not, but it's not the way
   I prefer to see vanilla data-to-data transformations packaged.

Still, there is something about the whole experiment that I enjoy. It's
a weird take on the whole uniqueness/linearity question. Linear Haskell, Idris,
Rust, and Pony all seem to have some really different ideas here. In Rust,
the way to share is to guard access with a `Mutex`. The manual discourages
this with "do not communicate by sharing memory", recommending message-passing
when possible. In Pony, you can pass an `iso` over to another actor (another
thread), which is cool, but I'm not sure how often I would prefer passing
over a scarce resource to message passing.

My typical uses for mutation are:

* Build a small structure, probably from a list, and then freeze it. This is
  local mutation done as a performance enhancement. GHC calls this `ST`.
* Build a small structure, using it as it is built to perform some other task,
  and then discard it. Also accomplished by GHC's `ST`.
* Build a large structure (several GBs) that stays live over the course of an
  entire application. This structure may grow and shrink over time. It is
  only used linearly. Such a structure does not need to be traced for garbage
  collection since it handles its own deallocations.

The first two are not hard to deal with in an ML-family language. It's the
third class that's the bear. If you tried to build that with GHC's primitives,
you find the the garbage collector often scanned the entire object. Rust
could handle this kind of data extremely well. I'm not sure what Pony would
do. I'm guess there would be an actor that handled the data, but it would
probably get scanned by the GC periodically.

I'm just rambling now, but I do think, having seen how both Rust and Pony
prohibit non-linear access of certain values, that in an ML-family language
that distinguished pure expressions from imperative statements, that it
would be useful be able to mark a reference type (something with identity,
not something immutable) as being single-use. For example, if I'm going to
insert two elements into a mutable set:

    // Asterisk means "linear", the bang arrow means "effectful function"
    insertBoth : <Set* a, a, a> !-> Set* a
    insertBoth = proc <s0,a,b> -> do
      s1 <- insert -< <s0,a>
      s2 <- insert -< <s1,b>
      pure -< s2

To make this work, you would need for `insert` to mark its `Set` argument
as `Set*`. Somewhere, something unsafe has to happen. There must be some
kind of primitive that means "get rid of this uniqueness marker" and
another primitive that means "conjure up a uniqueness marker". That's
fine though because linearity tends to not work well once you start getting
under the hood of data structures. The nice thing that Rust gives the user
is that it lets you temporarily treat a linear thing as nonlinear. This
is useful in the case where you want to do a bunch of membership tests
on a set. Having each call to `member` return a bogus `Set*` (just the
same as the argument that you fed to it) is annoying. It's a bad API, and
most languages that have riffs on linear types try hard to avoid this.
However, I'm not sure how to avoid it. Maybe it is possible to go a
different direction. You could have:

    insertBoth : <Set* a, a, a> !-> Set* a
    insert     : <Set* a, a>    !-> Set* a
    member     : <Set? a, a>    !-> Bool

Here, `member` would mean "I accept a linear set, but I don't count as
consumption". This is a terrible idea though. I think the most simple
option is to have `member` just return a new reference to the `Set*`.
It would be annoying, but in the language I'm imagining, mutable data
would not be what you typically work with. Data structures could provide
three interfaces:

1. Persistent
2. Mutable, no linearity invariants
3. Mutable, linearity invariants

I really do think that Rust's borrowing is a really good solution for
stuff like `member`. However, it seems difficult to incorporate into
a type system.

# Garbage Collection of Immutable Cycle-Free Data

Ueno's [non-moving garbage collector for functional languages](https://www.pllab.riec.tohoku.ac.jp/papers/icfp2011UenoOhoriOtomoAuthorVersion.pdf)
makes heavy use of bit sets. The idea is that, in functional languages,
you end up with this situation where something like 90-99% of allocations
(I made those numbers up) do not survive even a single collection.
Copying collectors have an easy time with this. If you cannot reach it,
you don't spend any cycles on it. For non-moving collectors, at collection
time, you *have* to pay for every slot in an arena that could have been
used. Ueno's trick is to minimize this cost. At one bit per object, with
the bits stored separately from the objects, you end up paying to zero out
a small amount of memory (1KB of memory for every 8192 objects).

I wanted to explore what happens if you add more constraints to the heap
that Ueno's collector runs on. My two constraints are:

* Data is immutable
* Data is non-cyclic (this one might not be that important)

Equipped with the immutability constraint, we can confidently build, on
a per-object basis, a bitset of everything kept live by the object.
This bitset cannot change over the lifetime of the object. For example:

      A   B
     / \ / \
    C   D   F
    |      / \
    E     G   H

Here, `A` keeps `C`, `E`, and `D` live. This will remain true as long as
`A` is in scope. `A`'s bitset is just its children and the union of their
bitsets. For garbage collection, it should be possible to start with the
"alive" bitset as zero and then union (boolean disjunction) all bitsets
for everything encountered while walking the stack.

That is extremely simple, but the cost of these bitsets is potentially
enormous. Every heap object needs a bitset that has an entry for everything
in *the entire heap*. Most garbage collection techniques have linear space
overhead, and this implies quadratic space overhead. Three things might
bring this overhead down:

* With Daniel Lemire's roaring bitsets, it is possible that the space
  overhead may be considerably less that the overhead that the expected
  worst case.
* Roaring bitsets can be implemented as persistent data structure. As part
  of a language runtime, a persistent implementation would need reference
  counting.
* To prevent allocations from being super expensive, it might be possible
  to only do this trick for older generations. That is, when allocating into
  the nursery, do not build any bitsets immidiately. Rather, wait until
  a object survives a collection, and then build the map as a part of
  the collection. This does not actually help with space that much, but
  it would prevent the construction of bitsets that never even get used.

Let's consider a 32GB where objects are, on average, 32B. That means 1
billion heap objects. Without any compression, the bitset needed to track
all of these would be 128MB. That's a lot. And that's just the big top-level
one produced during minor GC. On top of that, you have to consider all of the
other heap objects. There are other implementation possibilities whose
consequences are not clear to me:

* Track which bitsets are supersets or subsets of other bitsets. If you
  are going to union something with the accumulator for the live set, and
  you know that a superset has already been unioned into the accumulator,
  then you can skip the bitset. This seems unlikely to be super helpful
  because the GC already avoids scanning children, cutting out all of
  those union-with-subset operations.
* Packing objects onto the same page as siblings (think of tree-like objects).
  Only a copying collection pass could do this. Roaring bitsets compress best
  when you have runs 1 or 0. Unfortunately, a nonmoving collectors would
  probably (I have never tested this) produce a liveliness bitset with
  erratic patterns. Most of the bitset, for any given object, would just
  be zeroes, but the places that are ones wouldn't be packed together tightly.
  And that's room on the table for improvement.
