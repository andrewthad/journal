# Good Type-Level Multiplication and Addition

Let's ignore the whole question of refinement types for the moment.
What about just having special multiply and add type constructors
that can normalize the expression. For example:

* `n + 1` ==> `n + 1`
* `1 + n` ==> `n + 1`
* `n + n` ==> `2n`
* `(n + 1) * n` ==> `n^2 + 2n`
* `(n + m) * (m + 3)` ==> `nm + m^2 + 3n + 3m`

Simple stuff. And I think it fits into Complete and Easy. Numeric
predicates need to bubble up rather than being pushed down since
they cannot be decomposed. Here are some examples of where these
may show up:

    copy : MutArray n -> Array n -> Effect ()
    copyMut : MutArray n -> MutArray n -> Effect ()
    append : Array n -> Array m -> Array (n + m)
    apply : (Element -> Element -> Element) -> Array n -> Array m -> Array (n * m)
    take : Nat n -> Vector (n + m) -> Vector n
    drop : Nat n -> Vector (n + m) -> Vector m
    length : Vector n -> Nat n
    (*) : Nat n -> Nat m -> Nat (n * m)
    (+) : Nat n -> Nat m -> Nat (n + m)
    (-) : Nat (n + m) -> Nat m -> Nat n

So, not really a whole lot of situations. Let's try playing around
with this:

    // We should be able to write dropEnd with take.
    dropEnd : Nat n -> Vector (n + m) -> Vector m
    dropEnd n v = take (length v - n) v

Is there an inference strategy that causes this to typecheck? Working our
way up, we can see that `length v` has type `n + m`, and `n` has type `n`.
Since type-level addition has normalization built in, subtraction ends
up being tricky. Even though we've got two `Nat`s that exactly match the
types we are looking for, `n + m` is really the same thing as `m + n`, so
it is cheating to go from the inside out here. But, working in the opposite
direction, we would learn that `take` expects its first argument to have
be of tagged with `m`. Equiping with this additional knowledge, the type of
subtraction becomes `Nat (m + ?) -> Nat ? -> Nat m`, where the question mark
is a metavariable that needs to be solved. And here, we are able to switch
back to inside out. The two arguments of subtraction give consistent results.
To the left, we see that `length v` has type `Nat (n + m)`. To the right, we
see that `n` has type `Nat n`. So, the metavariable is solved as `n`. Does
this actually work with Complete and Easy? I'm not totally sure. I really
need to work though the system more to understand when switches between
synthesis and checking happen.

One thing that becomes clear as I'm writing this is that multiplication
might not be as simple to incorporate as I imagined. In particular, the
type `2 * n` is same as `n + n` so if you knew that a result was supposed
to have the shape `?a + ?b`, it should match `2 * n`. In fact, it matches
all sorts of types: `6 + x + y` is matched in many different ways since the
6 could be split up. But if we were trying to check something like

    a + b : Nat (6 + x + y)

We would need to switch to bottom up and have `a` and `b` both synthesize
types. That is, we could not push the `6 + x + y` down any further. The
general idea here is that type-level addition and multiplication do not
decompose, at least, not in a way that is generally useful. This means
that there are certain situations where inference will fail. For example,
something as simple as

    n + 1 : Nat (n + 1)

will only typecheck if `n` is in the environment and has a solved type.
It cannot be inferred to have type `Nat n`. However, it will usually be
the case that the type of `n` is available in the environment.

Here are two different definitions of another operator. It throws a wrench
in things:

    subMaybe : Nat n -> Nat m -> Maybe (Nat (n - m))
    subMaybe : Nat n -> Nat m -> Maybe (exists p. Nat (p + m = n, Nat p))

The second one requires existentials, and I've done that before in
the `natural-arithmetic` library. I don't want to go down that route because
it is difficult to use. The first approach is a little unsettling because
it implies that our type-level numbers aren't really naturals after all.
If we have type-level subtraction, someone can write `2 - 5` and they
should get a type-level `-3`. But just because they exist at the type-level
doesn't mean that there needs to be corresponding term-level values.
That is, `Nat (-3)` may very well be uninhabited. In fact, we want it
to be so that `replicate : Nat n -> a -> Array n a` is valid for all
arguments.

The real difficulty here is that now the type-level arithmetic has been
extended with negation. Is this a problem? Perhaps not. All of the same
laws are good. We just now have negative coefficients as well. Negation
does pose problems for inequalities, but we aren't using those here.

What else could we do with subtraction. Well, it would be nice to be able
to build something that indexes:

    index : Array (n + 1) -> Nat (n - m) -> Element
    index : Array (n + m + 1) -> Nat m -> Element

These two functions are the same. Can one be written in terms of the other?
I'm not sure, but I would hope so.

One last thing before I go is that we do need lightweight existenials to
really make any of this usuable. We need a `Nat`-like type that just means
"I'm not negative", but nothing more. And then we would need an existential
`let` (usually called something like `open`) to convert between the two.

Where do inequality refinements fit in? Well, maybe we don't need them. One
thing that refinements do let us express nicely is that a number lies between
two other numbers (needed in mergesort, for example), but the arithmetic
discussed above lets us do this:

    loMidHi :: (Nat n, Nat (n + m), Nat (n + m + p))

But maybe not. Since our type-level numbers are not natural numbers, this
does not really mean what we want it to mean.
