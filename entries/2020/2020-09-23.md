# Crit-bit Notes

I learned about [crit-bit trees](http://cr.yp.to/critbit.html) yesterday. There
are some specifics about them that it took me a while to figure out, so I'm
writing them down in case I need to figure them out again. The definition of
crit-bit trees reads:

>  A crit-bit tree for a nonempty prefix-free set S of bit strings has an
> external node for each string in `S`; an internal node for each bit string
> `x` such that `x0` and `x1` are prefixes of strings in `S`; and ancestors
> defined by prefixes. The internal node for `x` is compressed: one simply
> stores the length of `x`, identifying the position of the critical bit
> (crit bit) that follows `x`.

A couple of notes on this definition:

The terms `x0` and `x1` mean "bitstring `x` followed by the bit 0/1".

The data structure really does not support empty sets. In C, people
work around this by using `NULL` for the empty set. In Haskell, an
extra `Empty` data constructor that is inadmissible in most contexts
is used.

The definition itself just describes the data structure but not any of
the algorithms for operating on it. For these, see the pdf in
[Adam Langley's critbit repo](https://github.com/agl/critbit). For
lookups, you just walk down the tree and check each bit that the tree
branches on. At the end, you must `memcmp` against whatever you find
at the leaf. The string you find at the leaf might not look anything
like the key you were searching for. All you know is that the bits
that you had to check on the way down matched. There is no short
circuiting for lookup failures. This is something interesting that
distinguishes crit-bit trees from other trie-like structures that
store substrings at the branch nodes.

The term "prefix-free set" means that you cannot have "foo" and "foobar"
in the set because "foo" is a prefix of "foobar". However, this restriction
is easy to relax, and there is no performance penalty for doing so. Bryan
O'Sullivan has a [crit-bit tree implementation](https://hackage.haskell.org/package/critbit)
on hackage. It includes a description of the trick used to relax the
restriction:

> We use 9 bits to represent 8-bit bytes so that we can distinguish
> between an interior byte that is zero (which must have the 9th bit
> set) and a byte past the end of the input (which must /not/ have
> the 9th bit set).
>
> Without this trick, the critical bit calculations would fail on
> zero bytes /within/ a string, and our tree would be unable to
> handle arbitrary binary data.

So it's kind of like putting a `NUL` terminator on strings except that
you don't actually glue anything to the end of the strings in memory.

Finally, there is a more cache-coherent version of a crit-bit tree
called a [qp trie](https://fanf.livejournal.com/137283.html). These
just have higher fanout. The original version did four bits per node
(rather than one as crit-bit trees do). The author has variants that
do five bits per node and eight bits per node. HAMT-style array
compression is used to avoid allocating space for a 16-element array
when only a few of these are typically needed. To me, the four-bit
and eight-bit variant both seem appealing. On English-language text,
the eight-bit variant will compress very well. There are complexity
tradeoffs between the four- and eight-bit variants:

* With four bits, you have to do some kind of trick to figure out
  which half of a byte you are in. The mask only needs to be 16 bits.
* With eight bits, the mask needs to be 256 bits. The simple BMI
  instructions that the four-bit variant used get much more
  complicated.
