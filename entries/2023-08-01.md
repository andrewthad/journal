# Interpreted Language

What would be useful in an interpreted untyped language? This continues
an idea from 2023-07-31. Here are some features I want:

* Top-level functions with known arity. Functions must be applied to the
  correct number of arguments. (No currying)
* Single integer type backed by a "big int".
* No mutation. No uniqueness or linearity.
* No regions. No stack allocation.
* Builtin array type, backed by persistent array so it doesn't need
  mutation to work.
* Objects are just maps where the keys are field names and the values
  are the field values.
* Arrays unpacked into data constructors might need to be handled specially.
  I'm still thinking about how this should work. We want the lowering of
  the typed language into the untyped language to be straightforward.
* Don't need closures as first-class values
* Join points need to be supported
* Module system needs to work without performing specialization. This means
  that we need some way to pass around a map of implementations to functions
  that is part of a function's environment. Module signatures don't have
  any types, just function names. The functions prototypes in a signature
  could possibly have arity. Not sure though. If they did, this would be
  a very lightweight form of runtime type checking.
* Some system for dealing with IO. That is, we need something like bind
  to sequence effectful computations.

I'll explore a few of the more specific ones in the rest of this.

## Module System

Module instantiation would happen at the top level. Interestingly, applicative
and generative modules collapse into the same thing since (1) the system is
unityped and (2) there are no top-level mutable variables. Functions look like
this:

    data Term
      = Int Integer
      | Apply FunctionPath [Term] -- this may lookup a function in a module
    data FunctionId -- the name of a function
    data FunctionPath
      = FunctionGlobal FunctionId
      | FunctionModule (NonEmpty ModuleId) FunctionId
      | FunctionBuiltin Builtin
    data Function = Function
      { id :: FunctionId
      , arguments :: [TermId]
      , body :: Term
      }
    data SignatureDefinition = SignatureDefinition
      { functions :: Map FunctionId () -- names of functions, arity not captured
      }
    -- Module definition has no name. Names are assigned in ModuleAssignment.
    data ModuleDefinition = ModuleDefinition
      { arguments :: Map SignatureId SignatureDefinition
      , functions :: Map FunctionId Function
      , modules :: Map ModuleId Module
        -- ^ Child modules inside this module, all public. Should these be
        -- allowed to access the functions in this module? Should the
        -- functions in this module be allowed to access the modules?
      }
    -- Module type represents both definite and indefinite modules.
    -- Partial instantiation is allowed.
    data Module
      = Lift ModuleDefinition
      | Apply Module (Map SignatureId Module)
      | Variable ModuleId
    data ModuleAssignment = ModuleAssignment
      { binder :: ModuleId
      , module :: Module
      }
    evaluate ::
         Map FunctionId Function -- global functions
      -> Map ModuleId Module -- module assignments
      -> Map TermId Value -- in-scope arguments
      -> Term
      -> Either Error Value

This is much more tricky than I realized it would be. When we evaluate a
function from an indefinite module, we need a context that tells us what
all the signatures were filled in with.

I'm beginning to think that it might be easier to just eagerly substitute
whenever we instantiate an indefinite module. This should make some of the
scope problems more simple.

    data SignatureDefinition = SignatureDefinition
      { functions :: Map FunctionId () -- names of functions, arity not captured
      }
    data Module = Module
      { arguments :: Map SignatureId SignatureDefinition
      , functions :: Map FunctionId Function
      , modules :: Map ModuleId Module
      }
    applyModule :: Module -> Map SignatureId Module -> Either Error Module
    evaluate ::
         Map FunctionId Function -- global functions
      -> Map ModuleId Module -- module assignments
      -> Map TermId Value -- in-scope arguments
      -> Term
      -> Either Error Value

This way, whenever we instantiate a module functor, all of the functions
are rewritten with the new function IDs. When we evaluate something, we
should mostly be evaluating `FunctionGlobal` and `FunctionBuiltin`. If `evaluate`
ever sees `FunctionModule`, it had better be a module with an empty `arguments`.
We might be able to perform an entire "module resolution" phase first so that
we do not have to worry about this case happening. After module resolution,
nested modules would still exist, but signatures would not exist.

Now I'm wondering what the scoping rules for nested modules are supposed to be.
Consider:

    module A:
      function foo(...)
      module B:
        function bar(...)
      module C:
        function baz(...)

I think the scoping rules should prevent `foo` from referencing `B` or `C`. Because
`B` and `C` certainly need to be able to reference `foo`. If `B` or `C` is
indefinite, then accessing them from `foo` makes no sense (they must be instantiated).
But what if we defined and instantiated `B`:

    module A:
      function foo(...)
      module B:
        signature OrderedType 
        function bar(...)
      module K = B[OrderedInt]

Should we be able to reference `K` from foo? Maybe. If we do allow this,
then it's possible to have `foo` and `bar` (or one specialization of `bar`)
be mutually recursive. This isn't bad, but it's weird. So I think we should
we restrict `foo` from talking about `K`. Suppose that we really needed to,
and `bar` didn't reference `foo`. We could instead write:

    module B:
      signature OrderedType 
      function bar(...)
    module K = B[OrderedInt]
    module A:
      function foo(...)

And now `foo` can reference `K`. Alternatively, we could make module and
function declarations sensitive to their order inside a module, and this
could fix the problem. Top-level modules already have an implicit order,
so this is actually a natural generalization of that behavior.

Here's something I dug back up:
[Fix data type in OCaml](https://stackoverflow.com/questions/12995044/fix-data-type-in-ocaml)
but it looks like this feature just lets you define an infinitely expanding
type, which is actually enough to do a lot of interesting things. Here's
my variant of the answer from the SO question:

    module type ParamType = sig
      type ('a, 'b) t
    end
    module EqFix (M : ParamType) = struct
      type 'b fix = ('b fix, 'b) M.t
    end
    module Param = struct
      type ('a, 'b) t = Nil | Cons of 'b * 'a
    end
    module EqList = struct
      include EqFix(Param)
    end
    open Param
    let rec to_usual_list : ('c EqList.fix, 'c) Param.t -> 'c list =
      function
      | Nil -> []
      | (Cons (x, xs)) -> x :: to_usual_list xs

This is a clever trick, but I feel like what I really wanted is something
more like this (not a real programming language):

    module type ParamType = sig
      type element
    end
    module MySyntaxTree (M : ParamType) = struct
      type ast
        = Lit Int
        | App M.element (List element)
    end
    x = MySyntaxTree(struct {type element = x.ast})

The tricky part is that `x` is defined recursively, and I don't know how to
allow that. If you gave `x` a signature, it would be:

    x : struct{type ast = ...}

You cannot fill in the RHS of the `type ast` declaration since it references
`x`, but we do not actually need that to get this particular declaration
to typecheck. Just knowing that module `x` has an `ast` type is enough.
I think we need something like this:

    x = with(x : struct{type ast}):
      MySyntaxTree(struct {type element = x.ast})
    // Inferred type of `x` is now:
    //   x : struct{typ ast = Lit Int | App x.ast [x.ast]

Back to an earlier question, what do we really want the rules for ordering
modules to be? Maybe something like this:

1. Primops have global scope
2. Top-level functions have global scope
3. Functions cannot reference modules defined "beside" themselves
4. Modules (and all children of them) can reference functions defined "beside" them.
   This explains rule 2.
5. Another way of thinking about this is that, within a module, function
   declarations preceed module declarations.
6. Functions defined "beside" one another can reference each other.
   That is, mutual recursion of functions is allowed, and functions
   have no order. Reordering functions cannot cause things to break.
7. Modules do have a particular order. The are may only reference
   modules defined earlier.
8. We could cook up some crazy construct for building a module instantiation
   that uses the result as an argument.

So, how do we want to actually evaluate modules? We do evaluation in several
passes:

1. Apply module functors to arguments. Every time we see a module
   application, perform substitution.
2. Dead code elimination on modules. If a module (definite or indefinite) is
   unused, remove it. This includes instantiations like `module X = Y(r=Z)`.
   If `X` isn't used, this declaration gets eliminated. If `X` is indefinite,
   then a downstream user of it should eventually saturate it. This
   saturatation should cause `X` to be unused.
3. Scan entire program for unsaturated modules. Fail if any are detected.
4. Evaluate the program with a module context available.

This is much more complicated than I wish it was. I'm not sure how to avoid
this complication though. We could skip steps 2 and 3 and just perform the
checks in step 4, but I don't think this is a good idea. So, originally,
we have:

    data Module
      = Lift ModuleDefinition
      | Apply Module (Map SignatureId Module)
      | Variable ModuleId

and then after step 1, the `Module` data type disappears and is replaced
by `ModuleDefinition`.

Final question. How do we deal with IO? Let's try:

    data Term
      = Int Integer
      | Apply FunctionPath [Term]
      | Let Binder Term Term
    data Effect
      = Bind Binder Effect Effect -- monadic IO
      | Apply EffectfulFunctionPath [Term] -- Apply effectful function
      | Pure Term

This strategy keeps effectful functions and non-effectful functions in
completely separate namespaces. We could unify them with:

    data Term
      = Int Integer
      | Apply FunctionPath [Term]
      | Let Effectfulness Binder Term Term
      | Pure Term

The argument (the term that gets bound to a variable) of an effectful `Let`
must be an effectful term. This means that it must evaluate to `Pure` or
that it must be an application of an effectful builtin function to an argument.
We might want to separate `Let` and `Bind`.

Effectful terms must not be passed as arguments to functions. The argument
to `Pure` cannot be effectful. That is, something like `Pure (Pure x)`
would always be rejected.

