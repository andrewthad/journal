# Sharing Read-Only Data

If we have a per-thread multi-generation heap, concurrent garbage collection
is easy. Nothing is shared. How do we share read-only across threads without
negatively impacting concurrent GC. The only way that a thread A can come to
depend on memory owned by thread B is if thread B creates thread A. This does
not necessarily happen. Thread B could fork thread A and only pass it unboxed
arguments, and then thread A would not refer to anything in thread B's heap.
Alternatively, thread B could do a deep copy of the arguments passed to
thread A. Again, this would prevent sharing the read-only arguments. But
thread B might have something big that it would like to pass thread A, something
like a large map or a cache of assets. We do not want to copy this, so thread
A needs to indicate somehow that it uses memory from thread B. Let's consider
two situations where this may happen:

* Thread B forks several threads as a way to parallelize a pure computation.
  This is similar to GHC's sparks. Thread B will block until the worker
  threads finish. Consequently, it cannot outlive them.
* Thread B forks thread A and then completes while thread A is still running.
  Thread B's heap (but not its stack) must be considered live until thread
  A finishes.

In the second case, thread B's heap needs to be marked in some way with an
indication that the memory backing it cannot be reused/freed until one or
more child threads finish. As each child finishes, it must remove its
thread id from thread B's list. Eventually, one of them will make the list
empty, and at that point, the memory is released. In the first case, none
of this is really necessary since thread B just blocks until the children
are finished.

It is not possible to create a circular reference between thread heaps. This
is good. It means that in a chain like:

    A -> B -> C -> D

As long as thread A is live, thread D's heap cannot be destroyed. Despite
that these heaps cannot be destroyed, they can be collected. Any blocking
thread must be at a safepoint. Let's come back to that later though, since
that is really just an optimization. In the scenario above, let's assume B and
C are running. If A exhausts its own nursery, it can GC itself with no
synchronization whatsoever. However, if B exhausts its heap, it must
wait for A to finish. Similarly, C must wait for B, which implies waiting
for A as well. But A may be blocked awaiting a response from B or C. We
certainly do not want a deadlock here. When A blocks, its at a safepoint.
The threads waiting for A to GC itself can detect this and prompt A to
begin GC. This way, the deadlock is avoided. Several things could happen
during GC:

* Heap A might stop depending on B. This can be detected and the graph
  could be updated.
* Heap A might stop depending on B and start depending on C instead,
  since objects in B may reference C.
* Heap A might end up depending on both B and C.

In any of these cases, GC only requires synchronization to begin. After
starting, no synchronization is required. Also, note that objects in
B and C need to be copied to into the B and C heaps respectively. It
is easy to detect where something lives if the heaps are contiguous.
What about this dependency chain:

    A -> B -> C -> D
         ^
    X ---+

Here, two children depend on B. When B's nursery runs out of space, it
must wait on both A and X. Then, a single thread will collect A, X, and
B. What about making this multi-generation? That should not be too hard.
Each one of these heaps could have generations within itself. After
a sufficiently long period of time (perhaps every time the old generation
reaches a certain size), the old generation could is scavenged as part
of the collection. This might not happen everywhere at the same time.
For example, if A, X, and B were all being collected, it is possible that
only B would have its old generation considered. Normally, anything
pointing to B's old generation would just get ignored though. This
brings up an important question: Can A's old generation point to
B's young generation? I want the answer to be "No", but I do not see
a good way to enforce this. If A's old generation can point to B's
young generation, then whenever B is collected (which requires collecting A),
we have to look all the way through A's old generation. That's not
good for performance. To stop this from happening, A would need to always
make sure to promote things in B (and C!) when it GCed itself. But it cannot do
this since B might be running when A is performing GC on itself. The idea
of directed heap dependencies appears to be at odds with generational
collection. I need to think about this more.

