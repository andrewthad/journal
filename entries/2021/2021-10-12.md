# Compiler Things to Think About

Ruby has a cool array slicing syntax. You can do both of these:

    arr[2..10] // take the elements starting at index 2, ending at 9
    arr[2,8]   // take 8 elements starting at index 2

These two expressions mean the same exact thing, but depending on
the context you are working in, one might avoid a noisy subtraction
in your code.

I think that bitfields receive poor treatment by most programming languages.
I'd like to have access to the same syntax that I do for arrays, particularly
for indexing and slicing. It's not difficult to do this in a compiler. You
just have to use the same old tricks that you normally do for type-directed
overloading. You can go a little further with the index operator and let it
be overloaded for maps and sets and stuff, but I don't feel like there is
as much value there.

Since I'm think about overloading, there is also the issue of the overloading
of record labels. To handle these, you have to know the type of the record
that the accessor is paired with. It should be possible to handle this in
two stages. During parsing, leave the label as text, and then during
typechecking, perform a lookup based on the type of the record.

I would love to have an expression language that, post typechecking, enforced
lots of invariants about variable scope and type soundness. The type soundness
part is pretty straightforward with GADTs. Variable scope is way harder.

So far, I've been just hardcoding all data types. I need to figure out how
to quit doing this since it is becoming tedious.

# Leaves of qptries

On integers that aren't randomly distributed, qptries do a pretty good job of
using cache lines. The exception is the leaves. The leaves look like this:

    data Leaf a = Leaf
      { key : Word64
      , value : a
      }

With a tag, this ends up being 24 bytes (assuming that `a` is some 8-byte type,
like a pointer). If `a` is 4 bytes, then `Leaf` could end up being 16 bytes.
Inlining the leaves into the branch could eliminate a huge number of pointers,
but it would make the arrays in the branches larger. If the value is a 128-bit
or 256-bit field (an IP address or a hash), then the leaf would use more of a
cache line and this would all be a moot point. At a size of 24 bytes, it's
not clear to me what the right call is, but at 16, I think it would be prudent
to pack leaves into branches:

    data Branch a = Branch
      { mask : Word16
      , index : Int8
      , children : Array (Branch a | (Word64, a))
      }

We need a tag bit in each array element, but we need to steal a bit out of
that second option somewhere. We could use the `NULL` pointer value for
this. Alternatively, we could keep a second bitmask around, and the bitmask
dictates how each element is interpreted. This seems like a pain to try
to plumb around though. The first option would look like this in C:

    struct choice {
      void* value; // if value == NULL, then child is valid
      union {
        Branch* child;
        uint64_t key; 
      }
    }

The above is always 16 bytes on a 64-bit platform. If we were doing pointer
compression to represent pointers as 4-byte offsets, we might instead try:

    struct choice {
      uint32_t value; // if value == 0, then child is valid
      union {
        uint32_t child;
        uint8_t key[8]; // use this to force packing,
                        // perhaps __attribute__((packed)) is better
      }
    }

Now we have a 4-byte-aligned, 12-byte struct. I am not sure how to make a
compiler figure this out. Then, beyond that, I am not sure how to make it
so that a user can figure out that the compiler is doing what they hope
it is. Maybe this could be asserted somehow? Also, what is the interface
for structs unpacked directly into arrays? You cannot access them with
`index`. You need some kind of `with` operator to scope them. And what
about updates and inserts? You need to initialize the new element in the
array after performing `memcpy`. It should be possible to make `insert`
work for structs packed into arrays like this.
