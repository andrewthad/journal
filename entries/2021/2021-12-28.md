# Uniformity of Types

I have been working on a type system recently where the types are defined
like this:

    data Type :: TypeEnv -> * where
      Int :: Type e
      Bits :: Type e
      Bool :: Type e
      Box :: BoxedType e -> Type e
    data BoxedType e
      Concrete (Con n) (Vec n (BoxedType e))
      TypeVar (Var e) -- some variable in the type environment

You can have functions with types like this:

    insert : forall a. (Node a, a) -> Node a

In this function's type signature and body, the type environment only
has `a`. The goal for the implementation is to actually carry some evidence
of the type around at runtime. That is, when lowered to C or assembly, there
should actually be an argument corresponding to `a`.

Arrays have given me trouble. What exactly can go inside of an array?
At first, I thought that it would be possible to restrict the set of
types that can be used as an array element. However, the restrictions
bleed into the type system of any higher-level language built on top
of this. As an alternative, it should be possible to make certain uncommon
uses of arrays perform poorly but still work.

First, let's look at the easy situation: `Bool`. C++ has endured decades
of criticism for the bitvectors it uses to back boolean vectors. It is not
possible to slice into a bitvector and get back a pointer. This causes
problems with all kinds of data structure that assumes that slicing works.
The solution for `Bool` is simple: use a whole byte for each boolean.
Additionally, a `BitArray` type should be provided for the other case,
and then a module system at a higher level would let users specify which
properties they needed an array to have. So, we get this additional
data constructor:

    BitArray :: Type e

What about arrays more generally? We need to be able to put anything in an
array, and we want for arrays to always live inside of data constructors.
If the array field is projected out, it should keep the entire object that
it lives inside live. We add this:

    Array :: Type e -> Type e

Now, when an array is projected out, how do we recovered the complete type
of its containing object? That is, suppose we have:

    data Node a
      { metadata : a
      , elements : Array Bits32
      }

When we project out the elements with `myNode.elements`, we might end up in
a situation where we cannot figure out what the type of `metadata` is. So,
an array must be represented in a way that preserves the full type of its
containing object. This only needs to be done when we are in an allocating
setting. For example, we do not need to track the full type when we do
something like this:

    myNode.elements[0]

The array is consumed without GC having a chance to run. But, in the case
where the array escapes and outlives its containing object, we must capture
the relevant type environment. Unfortunately, the type environment lives
on the stack, so capturing it implies allocation, but allocation is a strange
thing to do for field projection. Especially because most of the time, we
do not actually need to close over the type environment at all since the
outlive case is uncommon.

Maybe type instantiations could live somewhere on off of the stack. Not on the
heap in the traditional sense because type instantiations are never freed.
It should be done like the way that GHC does top-level infinite tries. Or
even better, if polymorphic recursion is prohibited, there is no need for
it to be infinite at all. All types that are ever actually constructed could
be found with static analysis. Trying to pack all of this information into
a single 64-bit word (used to index into some global data structure to recover
all the information) is tricky. Naively, if we represent every type as
a 16-bit word, then a 5-ary type constructor runs out of space. However,
most type constructors are only applied to a small number of types. For
each type constructor, we must, at compile time, come up with a different
number for each distinct full application of it and then come up with a
bit twiddling function that combines the inputs to create this number.
(It is allowed to produce garbage for any input types that were statically
determined to not happen.) In the easiest case, two input types, it is 
sufficient to just choose a bit in which they differ and incorporate
that bit into two new unused patterns. With a large number of input types,
this problem becomes more difficult, but I believe it is still tractable,
at least, with real-world types.

With this machinery in place, projecting an array is straightforward. We
must capture the type of the containing object, the pointer to the array
(certainly 64 bits), and a pointer to the containing object (32 bits).
If types can be represented as 32-bit numbers, then the total size is
128 bits, and if we combine the two 32-bit fields, we can fit them
comfortably into one register. So, an array is represented as a 128-bit
value if it must be stored.

It seems like this also makes existential quantification possible.
It does not. Existential quantification makes it impossible to statically
determine all type instantiations. The difference between existential
quantification and what we are doing with arrays is that, with array
projection, we cannot go back into the containing object and project
out any of its other fields and use them. Our final type for types is:

    data Type :: TypeEnv -> * where
      Int :: Type e
      Bits :: Type e
      Bool :: Type e
      Box :: BoxedType e -> Type e
      BitArray :: Type e
      Array :: Type e -> Type e
    data BoxedType e
      Concrete (Con n) (Vec n (BoxedType e))
      TypeVar (Var e) -- some variable in the type environment

Notice that in types like:

    specializedIndex : forall (a :: Box). Array a -> Int -> a

The array is represented by two words, one of which is data about the object
only needed for GC, one of which is what would typically be considered an
array. Additionally, there is a word for the `a` type, which although
implied by the array's type (and technically a little redundant), is necessary.

