# Runtime Representation of Managed Arrays

GHC does not allow interior pointers. In particular, this is a problem
for arrays. Most high-fan-out tree-based data structures have a natural
implementation where an array is embedded into a data constructor. In
GHC, such a representation is not possible. I would like to be able to
write code like this:

    -- High-level data type
    data Node
      = Branch Int (Array n Int) (exists (n | n <= 8). Array n Node)
      | Leaf Int (exists (n | n <= 8). Array n Word)

This is just a tree where every node in the tree has a Word attached
to it, and no node is allowed to have more than 8 children. What kind
of low-level representation would we like for this. GHC forces this on
us:

    -- Low-level data type (similar to GHC's STG)
    data Node
      = Branch Int Box Box
      | Leaf Int Box

Each `Array` becomes `Box`. That's an indirection, which makes the `Branch`
and `Leaf` data constructors both use only 24 bytes of the meaty 64-byte
cache lines that we want them to be using. Let's try something else:

    data Node
      = Branch Int FixedLenArray VarLenArray
      | Leaf Int VarLenArray

Ok, now we have communicated that something of variable length is hanging
out at the end of the payload. This length must be captured at runtime in
the header word, but that's fine. We've got space for that. What's next?
Functions that accept arrays as arguments need to be able to accept arrays
that are behind interior pointers. Otherwise, you end up having to write
everything twice, and you end up with an ecosystem where there is a bunch
of code that only works on one kind of array. Here is an example:

    -- Second arg is array length
    sum : Array n Int -> Int -> Int

What do we want to get passed to this at runtime? I am trying to avoid
actually having interior pointers loaded into registers at runtime. I
want to keep the base pointers around since that makes it easier to
have a GC that can relocate objects. Let's try this:

    sum_cg : GcPtr -> Int -> Int -> Int

So, you provide two things: the base pointer and an offset. What should
the unit for the offset be. There are three options:

* Bytes
* Machine words (i.e. 8 bytes)
* Array element

The third option (array element) is desirable because it means that the
offset could be used as an initial offset when using the array in a
loop. The cost of doing so is that in the mid-level IR (STG like),
arrays types must carry their element type with them. This leads to
more monomorphization. A function like `id` would end up with separate
instantiations for `Array W8` and `Array W16` even though the generated
code for these is identical. I am not too concerned about this issue
though since I do not expect for arrays to be passed to functions that
are totally polymorphic in the argument. So, here is our sum function
in the mid-level IR:

    sum : Array W64 -> W64

And then in a lower-level IR, we have `sum_cg` as before, but the second
argument is interpreted as an offset in units of 64-bit words. When we
do something like this:

    case x of
      Branch _ keys _ -> sum keys 8

This should become:

    case x[0] of
      Branch -> sum_cg x 2 8   // The position 2 because tag is 0 and Int field is 1

Good. And we trivially have a `drop` function that just increments the
offset. The general idea is that the notion of offset is built into the
runtime, but length is not. If the keys had been 32-bit words instead,
this fragment would have been lowered to: 

    case x[0] of
      Branch -> sum_cg x 4 8

So, essentially, we treat the object as though it were an array, even
though it isn't really. It's fine to do this as long as the user doesn't
have a way to peek at the offset. The user can certain do stuff to make
OOB happen, and that's fine. I just don't want users to have a way to
ask "what's the real beginning of this array", because everything going
back to offset zero is not necessarily an array.

In this framework, an non-embedded array is actually just a kind of degenerate
case. We have a data type like:

    data Vector = Vector VariableLenArray

This raises an important implementation concern. Data constructors with
a variable-length array should probably have the array's length as a
second header word and use a single bit in the header word to communicate
that the second word is there. That way, the garbage collector can figure
out the true size of the object. This unifying strategy is powerful, but
it means that we must support arbitrarily large arrays in data constructors.
I dislike having to waste that precious space for a number that's guaranteed
to be tiny in many cases. I'll have the this about this more.
