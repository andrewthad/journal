# Mutable Objects and Reference Counting  

In a mostly-immutable setting, reference counting works pretty nicely.
I explored one possibility for support mutable objects in the entry from
2021-01-07. After skimming the Ulterior Reference Counting paper again,
I have another idea. It goes like this:

Every old-gen heap block (probably 4KB-32KB) has a bitset associated with it.
This bitset tells you which objects are forcibly retained by a mutable
reference. That is, mutable references do not contribute to a reference count.
All mutable objects are scanned at every nursery collection, and the objects
they reach have their "retain" bit set to 1. An object with a reference
count of zero can still be considered live if its retain bit is set to 1.
There is definitely some trickiness with this though. If an object is only
kept live because of the retain bit and then the retain bit is cleared
before a minor GC and doesn't get set again, how do we learn that the object
died? We could do two bitsets, a current and a previous, but then we still
have to track which bitsets were modified and then scan and diff the current
and previous of each one at the end. This makes modifying these bitsets
somewhat expensive because you would have to check before each modification
to see if you needed to reset current (memset to 0) and add to the
list of blocks with modified bitsets. So, the total space overhead would be
something like:

* A 4KB block of 32B objects has 128 objects. So, 128 bits for current
  and 128 bits for previous makes 256 bits, which is 32 bytes. That's
  less than 1% space overhead.
* We need to cheaply be able to track modified blocks. We could also
  do this as a bitset. Let's assume that we have a 1GB broken into
  4KB blocks. That makes 2^30/2^12 = 2^18 blocks, and 2^18 bits is
  2^15 bytes, so that's 32KB.

This really doesn't seem that bad. Any time you look at the fields of
a mutable object, you have to consult the bitset of all blocks. If the
block has not yet been modified, then set the corresponding bit to 1
and `memset` current to 0. Then, set the appropriate bit in current.
At the end of a minor collection, we must scan the entire 32KB global
bitset to check which blocks changed. We visit these and diff current
and previous, possibly freeing objects. Then, we reset the global bitset
to zero.

I dislike the global bitset. It seems large and likely to negatively
impact cache. If we make blocks bigger, we can decrease the size of
the global bitset. The alternative is to do it as a list instead of
a bitset. The list will work much better when the number of mutable
objects is small. It does have to be scanned every time, but SIMD can
make these scans pretty fast. And in all honestly, you really shouldn't
have more than a few dozen blocks being pointed to by mutable objects.

One possibility for an optimization is on arrays. The elements in an
array of heap objects are likely to live in the same block. So, rather
than handling them all separately, it should be possible to batch them
by heap block.

One caveat. You have to do the different parts of collection in a
particular order.

1. Old mutable objects are considered roots, and so is the stack. You have
   to do copying collection from the stack roots first.
2. Next, you scan the old mutable objects, copying young objects that they
   point to and setting bits for old objects that they point to.
3. Next, you apply updates to counters based on a list built while scavenging.
   At this time, only non-retained objects that drop to zero RC are freed.
4. Last, you walk the appropriate bitsets and free anything that has had its
   retain bit zeroed and has a reference count of zero.

The order of these four steps is important. I think that 1 and 2 can be done
in either order though. Any young mutable objects promoted by steps 1 or 2
are immidiately treated like old mutable objects. Any mutable reference to
an object (from a young or old mutable object) does not count toward the
reference count. The reference count is just a count of immutable references
to an object. Note that this strategy might cause some mutable
references to be retained for much too long when there is a chain of mutable
references. There might be a way to improve this though. It might be possible
to add a step 5 that checks all the old mutable objects (including ones just
promototed in steps 1 and 2) and then, if any of them have RC 0 and are
not retained, free them, update retain bits for the things they referred to,
and then run steps 3, 4, and 5 again. I think that this might still have
problems in a mutable-to-immutable-to-mutable situation. I have to think
about it more. Consider the broad object categories:

1. Young Immutable (points directly to 1, 2, 3, 4)
2. Young Mutable (points directly to 1, 2, 3, 4)
3. Old Immutable (points directly to 3 and 4, transitively to 1, 2, 3, 4)
4. Old Mutable (points directly to 1, 2, 3, 4)

It's really the third category that we are hoping to make shine with RC.
And it can shine. But, because of how the collection steps are broken
apart, any data structure that interleaved class 3 and class 4 objects
(as a chain `3->4->3->4->3->4->...`) would have an extremely negative
impact collection times. Treating mutable objects as roots is the real
problem because that leads to incorrect retentions that we have to go back
and fix. We need to prove the a mutable object is reachable before we
mark its children as retained. How could we do this? Steps:

* There is no "remembered set" of mutable objects.
* Mutable objects must be proven to be reachable before they are scanned.
* How can we prove that a mutable object is reachable?
* We mark every immutable object as either transitively referring to mutable
  objects or not. This requires a single bit.
* We decide the value of this bit as we evacuate immutable objects. This bit
  will never change. The value of this bit is decided by examining immutable
  children and by ORing those results. In many situations, this bit can be
  decided at allocation time at no cost. Only for sufficiently polymorphic
  code do we need to figure this out by tracing the fields.
* We have to scan everything that transitively has mutable pointers. These
  scans only descends into some of an object's fields. Namely, the ones that
  have mutable pointers.
* Scans are triggered by:
    * Evacuation (scans relevant children)
    * Encountering pointer to object from stack
    * Encountering pointer to object from live mutable object
* We have to make sure that we do not scan the same object twice. This
  requires a mark bit (or two).
* We still must have two bits per object that tell us about whether or not
  the object is being retained by a mutable object or the stack and whether
  or not it had been previously retained. If, at the end of a collection,
  we see 1-goes-to-0 for an object with RC of 0, we add the object to a
  buffer of objects to free. Let us call this the "freed object buffer".
* We still must have a set of blocks that documents the places where retain
  bits have changed. At the beginning of a collection, we can examine the
  bitsets that had been modified last time, zero them, and then, if they
  were not already entirely zeroed, add them to the new list. This seeds
  the list.
* Learning that RC = 0 for an immutable object does not give us any certainty
  that its memory can be reclaimed. We have to wait until the end of collection
  to be sure that nothing mutable is retaining it. This seems problematic.
  If we cannot act promptly, then what do we do about objects it refers to?
  We would like to be able to decrement their reference counters. Oh, doing
  this at the very end of collection might just happen to work out. Let's
  consider the two possibilities:
    * Object transitively has no mutable fields. Decrementing counters of
      field objects is fine because none of the children are going to cause
      any mutable objects to become unreachable. We can proceed recursively
      and free any unretained object with RC = 0.
    * Object transitively has mutable fields. This is the case that looks
      scary. The concern is that if we start freeing things, we will cause
      something mutable to become unreachable, and then the runtime will leak it.
      However, by this point in the collection process, the runtime will have
      actually already figured out that the mutable object could not be
      reached. Why? Because we already scanned every live object with mutable
      references earlier in the process. So, when we reach the mutable field
      (or fields), we want to ignore it because a different part of the
      collection routine has already marked the object it refers to as
      unretained. In a way, this kind of makes sense because mutable references
      do not count toward reference counts.
* The freed object buffer is scanned last. We do not start adjusting reference
  counts on the children of freed objects until we have complete information
  about retained objects. The freed object buffer is seeded by the looking for
  1-goes-to-0 retentions for objects with RC 0. As we scan the freed object
  buffer (marking bitmaps so that objects may be reused), we may push more
  entries onto the freed object buffer. Anything child that drops to a 0 RC
  and is not retained gets added to the buffer. Eventually, the buffer
  becomes empty and GC ends.
* We need to increment reference counts as we evacuate objects. We must
  increment counts for any object pointed to by an evacuated object.
  Incrementing can happen more than once if multiple evacuated objects
  refer to the same object. Old gen or young gen makes no difference.

Notice that objects with a mark bit, or at least objects that ever use their
mark bit, cannot be shared across threads. At runtime, we can figure out pretty
cheaply whether or not it is safe to share an object across threads. It is,
however, difficult to enforce this in a type system.

In this system, the stack counts as a big mutable object. So, if it's only
the stack that refers to something, the reference count for it is 0, but it
is marked as retained.

The way that objects get freed in this system is either:

* Retention of an object transitions from True to False when the RC is 0.
* RC of an object drops to 0 when the retention is False.

These two happen at different times. I think that this system should
have no trouble with cycles of mutable objects. Immutable cycles would
cause problems though.

# Freezing Mutable Objects

How does in-place freezing work? Probably the same way as GHC, by flipping
a bit to indicate that the object is not mutable anymore. This should be
fine, but deep freezes require rebuilding some of the frozen structure.
This is almost inevitable. Even if there was some hope of reusing the
entire structure (and there is), you would still have to walk the whole
thing just to get all the mutable-to-immutable bits flipped.

The tricky part is that, with an in-place freeze, it is possible to end up
with an immutable object in the old generation with RC = 0 and unretained.
I think this is fine because garbage collection would know to check the
retention bitset (it should always check retention bitset for blocks where
mutable objects were found during the previous collection). It would observe
a true-to-false transition for a 0-RC object and would release the memory.
If it turns out that a frozen object is referred to (by something evacuated),
then its count goes to 1.

Actually, a deep in-place freeze is a serious problem. If the frozen structure
is unreachable, then everything is fine. But, if it is reachable and if all
the nodes were part of the old gen, then we have a bunch of incorrect
reference counts on the nodes.

The one good thing is that even a freeze that rebuilds a tree-like structure
gets to use the leaves in place. With high fan out, the leaves are often 80%
or 90% of the data. So, it's not like there is actually that much rebuilding
going on.

# Performance

I have no idea how poorly or how well this would do. If you have a bunch of
mutable data, it's probably going to be terrible since the whole heap would
get scanned at every collection. But, if mutation is just used for short
build-and-freeze scenarios, then you should be able to get fast bump allocation
and never have to scan old (seldom-accessed) heap objects.

# Multi-threading

So, this scheme does not let you share mutable objects across threads.
Similarly, you cannot share anything that references mutable objects
across threads. I think that's fine because synchronizing access to
mutable objects is expensive and creates difficult-to-detect possibilities
for errors. Sharing immutable data with an `MVar`-like construct should
be fine. The only tricky thing is this makes the garbage collection routines
on different threads interfere with one another. One solution is to just say
that each thread is only responsible for managing counters to objects that it
allocated. Any counter adjustments to data allocated by another thread
get shoved into a buffer, and then you push the buffer over to the other
thread and let it apply the adjustments during its collection. This means
that some objects will not be collected promptly, but it also means that
there is no synchronization required for counter updates (or changes to
any bitsets).

Does that really work though? You also have to somehow push over information
about the retained bit. Yeah, I think its fine. You just have to make sure
that any updates to the retained bit and the reference count for an object
get pushed atomically. (Not hard since everything is pushed together.)
That way, if the object stopped being referenced by the stack but got
pushed into another object, the owner thread would increment the RC before
setting it to unretained. 

Oh, the retain bit is tricky. If an object is shared across several threads,
then the idea of retention doesn't really make sense any more. For the
owning thread, sure, it can walk its own stack to figure out retention.
But the others, I don't know what they shoud be doing with that information.
Here's an option: do the bitset thing just like the owning thread does,
and then at the end of collection, if retention goes true-to-false or
false-to-true, include an RC increment or decrement in the pushed counter
changes. If it doesn't change, do not include anything.

There is another difficulty. What about when a thread terminates? One option
is to say "you are not finished until all the memory you gave out becomes
unreachable". That is, the thread just sits there running another collection
cycle every time it gets updates. That is a truly terrible idea. Better
ideas include:

* Transfer ownership of blocks. This makes the most sense when all shared
  memory was shared with a single thread. It might be hard to figure out
  who should get it though.
* Recycle threads. Keep running GC periodically if nothing needs to use
  the thread, but then when someone spawns a new thread, then this thread
  is used to recycle the garbage.

Neither of these are great. I don't like the idea of dumping a bunch of
extra responsibility on a spawned task that didn't even expect to be
interacting with other threads for GC. Here's one other option:

* The eternal garbage thread. Transfer ownership of blocks to one monster
  thread that just keeps shared objects that were disinherited by their
  original owner.

I like this idea. It does not place a burden on unwitting threads. Plus,
you could still do more sophisticated ownership transfers in special cases.
For example, A forks B and B computes a result, passes it to A through
an MVar, and then terminates. The clear choice for the new owner of B's
memory is A. After all, A is the only thread that can see anything B
allocated. You could have a `forkAndAssumeMemoryOwnership` for this
situation.

The only big disadvantage of the monster thread is that it might lead
to fragmentation problems. This could be addressed with MESH, but that's
not a great solution. We really should try to transfer blocks to other
threads that have been using them.

# Obsolete Notes

Is this a good plan? Let's step back and consider the goal. The goal is to
support mutable references without introducing a write barrier. Write barriers
introduce unnecessary overhead for quickly building and freezing small
structures. If you want to avoid a write barrier, then you must trace all
mutable objects on every minor GC (they are all roots). When you combine
this with reference counting, it means that you not only have to check the
fields of each mutable object, you also must know what they previously were.
I'm only aware of two ways to do this. The first is what I described in
this journal entry. The second is by taking a snapshot of each mutable object
during each collection, and then you can diff them. The advantage of the
approach I suggest here is that a bitset naturally consolidates all mutable
references to the same object. Since everything mutable has to be scanned
during every collection, you do not really need a count that includes mutable
references. You just need to know "did anything mutable point to this?", not
how many mutable things pointed to it.

There is one problem. When something mutable goes out of scope, we need to
make sure that anything that it referenced gets its retain bit reset. So,
we actually need to keep both the previous list of blocks and the current
one, and we must consider the union of the two when visiting the per-block
bitsets.

Is this all worth it? Not sure. It is certainly complicated, but the overhead
seems really low as long as you don't keep too many mutable objects around.
