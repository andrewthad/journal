# Splitting up pointers

What if the pointers referred to by an immutable object were all stored with
relative addresses? We want to make sure that access time is still `O(1)`
for fields in an object, and we want to make sure that we can still
address some large amount of memory, at least 256GB. How can this
be accomplished?

First of all, why do this? One really nice thing about this is that it
would make it possible to `mmap` data into an application and not require
any pointer fixups on address reservations.

The easy case is if the only field with pointers is an array of pointers
that's unpacked into the data constructor. It's easy because we can use
the base object's address as a base pointer. There is a bit of trickiness
with building the object to begin with since you have to do some address
subtraction when freezing the object. (When mutable, the object would
use absolute addressing and would switch to relative on a freeze.) But
to actually get the value at a certain position, you just multiply the
number of bytes per pointer offset that were required to find your place
in the array.

Let's say that there is an object with a dozen pointer fields. We could
do the same thing we did with arrays, but now we have this weird problem
with accesses. That is, they are not cheap like they would normally be.

Let's try something more simple. What if we always use 4 bytes per offset?
This is kind of like how the JVM does pointer compression. Now, the catch
is that an object have a field that is located further than 2GB from it in
either direction in memory. This is an unfortunate limitation. Can it be
worked around? One candidate solution is to use 8 bytes for the offset
instead. That works, but I hate the wasted space from doing that. Another
(frightening) possibility is to map the same physical address space to
multiple virtual addresses. This requires `memfd_create` if the memory
is not backed by disk. Playing with virtual addressing like this is odd,
but it should work. You would have to be able to do this promptly though.
You cannot wait until GC because you have to have an offset available
at creation time. In an application that consumed a lot of memory, the
overhead of this strategy would be unacceptable.

Another option is the unconditional compression of all heap objects.
The compression would cause all pointers to be relative, and to use
any heap object, it must first be decompressed to the stack, and then
pointers could be dereferenced. I dislike this strategy because it
requires compressing objects in the nursery that might never even be
promoted.

The most simple thing I can think of is to just use 5-byte pointers
or 6-byte pointers. A 5-byte pointer gives you 1TB of addressable
memory, which is great, but then you have to coax `mmap` into
putting things into virtual address space that's near you. This
is doable but a little annoying. With 5-byte pointers, you can
fit 12 pointers in a cache line, which is nice (with 8-byte pointers,
you can only fit 8). Getting a pointer field out of an object would
look like:

    LOAD r0, base[FOO_OFFSET]
    AND r0, r0, 0x000000FF_FFFFFFFF
    ADD r0, r0, base

Building objects would be kind of annoying because you would have to
write the fields in a specific order, and you would have to subtract
the base pointer from each one before writing it. But that's not
too bad. On x86, it might not even be necessary to do the tricky
stores for objects that are small enough. It may be possible to
stick the absolute pointers in a vector register, apply the subtraction
to everything, and then shuffle the bytes that matter into place
and perform the write. This would only work if you were dealing with
8 or fewer pointers, but it might improve performance in that case.
I'm not sure.

To look at a practical situation, let's consider any kind of medium-fan-out
tree-like structure. Something like:

    data Node = Node
      { metadata : Word64
      , children : Array Node | len <= 16
      }

Various operations on the children:

* Indexing: multiply index to 5 to find base, then load, mask out upper
  bits, and subtract base.
* Scanning: like indexing but we can take advantage of strength reduction
  to avoid any multiplication.
* Insertion: This is the tricky one. The offsets are relative to a base
  pointer, and since we are building a new object, the new base pointer
  will be different. Take the difference in the base pointers and then
  apply that difference to each offset while performing the copy. We may
  use SIMD to apply this difference to 8 elements at the same time. This
  requires shuffling, subtraction, shuffling again, and then a masked write
  of at most 40 bytes. For an array with sufficient guarantees around the
  size of the children, the looping construct could be omitted.
