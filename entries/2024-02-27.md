# Type-Driven GC Optimizations

## Escape Analysis Without Lifetime Analysis

I've probably written this down before. Suppose that a value of some type T is
allocated in a function that returns a value of type S. If the type S does not
contain any values of type T in it, then the allocated T cannot escape.

    function(x : Int)(S):
      t = allocate T { ... }
      ...
      s = ...
      return s

In this case, we may safely allocate `t` on the stack since it cannot possibly
appear in `s`. It is possible for some of the fields of type T to be boxed, and
those may appear in type S. That's fine. We do not need a complete "no overlap"
guarantee for this to work.

## Rolling Back Bump Allocation per Data Constructor

Suppose that we have a separate bump allocator for each data constructor.
(Not just for each size class.) Now suppose that we have a function like
the one above but with a potentially unbounded number of allocations of T:

    enumerate = function(n : Int)(Array T) { ... }
    function(n : Int)(S):
      ts = enumerate(n)
      ...
      s = ...
      return s

The values of type T could not be allocated on the stack. But the GC can
still be clever here. At the beginning of the function, we record where
the bump allocator is for certain types (explained later). We have to record
both the block and the position within the block. Additionally, we record
the total number of minor collections. For example, at runtime, we might say:

* Minor collection counter: 674639
* `T`: Block 1007, Position 24
* `Array T`: Block 762, Position 2248

We only mark the positions for data constructors that are both (1) non-escaping
and (2) might be allocated by the program during the execution of the function.
During code generation, we insert code to record the necessary data at the
beginning of the function. At the end of the function, we check the minor
collection counter. If it has changed, then we do not do anything special.
If it has not changed, then we restore all of the bump allocation arenas.
If the same blocks are still in use, this is simple. Just change the position.
But if the blocks have changed (if either of them was filled), we need to
revert that. Every arena block needs metadata that records its predecessor.
This means that the runtime can work its way backwards through the blocks,
pushing them back onto some kind of "free block set" as it goes.

One pathological case to consider is where we get stuck allocating near the
end of a block. Our GC optimization could lead to lots of "fetch a new block"
followed by "free the block" operations that would not have happened if we
had not introduced the optimization. This pessimization can be defeated with
some kind of check like "if we would have rolled back to a position that is
within 512 bytes of the end of a block, use position 0 in the successor
instead".

This optimization only helps for functions that do not allocate so much
that they force a minor collection to occur. Arena sizing is all over the
place for languages with GC nurseries. For GHC's runtime, I've heard of
numbers ranging from 1MB to 128MB.

Also, the windows for this analysis do not have to be function bodies.
We can put these windows anywhere. There are two complications:

1. If windows are nested, then things are more simple. If a window
   can overlap another window without being completely inside of it,
   then it possible for an end-of-window arena inspection to observe
   bump allocators moving backwards. There isn't a soundness issue here.
   If the inspection sees backwards motion, it just doesn't need to do
   anything. But if this happens, the runtime does not reclaim objects
   allocated between the first window end and the second window end.
2. If we insert all possible windows, the performance would be awful.
   We do not want to be checking the positions of dozens of bump allocators
   all the time.

Starting by creating windows that align with function bodies makes sense,
and it makes the behavior predictable.
