# Where to Put Reference Counts

In a multithreaded settings, where should reference counts live? The
conventional wisdom is "with the object's fields", and this conventional wisdom
might be the right answer, but I've been thinking about other possibilities.
The first question is "Why not put it with the object's fields?" If you are
working with thread-shared immutable objects, it's a shame to stick a counter
in with the other immutable data since it means that if a thread ups the counter,
then the resulting cache line invalidation would means that other threads that
were just trying to read the fields would need to reload the cache line even
though the fields these other threads care about didn't change.

There are several options I am aware of:

* Put counters with the objects. Already discussed.
* Put "pointers" (probably indexes into an array) to counters in each object.
  Use a big global table of offsets.
* Big global table but without pointers/indices. Index is determined by
  memory address of the object. 
* Counters per block at the beginning of the block.

The detriment of any design that moves the counters out of the objects is
that updates to counters become cache-incoherent.  I'm going to dig into the
last option (counters per block) because it seems promising. What if we
have a block of 64B objects? Let's assume 4KB pages. We could pack 64 64B
objects onto a 4KB page. Cool. But, what if we put a 1-byte counter for
each object at the beginning. That is, we reserve 63B at the beginning of
the block, then add 1B of padding, then store 63 64B objects on the page.
This scheme appeals to me for several reasons:

* No unneeded invalidations for other threads that are just reading.
* No need to store index to counter.
* Counters are packed together. Objects in the same block are likely
  to have been allocated at the same time. (That might not be true.)
  Counter decrements are may happen in a cache-coherent way.

Most importantly, we have a straightforward option for counter overflow.
What is counter overflow? I read a paper (and I cannot remember which
one it was) that cited an emperical study that showed that over 99%
of counters in reference-counted programs can be handled with three bits.
That is, the number of references to an object do not usually get higher
than 8. If you opt for a low-precision counter, then you have two options
for objects the need a big counter. You can stop counting once there are
too many references and fall back to tracing collection. Or you can store
the true count in an auxiliary data structure. Falling back to tracing
collection is appealing if you are already planning on adding a tracing
collector to help collect cyclic data. But I don't want to do that. So,
I like the other option of having an auxiliary data structure with the
accurate count.

Where should the accurate count go? It would be cool if there was somehow
space on the page for it. But this is not possible, well, not without
unconditionally reserving the space. [Down for the Count](http://rifatshahriyar.github.io/files/others/rc-ismm-2012.pdf)
mentions the possibility of using a hash table for big counters. One
possible simplification of this technique is to use association array
rather than a hash table. At first blush, this might seem ridiculous,
but the number of objects referred to by more than 256 other objects
must be small. Each reference costs the size of a pointer (let's say 8B).
So, the amout of memory needed to store 256 references to the same object
is 256 * 8B = 2KB. With only 1GB available memory (this is small, but humor
me), we could say with certainty that there are no more than 512K big-counter
objects. That's still way too many. So, perhaps we could bump the counter
to 2B instead of 1B. The cost of 65536 references to the same object is
64K * 8B = 512K. So you could have at most 2K of these in a 1GB heap.
And that's the worst case possible. I suspect that the in-practice worst
case would be something like a dozen and that all of these super-shared
objects would be strings.

Maybe it is just safer to stick with the tried-and-true hash table and
keep the counters down to 1 byte. Or maybe it's better to stick to
simple 4-byte counters and then not have to worry about overflow.

Also, one possible optimization is to use a bit from each counter as
an indicator of whether or not the object has any pointer fields. Why
is this useful? It means that if the counter hit zero, then rather
than having to look at the object's type (in the object itself) to
check the layout of the object, we could avoid that load. It would
be nice to avoid that load because a deallocated object probably has
not been touched in a while, and we do not particularly want to bring
it into the cache if we do not have to. (If it has pointer fields, then
of course we have to load the object into memory). I'm not sure if this
is a worthwhile optimization though. I've never seen any empirical studies
on what percentage of objects contain pointers.
