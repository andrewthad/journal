# Runtime Support for a Builder

## Plain Old Haskell

In the Haskell ecosystem, I've seen two different kinds of builders.
The first is a cons list:

    data Chunks = More Bytes Chunks | Done

You can only push cheaply onto one side of this. The other builder
is roughly:

    newtype Builder = Builder (forall s. MutableBytes s -> Int -> ST (MutableBytes s, Int))

It's more efficient, but you have to be careful, and if you aren't
careful, you end up allocating closures. I'm unsatisfied with both
of these builder types. Here's something close to the builder I
really want:

    data Chunks
      = ConsLeft Bytes Chunks
      | ConsRight Chunks Bytes
      | Empty

    // Equivalently, with infix data constructors
    data Chunks
      = Bytes :> Chunks
      | Chunks :< Bytes
      | Empty

It's like a cons list, but you can push cheaply onto the beginning or the
end. It's kind of tricky to flatten out at the end. It can be done with
three passes:

1. Calculate total length and total number of chunks
2. Calculate each chunk's start position
3. Copy chunks

I think that passes 2 and 3 can be combined.

## Bring in the Runtime

Something interesting about any kind of chunk-based builder (including
the cons list that only support efficient cons on one side) is that most
`Cons` objects have a reference count of 1. For example:

    x.firstName :> " " :> x.lastName :> Empty
     "Roberta"     " "      "Chan"

Although the bytes themselves are aliased, the chunks are used linearly.
And if `x` happened to go out of scope after building this, then the
bytes might happen to be used only once as well. When it comes time for
a copying collector to copy this over to an old generation, what should
it do? If there is considerable sharing going on, then just preserve the
structure. But, if everything is only used once, then the garbage collector
itself could coalesce them:

    "Roberta Chan" :> Empty

This is a considerable improvement in space consumption and in cache coherence.
How often would this actually matter though? For large (multi-megabyte)
builders or for builders that get consed onto slowly over a long period
of time, this could improve performance. However, those cases are uncommon in
my experience. Usually, it's just: build, flatten, output. If output really
is the final operation, then vectored IO (`writev`) makes it possible to
avoid the flatten step. However, exploiting this is tricky.

So, in spite of this being a cool trick, I'm not sure that it would actually
ever lead to any meaningful performance gains.

## Fewer Indirections

There's one other twist on the data type that I wanted to explore. If the
data constructors support variable-length array fields, you could do:

    data Chunks
      = [Bytes] :> Chunks
      | Chunks :< [Bytes]
      | Empty

Making this easy to use requires buy-in from the compiler rather than the
runtime. Basically, the compiler would rewrite

    [x.firstName] :> [" "] :> [x.lastName] :> Empty

to

    [x.firstName, " ", x.lastName] :> Empty

This would cut down on indirections, and we wouldn't need to wait until
GC time to do it. It's easy to just build this correctly. One possible
optimization opporutinity would be that, for small statically known character
sequences (probably 6 or fewer characters), we could store the character
sequence directly instead of a pointer to it. I'm not sure if this is
worth doing though.
