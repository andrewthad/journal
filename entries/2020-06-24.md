# Lessons from Attempting to Implement Type Checker

Higher-kinded types have a slight complexity cost. When resolving
the types of fields in data constructors, you have to walk the
spine of the type to inspect the type constructor application.
Doing this is inconvenient. It would be easier if type constructors
always had to be fully applied. Of course, then you lose HKT.
Going forward, I will probably just see if I can get further
by dropping support for HKT.

Taking inspiration from [Let Should not be Generalized](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tldi10-vytiniotis.pdf),
I decided to disallow let generalization entirely. Both type variables
and rep variables can only be brought into scope in a top-level declaration.
This makes things more simple. For example, the `typecheck` function now
only needs to return a type, not a type scheme. Consequently, instantiation
is only allowed to happen when a top-level (non-local) expression is used.
And that instantiate must be full instantiation. This does appear to
actually simplify things, which is nice.

Lifting type schemes to the type level (runtime rep schemes) appears
to work. You end up with types like this:

    map : forall {ra,rb} {a : Type ra, b : Type rb}.
      (a -> b) -> List {ra} a -> List {rb} b

This does not give you quite the same thing as GHC's `PolyKinds`.
You can only quantify over runtime representations. What's kind
of weird is that top-level expressions end up with a type scheme
and a rep scheme, and top-level types only end up with just a rep
scheme. So `List` looks like this:

    List : forall {ra}. Type ra -> Type Boxed

There is a question of whether tuples should be treated like any
other data type. I think that they actually need to be built in
and special. This is because other data constructors need to
reference tuples. Consider cons:

    cons : forall {ra} {a : Type ra}. <a, List {ra} a> -> List a
    cons <42, cons <11,xs>>
    cons(42, cons(11,xs))  // Alternative syntax

It really does need to have this type if we want to avoid currying.
If data constructors only accept a single field, using tuples like
this, then tuples themselves cannot be defined in the language. It
is possible to reduce the syntactic burden of this somewhat by
allowing some uses of constructor to omit the tuples part (pattern
matches and data constructor declarations). Even if data constructors
do admit multiple fields and we wrote tuples out as a data type, we
could not construct them.

I've only been focusing on a core language, so I haven't tried to do
any type inference yet. Having to write out all the types is a little
tedious, but it isn't really that bad.

My goal is to build up enough of a core language to make it possible
to implement B+ Trees. For this, I still need to add two things:

* Fixed-point combinator
* Boxed array type

And then after that, there is the question of how to speed things up
by taking advantage of multiple data instruction sets. There are two
ways to go about this. One is to support vector types and put fixed-length
vectors directly into the data constructor:

    Tree : Type Boxed -> Type Boxed
      Branch : Vec 8 Word64 -> Vec 9 (Tree a) -> Tree a
      Leaf : Vec 8 Word64 -> Vec 9 a -> Tree a

Modern processors can scan the whole line vector without any branching,
which is cool. The other option is to use larger boxed arrays, probably
with a fanout of 128 or 256. What you want probably depends on how read-heavy
your workload is. If you are just reading, the higher fanout is probably
better (plus it helps mitigate some of the overhead of prefix compression
if that gets added). But for building maps in a persistent fashion, lower
fanout is probably the better choice.

This is getting off on a tangent, but I wonder what the best way to provide
access to a *general* B+ tree is. Common specializations of B trees include:

* `Map Text Foo`
* `Map Bytes Foo`
* `Map Word32 Foo`
* `Map Word64 Foo`
* `Map Word128 Foo`

And then there are some uncommon ones as well, recursive types as keys and
nonsense like that. For the uncommon things, I do not care too much what is
done since you are not likely to get good performance anyway if you're doing
something like that. But what about these common cases? Surely, even if
implemented with a module system, their implementations could share
some amount of code. Maybe they are all actually specializations of the
same thing.

    Tree : Type Boxed -> Type Boxed
      Branch : Keys N -> Array N+1 (Tree a) -> Tree a
      Leaf : Keys N -> Array N+1 a -> Tree a
    // Keys is a base-offset encoding that is missing the base.
    Keys : Nat -> Type Boxed
      K8 : Array N W8 -> Keys N
      K16 : Array N W16 -> Keys N
      K32 : Array N W32 -> Keys N
      K64 : Array N W64 -> Keys N
      K128 : Array N W128 -> Keys N
      KVarLen : Array N ByteArray -> Keys N


