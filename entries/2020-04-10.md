# Abstracting over the Operating System

Among higher-level languages, it is common practice for a standard library
to abstract over the operating system. The developer gets an interface to
sockets, files, etc. that is neither POSIX nor Linux nor Windows. The
argument for such an abstraction is that the programmer who uses builds
on top of it is rewarded with applications that run on any platform.
Empirically, this arguments seems compelling. Most high-level languages
do this. Let's consider networking. Haskell has the `network` library.
Golang has `net`, [described](https://golang.org/pkg/net/) as "a portable
interface for network I/O". Python has a portable networking in its standard
library. Here's how the [documentation](https://docs.python.org/3/library/socket.html)
describes the `socket` module:

> This module provides access to the BSD socket interface. It is available
> on all modern Unix systems, Windows, MacOS, and probably additional
> platforms.

Given that most standard libraries (or de-facto standard libraries) already
offer portable abstractions over things like sockets and files, I don't think
I need to waste time convincing anyone of the merits of this approach. The
rest of this post is a brief discussion of the detriments and some musings
about a different way to go about this.

What's wrong with these portable abstractions? Cross-platform interfaces must
aim for the lowest common denominator. That is, they must only support features
available in all targetted platforms. This means that a high-level application
cannot take advantage of platform-specific features for *any* supported
platform.

As an aside, it isn't totally accurate to say that cross-platform interfaces *must* aim
for the lowest common denominator. It's more accurate to say that they
*should*. It's possible to cheat a little. Haskell's `network` library does this. Functions like
`isSupportedFamily`, `isUnixDomainSocketAvailable`, and `isSupportedSocketOption`
are indicative of this. The intent is that an application would decide,
based on the information provided by these functions, how to procede
when setting up a connection. On windows, perhaps an application would
forego an attempt to use UNIX-domain sockets and skip straight to using
IPv4 to connect to 127.0.0.1. (This example feels pretty contrived though.)
To really be sure that an application built on `networking` is cross-platform,
it means that any time you set on socket option or use an address family,
you have to call `isSupported(Family|SocketOption)` first. And that's a
little odd sometimes. For example, I would expect that `AF_INET` would
be available everywhere. None of the IPv4 examples on the page
warn you to check with `isSupportedFamily AF_INET` before running them.
Besides, even if you discovered that `AF_INET` was not available on
some strange no-networking-stack operating system, what would you do?
Probably just throw an exception.

Then there are some pseudo-portable functions like `getPeerCredentials`.
The [documentation](https://hackage.haskell.org/package/network-3.1.1.1/docs/Network-Socket.html#v:getPeerCredential) claims:

> This is implemented with `SO_PEERCRED` on Linux and getpeereid() on BSD
> variants. Unfortunately, on some BSD variants getpeereid() returns unexpected
> results, rather than an error, for `AF_INET` sockets. It is the user's
> responsibility to make sure that the socket is a UNIX-domain socket.
> Also, on some BSD variants, getpeereid() does not return credentials
> for sockets created via socketPair, only separately created and then
> explicitly connected UNIX-domain sockets work on such systems.

To its credit, this function is documented very well. However, I would
only try using this on Linux since on some BSD variants (which ones?),
it's got some quirks. Despite all of the effort that's gone into
neat compatibility tricks like this, there are still things like `recvmsg`
`recvmmsg` that are not there. And to be clear, this isn't an issue
of "oh, those crummy maintainers". I really like `network`'s maintainers.
The problem is that you have to answer the portability story. I know
how POSIX `recvmsg` works, and I know how Linux-specific `recvmmsg`
works, but I don't know anything about networking in Windows, and
I don't know if it's better to shim these in Windows or to have a
`supportsReceiveMultipleMessages` constant and hope users remember
to use it.

Regardless of whether you go for lowest-common-demoninator or just
make users test for the existence of features before using them, you're
still going to be trying to unify POSIX, Linux, and Windows. The
portable unified API will inevitably be something different from
anything it abstracts over. This cuts off users from the wide base
of existing knowledge about platform-specific socket programming.
It means that I cannot grab some C code for POSIX sockets off of
StackOverflow and mechanically translate it to Haskell. This isn't
the worst thing in the world, but I do find this inconvenient at
times.

What's the alternative? What if platform libraries were structured
like this:

```
posix-api
  linux-api (depends on posix-api)
  darwin-api (depends on posix-api)
windows-api
```

And of course, you could still have the least-common-denominator
filesystem and networking libraries build on top of these. These
would change out their dependencies and large parts of
their code based on which platform they were compiled on. Higher-level libraries
like a redis client or an http client could use the least-common-denominator
library if they really didn't need anything fancy, or they could use
the platform-specific libraries (again, having to rewrite their networking
code two or maybe three times) if there were platform-specific
optimizations available.

Anyway, just some thoughts. No one ever does this, and it's probably
because most people are fine with the general interfaces. Maybe it only bothers
me because I do want access to a lot of Linux-specific functionality,
and I wish there was a way to organize things that would let me use anything
from the man pages.
