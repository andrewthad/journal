# Minor Problem with Sequitur Invariant

Sequitur outlines two invariants: digram uniqueness and rule utility.
Unfortunately, there are sequences that cannot be described by grammars
that satisfy both of these invariants. Consider the sequence:

    aaa

The digram `aa` appears twice, but it cannot be factored out with a rule.
This is not a huge problem, but it is annoying.

# Sequitur Simplified

I figured out a different way to build grammars that is more simple than
Sequitur. It's performance is probably worse though. Instead of going
character-by-character, it starts with the entire input sequence loaded
into one rule. The algorithm is:

1. Scan all rules (including the rule for the input) for digrams. Ignore
   digrams that consist of the same token twice (e.g. `aa`). Build
   a digram bag. 
2. Bulid the replacement map (key: digram; value: rule).
   First, scan the digram bag and look for digrams that are exact matches
   of existing two-token rules. Add these to the replacement map.
   Next, scan the digram bag and look for digrams that have a count of
   two or greater. Create new rules for each of these and insert the
   digrams and new rules into the replacement map.
   Note: not all replacements in the map will necessarily happen.
   Some replacements cause others to not happen.
3. If the replacement map is empty, exit.
4. Walk the RHS of each rule and apply the replacement map. The newly
   inserted tokens do not need to be considered for replacement. That is,
   replacement is not recursive in this step.
5. Identify underused rules (0 or 1 use) and delete them, inlining their
   RHSs into use sites. The rule corresponding to the input string is
   special and is not deleted by this step.
6. Deduplicate identical rules. These can show up as a result of the
   same rule getting built from two different sides. The original algorithm
   did not have a corresponding step, and I think it might not be possible
   for this to happen in the original incremental approach.
7. Go to step 1.

This strategy avoids dealing with digrams that are the same token twice
because handling them naively results in nontermination. Another simple
solution to this problem is requiring the such digrams to appear three
times in order to be added to the replacement map. It's not a great solution,
but it very nearly solves the problem with minimal fuss.

Also, step 5 could be done repeatedly until there are no more underused
rules at all. I don't think it affects the correctness of the algorithm.
