# Dependent Naturals and Data Constructors

What happens when we put a natural into a data constructor. Consider:

    data Node a
      = Branch
          { count : Nat
          , children : Array (Node a) | ?.len = n
          }
      | Leaf
          { count : Nat
          , elements : Array a | ?.len = n
          }

If we have a value `n : Node a`, then we can project without knowing which
data constructor was used:

    n.count : Nat

We have a projection `elements` that can be applied to a node `x` of type

    Node Int | ?.constructor = Leaf

Let's say that we have a `sum` function that adds up all the numbers in
an array:

    sum :
         {n : Nat}
      -> (Array Int | ?.len = n)
      -> Int

Now we can add up all the children of `x`:

    sum x.count x.elements

When we project out a natural and bind it to something, we have to preserve
identity. For example, we ought to be able to write this as well:

    c = x.count
    sum c x.elements

or even this:

    a = x.count
    b = a
    c = b
    sum c x.elements

Here's another possibility. Given two child nodes with the same length, we
should be able to zip them:

    ch0, ch1 : Node Int | ?.constructor = Leaf
    same : Proof (ch0.count = ch1.count)
    zipFoo ch0.count ch0.children ch1.children

But we really do not want to have to deal with being able to use non-natural
types in a dependent way, so maybe it would be best to not allow this. If you
needed to be able to do this kind of thing, you could define `Node` differently
and avoid existential quantification:

    data Node (count : Nat) a
      = Branch
          { children : Array (Node a) | ?.len = n
          }
      | Leaf
          { elements : Array a | ?.len = n
          }

Another option is

    data Node a
      = Branch
          { children : Array (Node a) | ?.len = &.len
          }
      | Leaf
          { elements : Array a | ?.len = &.len
          }

With this, the `Node` itself has a `len` property. I think that the first option
makes more sense because the count needs to exist in a tangible way (at runtime)
when you allocate a `Branch` or a `Leaf`. This suggests that arrays should be
treated similarly. Instead of

    index :
         {n : Nat}
      -> (Nat | ? >= 0 and ? + 1 <= n)
      -> (Array a | ?.len = n)
      -> a

We could have:

    index :
         {n : Nat}
      -> (Nat | ? >= 0 and ? + 1 <= n)
      -> Array n a
      -> a

Why? An array with an unknown length is essentially unusable. That's not 100%
true, but it's mostly true. Any garbage collector will need to know about
the sizes of these things, and the easiest way to make that information
available is to put it right there in the type. I'm not suggesting getting
rid of the existential-quantification construct from the beginning of this
post though. We still need that for sure.
