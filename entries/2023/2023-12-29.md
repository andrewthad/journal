# PL Design Lessons

These are notes for myself.

## Planning Ahead

All of other notes in this post points toward a recommendation that I am
making to my future self: at every stage, plan before writing code.
This includes planning the language syntax before writing a parser,
planning the type system before writing a type checker, planning the
primops, the module system, the way lowering from one stage to the next
works, all of it. The best way to do this is usually by writing out
several specific examples and then seeing what happens when I try to
manually apply an algorithm. The reason that planning is so important
is that I have not found a good way to reuse code across attempts at
writing a PL.

## Ineffectiveness of Cross-Stage Datatype Reuse

I have never been able to share data types across stages. For example:
non-ANF and ANF, modules (plus functors) and plain old functions. It's
a dead end every time.

## Boilerplate When Lowering

Because of the difficulty of reuse, there is a lot of
boilerplate when lowering from one stage to the next. It's not difficult
to write. There's a lot of code that says "match this data constructor
for the higher level representation and output the same data constructor
for the lower level representation". The fields get transformed by some
simple traversal.

## Parser Boilerplate

I've come up with a strategy that I like for parsers. This only works
for languages that are not sensitive to whitespace. During tokenization,
we go ahead and match open brackets with close brackets. We do this
for round brackets (paretheses), square brackets, and curly brackets.
We do not do this for angle brackets because those characters tend to
get used for other things.

This makes it easier to write the parser, and it still feels very similar
to writing out an LL(1) parser in code. The main difference is the better
experience when doing a repetition (e.g. parsing a variable number of
function arguments).

In spite of this, there is still a lot of boilerplate, and I don't see a
good way to reduce this. I've played around with other strategies for
writing parsers, and I cannot seem to do much better than this.

## Identifiers and Reserved Keywords

My token type has a data constructor that looks like this:

    data Token = ... | Identifier Keyword Text | ...

And `Keyword` has a `None` data constructor. This means that a parser may
distinguish keywords from other identifiers, but it doesn't have to. The
reason that I like this is that it makes it easy to allow any name to be
used as a field in a data type. For example, let's say that `module` is
a keyword. We ought to be able to use `module` as a field name anyway:

    Binder = constructed
      { module : Text
      , file : Text
      }
    ...
    let theModule = myBinder.module

Originally, I thought it would be nice to allow keywords to appear as any
identifier. But, I have realized that, while this works for field names,
it does not work for let-bound identifiers. Field name are always introduced
in some way, typically by a period, which keeps things unambiguous. But
locally defined binders are initial tokens in sequences that a parser
recognizes. If we allow `let module = ...`, then we elsewhere must allow
`foo(module,55)`. Now our parser becomes at least LL(2) since we must
check to see if we have `module { ... }` or `module` without a curly bracketed
section after it.

There are two ways to avoid this. One is to just forbid a bunch of keywords
from being used as binders. This is normal, and a bunch of languages do this.
The other option is to introduce binders with a keyword at their use sites.
For example, consider:

    call(id foo)(id module, 55)

Here, we have required that `foo` be prefaced by the keyword `call` and that
`module` be prefaced by the keyword `id`. Other examples of this style:

    project(id myPerson)(age)
    jump(finish)(id accumulator)
    apply(id myModuleFunctor)(module { ... }) // Apply MF to unnamed module

Notice that the second argument to `project` and the first argument to `jump`
do not have to be prefaced by anything because fields and join points
cannot be abstracted over. We have reused the same `id` keyword for
locally bound identifiers, functions, and modules/functors because
the keyword further to the left makes it clear which context should be
used for lookup. Top-level constant data not play nicely with this. We need
to be able to distinguish between a function-local value binder and a
binder for nonlocal constant data. We really just need to be able to distinguish
local binders from nonlocal binders. Maybe sigils would work:

    call $foo (@module, 55)
    project @myPerson age
    jump finish @accumulator
    jump finish $myNonLocalValue
    apply $myModuleFunctor module { ... } // Apply MF to unnamed module

I think this should work nicely. It's not a great user-facing syntax, but
I don't mind looking at it.

## Primops

Certain primops can accept non-value arguments. Consider addition and array
indexing:

    add : (s : Signedness) -> (w : Width) -> Integer s w -> Integer s w -> Integer s w
    index : (a : Type) -> Array a -> Integer Signed 64 -> a

We have signedness, width, and type. In the case of addition, the signedness
and width arguments impact the behavior of the function (notably, overflow
behavior). That is, `add` is not parametrically polymorphic. But `index` is.
How might we represent these? Here is one way:

    data Op
      = Add
      | Index

Here is another way:

    data Op
      = Add Signedness Width
      | Index Type

And finally, we have a hybrid approach:

    data Arg = Type | Signedness | Width
    data Op : [Arg] -> Type where
      Add : Op '[ 'Signedness, 'Width]
      Index : Op '[ 'Type ]
    data InterpretArg : Arg -> Type where ...
    data Rec : forall (k : Type). [k] -> Type where ...
    data SaturatedOp = forall (args : [Arg]). SaturatedOp (Op args) (Rec InterpretArg args)

I have tried all of these over the last few years. An important question
here is "what about variable types, variable signedness, and variable
widths?". The first approach makes it more likely that we can reuse
the `Op` type across different stages. Lower-level stages are less likely
to support any kind of polymorphism in these positions. And higher-level
stages are more likely to support polymorphism.

## Lowering Higher Kinded Types

One option for compiling polymorphism is module functors. For example:

    identity : forall (a : Type). a -> a
    ==>
    identity = functor(a : Type) function(x : a) { x }

And here is polymorphism in data types (actually this is shown better in
the 2023-12-21 entry):

    type Option a = constructed { Some a | None }
    fromOption : forall (a : Type). Function(a,Option a)(a)
    ==>
    Option = functor(a : Type) constructed { Some a | None }
    fromOption = functor(a : Type) (function(...){} : Function (a,Option(a))(a))

This lowering might work with HKT. I wrote about this on 2023-12-21. For example,
what if we tried to make a signature for `Foldable`?

    foldable = Module
      { F : Type -> Type
      , len : F a -> Int
      , sum : F Int -> Int
      }

When we lower this, we get:

    foldable = Module
      { F : Functor(Type)(Type)
      , len : Functor(a : Type)(Function(F(a))(Int))
      , sum : Function(F(Int))(Int)
      }

## Types with RHS in Module Signatures

In SML, you can have a type with a RHS in a module signature:

    signature {
      type a = Int
      foo : a -> Bool
    }

I am not sure that it is important to support this. The above signature could
be rewritten as:

    signature {
      foo : Int -> Bool
    }

This causes it to match more modules. I think that, when interpreting SML's
`where type` construct, we could just eliminate the type from the signature
and substitute. This treatment simplifies things somewhat, and it makes it so
that signatures cannot contain types that depend on other types in the
signature.

## Mutually Recursive Functions

We could support some kind of concurrent binding for mutually recursive
functions. Like this:

    { myFunc1 = function ...
    ; rec
      { foo : Int -> Int
      , bar : Bool -> Int
      }
    ; myFunc2 = function ... // may refer to foo and bar here
    }

It's probably worth just doing this. Mutually recursive functions are really
important in certain domains (like parsing), and so I would have to add this
eventually anyway.

## Mutually Recursive Modules

I should think about mutually recursive modules again. I gave up on this a
while ago, but I understand evaluation better now, and there might be a
simple way to do this. If I'm already supporting mutually recursive functions,
I might be able to get the other constructs working the same way.

## Refinements and Subtyping

If we have a function signature `Function(Int)(Int)`, should we be able to
pass a function with the signature `Function(Int)(Int | >50)` where it is
expected? Yes.
