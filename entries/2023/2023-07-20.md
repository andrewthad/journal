# Region, Stack, Heap

Trying to figure out how to fake stack allocation with regions, I have
become convinced that it's just not possible. The language needs an
explicit understanding of what the stack is.

There is a related but
different problem which is that certain types (e.g. small tuple types)
need to be consider "value types", that is, always copied to and from
the stack when accessed. For example, consider something like:

    Array (Int,Int)

We want this to be an array of integers (with twice as many integers
as the length suggests), not an array of pointers. For this to be
possible, the tuple type needs to be a special type. Lots of other
types (e.g. `Option`, `Either`) should work this way as well.

But this doesn't solve our original problem. It feels orthogonal.
We want to be able perform certain allocations on the stack when we
can tell that they are non-escaping. We want to pass these around by
reference, not by value.

The most straightforward thing I can think of is scoping
stack-allocated values. For example:

    with (x : Person):
      x.name = "baz"
      x.age = 42
      y = freeze(x)
      y.age

I don't really like this solution though. Scoping the value makes
dependencies unclear. If we have multiple `with` statements, they should
commute, but we end up needing extra logic to handle this. What if,
instead, we did allow stack-allocated things to be returned from functions?
Let's try it:

    myFunc(name : String):
      x = alloc {stack} Person
      x.name = name
      x.age = 42
      freeze(x)

This changes the function's calling convention. The function cannot actually
place the `Person` in its own stack space, so instead, the caller provides
a pointer into its own stack (this might actually be a much more complicated
scheme since there could be multiple stack-allocated objects, and it is
possible that they all live in different stack frames).

The caller ends up with a `Person` that lives on the stack, but again, we
face the question "Who's stack frame does this live in?" And the answer
is "it depends". We use escape analysis to make the decision. If it is
possible for the stack-allocated object to escape, then the responsibility
is delegated to the caller. If it cannot escape, then the function can take
responsibility and provide an address in its own stack frame.

The trick that makes this possible is that nothing (not even another
stack-allocated object) can reference a stack-allocated object. So when we
have something like this:

    myFunc(...):
      x = alloc {stack} Person
      y = alloc {stack} Person
      if ...
        T: x
        F: y

Neither x nor y can be allocated in the `myFunc` stack frame because we do
not know which one will escape. Optimizations could change this since an
optimization might cause us to know which path is taken, which could make
it possible for an object that was previously designated as "escaping" to
be designated as "non-escaping". So, the calling convention is not stable
in the presence of optimizations. In fact, the calling convention cannot
even be predicted by the function's signature. This is a terrible story
for ABI compatibility, but I think it's fine.

Can we handle value types with the same strategy? Possibly. In fact, this
strategy sounds exactly like how we would want to handle an `Option` or
an `Either`. We still need value types to exist since we want it to be
clear what happens when they are used in a data constructor. But implicitly,
we may be able to reuse all the same machinery. So when the user writes:

    myFunc(..) returning (Either String Int):
      ...
      if(x):
        T: Left(err)
        F: Right(result)

It would be lowered to something like this:

    myFunc(..) returning (Either String Int):
      ...
      dst = alloc {stack} (Either String Int)
      if(x):
        T:
          dstL = use(dst,Left)
          dstL.left = err
          freeze(dstL)
        F:
          dstR = use(dst,Right)
          dstR.right = err
          freeze(dstR)

We really want both cases to use the same buffer. The whole thing actually
still works even if they don't, but the caller would end up allocating
extra space on the stack to make that work.

Another advantage of "on-stack" types is we can put them inside of arrays, and
they have the expected behavior (not causing an array of pointers to be created).
Maybe this distinction is avoidable though. If, for any type T, we allow both
`T` and `T!`, where the second form means that it lives on the stack (or is
unpacked into a data constructor), think about what each of these mean:

1. `y = xs[5]`, where `xs : Array T`
2. `y = xs[5]`, where `xs : Array T!`
3. `f(x : Person)`
4. `f(x : Person!)`
5. `y = p.pet`, where field `pet` has type `Pet`
6. `y = p.pet`, where field `pet` has type `Pet!`
7. `f(Int) returning (Person)`
8. `f(Int) returning (Person!)`

Most of them are clear, but what is the difference between 3 and 4? Are they
the same thing? In both cases, what ultimately gets passed in is a pointer.
Depending on what we actually do with `x` in the function body, we
might not need these to be two separate functions. If we read from `x`
and do not embed it in a heap-allocated object, then the same function
works for both. So we actually want there to be an "heapity polymorphic"
form, which would be preferred to 4 in all cases. Functions 7 and 8 are
certainly different.

In spite of all this, it might still be beneficial to be able to communicate
that certain types are always stack allocated. The extra syntax is noisy
and a little confusing. And we never want `Option` to boxed, ever. Well,
maybe if there is something large inside. So I don't know. It's tricky.

What about type variables? I think they should be able to be stack or heap
allocated:

    myFunc(Map a{s}, Int, a{s}) returning (Map a{s})
    choose(Bool, a{s}, a{s}) returning (a{s}) // all stack or all heap
    index(Array a{s}, Int) returning (a{s}) // all stack or all heap
    
So actually, any time there is a type variable, it should always be polymorphic
in its heapitiness. It's only concrete types where we should need to specify.

Actually, we definitely want the thing with on-stack defaults because types
like `Int` are never expected to be heap allocated. Maybe there should be a
choice to invert this like `Int*` to use a heap-allocated integer type. We
certainly want that for `Option`, so why not do it for everything.
