# Refinements on Integer Maps

What if we have a map where the keys are integers? What kinds of refinements
make sense. Tracking the maximum and minimum key might be useful. Consider:

    IntMap : Prop Integer -> Type -> Type
    Int : Prop Integer -> Type
    insert : Int p -> a -> IntMap p a -> IntMap p a
    empty : IntMap (\_ -> false) a
    empty : IntMap p a
    insert 5 myWidget empty : IntMap (\x -> x = 5) Widget
    insert 5 myWidget (insert 10 myWidget empty) : IntMap (\x -> x >= 5 and x <= 10) Widget

If we do not care about constraining the keys in any way, we set the refinement
to this:

    IntMap (\_ -> true) a

We may also want to allow the height to be tracked (if it's implemented as
a B-tree). We want to do this with a `Nat` instead since the height is
something that must necessarily exist:

    data IntMap : Nat -> Prop Integer -> Type -> Type
      Branch
        keyCount : Nat
        keys : Array keyCount (Int p)
        children : Array (IntMap childHeight p a)
        => IntMap (childHeight + 1) p a
      Leaf
        keyCount : Nat
        keys : Array keyCount (Int p)
        elements : Array (IntMap childHeight p a)
        => IntMap 0 p a

# Refinements for Initializing Arrays

When we first allocate an array, all the elements are undefined. We do not
want this undefinedness to be exposed the end user though. We need to prevent
users from accessing uninitialized array elements. What if we try to track the
initialization status of mutable arrays:

    // Assumes that we have linear or unique types
    MutableArray : Nat -> Nat -> Type -> Type
    allocate : (n : Nat) -> MutableArray 0 n a
    writeAndAdvance : a -> MutableArray i (n + 1) a -> MutableArray (i + 1) n a
    copy : Array n a -> MutableArray i (m + n) a -> MutableArray (i + n) m
    freeze : MutableArray n 0 a -> Array n a

This strategy is really simple. It requires the elements to be written in
order, and the runtime representation of this is a cursor into an array. This
handles a very common case. One neat property this solution has is that since
we are tracking how many elements have been initialized, we always have a
way to go from the cursor back to the beginning of the array. It only makes
sense to do this once everything is initialized. Above, we see a `freeze`
function, but we could also convert a fully initialized mutable array to
something a different mutable array type that allows random access and updates.

# Data Constructor Initialization: Fork and Join 

When we allocate a user-defined data type on the heap, all the members start
out with undefined values. We do not want to expose this to the end user.
Let's see how we might resolve this:

    me0 = allocate Person : (MutablePerson | ?.fields = {name=None,age=None,height=None}, ?.parent = None)
    me1,name1,age1,height1 = borrow [name,age,height] me0
    // me1     : (MutablePerson | ?.fields = {}, ?.parent = None)
    // name1   : (MutablePerson | ?.fields = {name=None}, ?.parent = Some me1)
    // age1    : (MutablePerson | ?.fields = {age=None}, ?.parent = Some me1)
    // height1 : (MutablePerson | ?.fields = {height=None}, ?.parent = Some me1)
    height2 = write(height1,height,100)
    // height1 : (MutablePerson | ?.fields = {height=Some (Int | ?=100)}, ?.parent = Some me1)
    name2 = write(name1,name,"bob")
    age2 = write(age1,age,50)
    me2 = join(me1,{name1,age1,height1})
    me3 = freeze me2
    // me3 : Person | ?.height = 100, ?.age = 50

The concurrent borrow construct makes it so that the ordering of the field
assignments does not matter. What about an unpacked array in a data
constructor?

    me0 = allocate Node(n): (MutableNode | ?.fields = {children=MutableArray 0 n Node,metadata=None}, ?.parent = None)
    me1,children1 = borrow [children] me0
    // children1 : (MutableArray 0 n | ?.parent = Some me0)
    children2 = ...
    // children2 : (MutableArray n 0 | ?.parent = Some me0)
    me2 = join(me1,{children2})
    // me2 : (MutableNode | ?.fields = {children=MutableArray n 0 Node,metadata=None}, ?.parent = None)
    // We still need to initialize metadata before doing a freeze.
    me3 = write(me2,metadata,myMetadata)
    me4 = freeze me3

What makes unpacked arrays different from ordinary fields:

* Scalar fields are tracked in the refinement with an `Option` type. They
  start out as `None`. Unpacked arrays don't need this because the `MutableArray`
  type already has its own way to communicate initialization status.
* When you borrow a regular field, the runtime representation of it is
  a pointer to the base object. When you borrow an unpacked array, you
  get an interior pointer. This suggests that unpacked arrays might need
  to be borrow separately from other fields.

# Struct vs Object

This issue shows up in C as well, but it's going to show up here. I would
like to have a way to bundle arrays with their corresponding sizes:

    struct ArrayWithLength a
      length : Nat
      array : Array length a
    type String = ArrayWithLength Char

Then we can write

    data Person
      name : String
      address : String
      height : Int

Person actually has 5 fields, not three. To access the fields:

    p.height
    p.name[length]
    p.name[array]
    p.address[length]
    p.address[array]

We might also be able to take an interior pointer with `p.name`, but I'm
not sure if allowing this is a good idea. We need to be able to
take interior pointers to unpacked arrays, but those are somewhat different.
Perhaps `p.name` could just be a shorthand for accessing both fields
individually. Then if we have some function

    takeFileExtensionSuffix : String -> String

We could just call it as `takeFileExtensionSuffix(p.name)`, and it would
really be passing two arguments. Alternatively, that function could be
written as:

    takeFileExtensionSuffix :
         (n : Nat)
      -> Array n (Char | p)
      -> (c : Nat, d : Nat, c + d = n, Array c (Char | p))

Then the shorthand no longer works.

For interior pointers to arrays, we need to be able to do something like
this:

    data IpNode a
      addr : Array 16 Unsigned8 // unpacked
      value : a
    myIpNode : IpNode
    myIpNode.addr : (Array 16 Unsigned8 | ?.parentType = IpNode)

For the parent, how much do we need to know? With mutable object, we had
to track the specific instance of an object that was the parent. This was
required because we needed to join the two back together (at runtime, just
dropping the interior pointer). However, with an immutable object, we
no longer have to worry about joining back up. So, we only have to track
the *type* of the parent. Why do we need the type? The type matters because
an automatic memory management system needs to be able to find the base
object. Depending on the system, this information might not be needed,
but some systems require it.
