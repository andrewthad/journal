# Kafka Wire Protocol and Forward Compatibility

## Background

Apache Kafka features a wire protocol with versioning. Different versions
of request and response messages are incompatible with one another. Every
time someone decides that there is an additional field that would be good to
include in a request or response, the Kafka wire protocol spec (which is
actually pretty easy to understand) issues a new version of that message type.
Kafka servers and clients have to negociate to figure out the highest version
of each message types that they both understand. Then they can communicate.

The [Kafka Protocol Guide](https://kafka.apache.org/protocol) is instructive in
at least two ways. It explains how to craft messages to communicate wih Kafka.
It also documents the evolution of the protocol over at least a decade. As an
example, consider "Produce Request" version 3:

    Produce Request (Version: 3) => transactional_id acks timeout_ms [topic_data] 
      transactional_id => NULLABLE_STRING
      acks => INT16
      timeout_ms => INT32
      topic_data => ...

The only different between version 3 and version 2 is the introduction of
the (optional) `transactional_id` field. Let's consider another example.
Here's the "Produce Response", version 1:

    Produce Response (Version: 1) => [responses] throttle_time_ms 
      responses => name [partition_responses] 
        name => STRING
        partition_responses => ...
      throttle_time_ms => INT32

The only difference between version 0 and version 1 is the introduction of
the `throttle_time_ms` field, described in the docs as:

> The duration in milliseconds for which the request was throttled due to a
> quota violation, or zero if the request did not violate any quota.

These two examples illustrate what most of the changes to the Kafka wire
format look like. In the first case, a newer version of Kafka introduced a
a new feature (transactions) that old clients could safely ignore. (Even
today, Kafka transactions not commonly used.) In the second case, the server
started exposing more information to the client. A client ought to
be able to ignore this new information. 

## Analysis

Kafka's wire protocol could be the poster child for any structured data
format that offers forwards and backwards compatibility in the presence
of simple schema changes. JSON, Protobuf, and Flatbuffers are contenders
in this space, although JSON would be inappropriate for Kafka since it cannot
represent binary data efficiently. Personally, I think that Kafka could
have benefited from using Protobuf (or even just borrowing some of the
ideas from Protobuf). It would make it much easier for those of us who
write Kafka clients.

The initial release of Kafka was January 2011, and the initial public release
of Protobuf was July 2008. I don't know what state Protobuf was in at the
time that Kafka was being designed. Maybe it wasn't a viable option at
the time, or maybe the developers just weren't thinking that the Kafka
wire protocol would ever end up evolving as much as it did. Recently,
[KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields)
added optional tagged fields to Kafka. These are presented in the spec as
`TAG_BUFFER`. So Kafka is moving in Protobuf's direction. It just took
a while.
