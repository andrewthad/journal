# Variation on Debruijn Indices

A drawback with debruijn indices is that they cause terms to be rewritten
with binders are introduced (CSE) or removed (DCE). To fix the
rewrite-on-remove problems, we can add a "tombstone" construct to the
language:

    let _ = compute($0,$1) -- in some context where $0 and $1 exist
    let _ = compute($0,$0) -- this is unused
    $1 + $1

When we remove the unused binding and renumber the identifiers, we get:

    let _ = compute($0,$1)
    $0 + $0

But instead, what if we had a placeholder construct:

    let _ = compute($0,$1)
    let {}
    $1 + $1

This placeholder gets cleaned up by a later pass.

That solves the problem with DCE, but what about introducing bindings?
This seems worse. We need to have a position available where we can
bind without changing the indices of other terms. The concept of a
"binding group" helps a little. That is, we could safely perform
this transformation:

    group-let
      _ = ...
      _ = ...
    $0.0 + $0.1

into this:

    group-let
      _ = ...
      _ = ...
      _ = ...
    $0.0 + $0.1

Adding to the end of a group is sound and does not cause us to rewrite
terms. But it is not generally possible to introduce new bindings in this
way. What about a scope modifier that increments all references by one?
This is kind of weird, but here's the idea (presented without groups):

    let _ = ...
    let _ = ...
    let _ = compute($0,$1) + 17  // Line A
    let _ = compute($1,$2) + $0 + $1 // Line B
    $0 + $1

CSE detects that the calls to `compute` in lines A and B are the same.
We introduce a new binding for this:

    let _ = ...
    let _ = ...
    let _ = compute($0,$1) // Common term
    let _ = $0 + 17      // Line A
    let _ = $1 + $0 + $2 // Line B
    increment
    $0 + $1

Everything below `increment` gets to stay as it was before. This is unsatisfying
because we still had to perform a renumbering of Line B. Let's try breaking this
into two parts: (1) introduction of the binder for the common term
and (2) replacement. It's really just part 1 that's difficult.

    let _ = ...
    let _ = ...
    let _ = compute($0,$1) // Common term
    let _ = compute(_,_) + 17  // Line A
    let _ = compute(_,_) + $_ + $_ // Line B
    $_ + $_

How can we make it so that this introduction does not require rewriting
the subsequent term? What if we let each index contain subindices?
When building a context, subindexed let bindings would hang off of the
main index:

    data Context
      = ContextNil
      | ContextCons
          Value
          Context -- subcontext
          Context -- next context

With this, we can write:

    let _ = ...
    let _ = ...
    let _._ = compute($0,$1) // Common term
    let _ = $0.0 + 17        // Line A
    let _ = $1.0 + $0 + $1   // Line B
    $0 + $1

We can introduce any number of levels this way. For example, we may write:

    let _ = ...      // Line X
    let _._ = ...    // Line Y
    let _._._ = ...  // Line Z

Here, line Z could refer to `$0` (X) and to `$0.0` (Y), so these are not quite
a group. Concurrent binding is not implied here. This is really more of a
trick to give us numbers in between the integers that can be used as debruijn
indices. We could accomplish something similar by making the indices rational
numbers and giving each binding a weight. We are also allowed to do this:

    let _ = ...    // Line T
    let _._ = ...  // Line U
    let _._ = ...  // Line V
    ...            // Line K

Here, line K can refer to U as `$0.0` and V as `$0.1`. Is it really useful
to support the reuse of a level though? I don't think so, and it is confusing.
I think that instead, we should define a context as:

    data Subcontext
      = SubcontextNil
      | SubcontextCons
          Value
          Subcontext
    data Context
      = ContextNil
      | ContextCons
          Value
          Subcontext -- subcontext
          Context -- next context

The trick ends up being that, when we are push something onto the context,
we cons onto the head of a list, but when we build a subcontext, we snoc
onto its tail. A subcontext must be built in the opposite direction as
the regular context because we need to be able to perform this transformation:

    let _ = ...    // At the beginning of X, this is $0
    let sub = ...  // At the beginning of X, this is $0.0
    X
    ==>
    let _ = ...    // At the beginning of X, this is $0
    let sub = ...  // At the beginning of X, this is $0.0
    let sub = ...  // At the beginning of X, this is $0.1
    X

Without rewriting X. Just one more time for emphasis (really for myself to
remember this), the indices into the subcontext appears backwards.
This is sort of a combination of debruijn indices and debruijn levels
where the syntax tree has the freedom to introduce debruijn levels
to make it cheap (and simple) to introduce binders.

The combination of these two features makes it possible to perform
optimizations like sinking let bindings without too much fuss.
The steps are:

1. Start with a syntax tree that starts with a let binding.
2. Recursively inspect the next item in the syntax tree and until
   we arrive at a place where no further sinking is possible.
3. Add a new let binding as a sub-binder. Its RHS should be the
   same as the original but with a shift applied (hmm...)
4. Replace occurrences of the old binding with the new one.
5. Replace the old binding with a tombstone.

About the shift though... How should be deal with that? It's one
of those "rewrite the term" situations that we are trying to
avoid. We could just introduce a shift operation in the syntax
tree that increments all variable references in the child expression.
Then, later, when cleaning up, perform the real shift.

One weird choice that I've noticed has to be made is whether the
subbindings should use the index of the let binding that comes
before or after them. Either way, we end up in a weird situation.
Either we cannot introduce a subbinding at the beginning of a
term, or we cannot introduce one right before a leaf. Maybe
we can support both:

    data Context
      = ContextCons
          Value
          [Value] -- subcontext
          Context
      | ContextNil
          [Value] -- subcontext

Rewrite this as:

    data ContextStep = ContextStep [Value] Context
    data Context
      = ContextCons
          Value
          ContextStep
      | ContextNil

Now, given any context (even the empty context), we can push a subbinding
onto the context. The interpretation in this system is that the subcontexts
have as their primary identifier the idenitifier of the *next* bound variable,
not the previous one.

So, the full combination of features needed to make debruijn indices
not awful to work with is:

1. Tombstone let bindings
2. Ability to mix debruijn levels and debruijn indices when binding variables
3. A syntactic construct for incrementing all variable references

I'm seeing a problem. What if we have something like this:

    let _ = ...
    let sub = ... // Line Q
    case $0 of
      True -> 
        let _ = ...
        ...
      False ->
        let sub = ...
        ...

What if there is something inside of the True and False branches that we want
to pull out with CSE? Where do we put the new binding? We would like to put it
after Line Q, but doing that causes the binding at the beginning of the False
branch to have a different level. We are ending up with some unfortunate
restrictions on where transformers can soundly introduce subbindings. I think
this particular difficult is because subbinding groups that are split across
a `case` boundary are problematic. We don't want to make it impossible to
introduce a subbinding right before a case statement. The case statement
needs to somehow split the subbindings into different groups. No, even that
is not enough.

What if we try to perform CSE on expressions that appear in two subbindings:

    let _ = ...
    let sub = foo($0) + $1
    let sub = foo($0) + $2
    ...

We cannot float the common invocation of `foo($0)` to anywhere. This whole
system appears to not be that useful.
