# Primitives for Enumerating Arrays

Broadly, there are several kinds of enumerations that programmers perform on
arrays. These are:

* Fold, uses accumulator, may terminate early.
* Traversal, produces new array, may use accumulator, early termination
  implies no new array.
* Filter, just like traversal except that elements may be dropped.

The Haskell ecosystem has adopted a stream-fusion framework, described
in [Stream fusion: from lists to streams to nothing at all](https://dl.acm.org/doi/abs/10.1145/1291220.1291199)
and implemented most prominently in the `vector` library. The crucial
data types are:

    data Step s a where
      Yield :: a -> s -> Step s a
      Skip  :: s -> Step s a
      Done  :: Step s a
    data Stream m a = forall s. Stream (s -> m (Step s a)) s

Operations like `map` and `mapM` are able to go from `Stream` to `Stream`,
which is how successive traversals can fuse.

I'm not interested in stream fusion though. I'm interested in figuring
out what array primitives a language should provide that meet 95% of users'
needs. These primitives should help the compiler perform several
optimizations.

* Compilation to vector instructions is easier when the traversal
  is high-level. This is the most important.
* Stream fusion. This is not very important.
* Flow fusion (fusing multiple passes over the same array). This is
  not very important.

How can we capture all of the key ingredients? Let's try:

    // Add all numbers in array
    for x in xs, (acc) start (0):
      continue(x + acc)
    after(acc): acc

    // Add all numbers in array, fail on large number, wrap
    // result in Some or return None.
    for x in xs, (acc) start (0):
      if(x > 1000):
        then: break(None)
        else: continue(x + acc)
    after(acc): Some(acc)

    // Find value corresponding to first element matching the
    // key, no accumulation here, but there is zipping.
    for x in xs, y in ys:
      if(x == key):
        then: break(Some y)
        else: continue()
    after(): None

The `after` clause means that, if you make it all the way to the end and
haven't broken out of the loop, then take the accumulator and do whatever
you need to to come up with a result. Simple folds like `sum` and `product`
just hand you the accumulator when they finish, but iterations that use
`break` often need to wrap the accumulator in something to indicate success.
Let's consider traversals that produce a new array:

    // Cumulative sum
    for x in xs, (acc) start (0):
      nextAcc = acc + x
      yield(nextAcc) and continue(x + acc)
    after(acc): ()

The `yield and continue` construct outputs an element for the new array
and updates the accumulator. How would flow fusion work? Let's say we
wanted to find the first index of a matching element:

    for {ix} x in xs:
      if(x == key):
        then: break(Some ix)
        else: continue()
    after(): None

And then we did this twice, each time for a different key. Assuming that
a compiler could even fuse these, what should the result look like: 

    for {ix} x in xs:
      ...

This is difficult. Why? It's because of `break`. If we were fusing
`sum` and `product`, it would be simple:

    for x in xs, (sum,prod) start (0,1):
      continue(x + sum, x * prod)
    after(sum,prod): (sum,prod)

Let's move to the issue of vectorization. Simple folds like `sum` and
`product` are easy. The tricky thing is `break`. Let's look at finding
the index of the first match:

    for {ix} x in xs:
      if(x == key):
        then: break(Some ix)
        else: continue()
    after(): None

We want to compile this to these vector instructions:

* Prelude broadcasts `key` to vector register.
* Vector register for `x`.
* Scalar register for `ix`, increments by multiple elements at a time
* Vector equality check.
* If all are false, loop around.
* If any are true, first first set bit in mask register
* Add position of first set bit to `ix` and return.
* If we make it to the end, return `None`, however that is represented.

That seems very possible. The general idea is that when we hit `break`
(or `after`), we transition from the lands of vectors back to the land
of scalars by performing horizontal operations.

For traversals that produce a new array, vectorization is straightforward
if we do not have an accumulator. If we have an accumulator, it becomes
complicated. Accumulators are fine in `sum` and `product` though, but
this is only the case because addition and multiplication are both
commutative. So, commutativity helps a lot. But it is difficult to parallelize
cumulative sum. Here the problem is that we have to keep inspecting
the result as the computation is happening. We would have similar
difficulty with:

    // Abort if sum exceeds 1000
    for x in xs, (acc) start (0):
      nextAcc = acc + x
      if(nextAcc > 1000):
        then: break(None)
        else: continue(nextAcc)
    after(acc): Some(acc)

Here, we have lost commutativity. Rather that have several parallel worlds
that join up at the end, we must perform a horizontal operation at each
step. And if some of the numbers in the array are negative, then there is
just no way to vectorize this. We need the sum at each step. The reason
that we could vectorize the find-first-match operation from earlier was
because the horizontal operation (`ktest`) doesn't allow results to mess
with each other.

# Conclusion

Vectorizing these constructs seems very difficult. I think that it would
be better for both the end user and the compiler author to just provide
built-in functions that a user could expect to be vectorized. Explicitly 
written loops would never be vectorized.

# Final Thoughts

Even without vectorization, I do think there are benefits to dedicated
control-flow constructs for array iteration. I think that rather than
having a `break` keyword, it might be better to just allow jumping to
a join point from the body of a `for`:

    // Add all numbers in array, fail on large number.
    toobig:
      ...
    success(total):
      ...
    for x in xs, (acc) start (0):
      after: jump success(acc)
      body:
        if(x > 1000):
          then: jump toobig
          else: continue(x + acc)

# Final Final Thoughts

There doesn't really seem to be anything to be gained by the iteration
construct. It's probably better to just have a `loop` with an accumulator,
and then the user can perform indexing inside it and decide when to terminate.
And `loop` is really just an anonymous recursive join point.

# More Thoughts

Nope. If we want `map` and `filter` without adding mutation, then we need
a looping construct. How about this:

    failure(n):
      ...
    success(n):
      ...
    for x in xs:
      .state (acc) starts (0)
      .epilogue:
        jump success(acc)
      .prologue:
        a = complicatedExpression(b)
      if(x > 50):
        then:
          if a < 200:
            then: jump failure(12)
            else: continue(acc + 2)
        else: continue(acc + 1)

For `map` and `filter`, we need to be able to output an element at each step:

    map x in xs:
      .epilogue(r): r  // the epilogue has access to the new array
      .prologue:
        a = complicatedExpression(b)
      yield(x + a)

And `filter` is like `map` except that you can use `yield` or `skip`. There
are lots of things we cannot do with `filter` and `skip`:

* Exploding an element into multiple elements
* Element insertion (grow an array by a single element)
* Element deletion

Insertion and deletion should be handled by primitives. That is, perform the
scan and then, in a second step, do the update with the primitive. But
exploding is more tricky. Intuitively, the way to do this is by letting
people call `yield` more than once, but the resulting language requires
sequencing. At least, the yields need to be kept in a particular order.

Let's look at another example of `map` with more defaulting going on:

    zs = :
      map x in xs:
        yield(x + 2)
    blah

But this is nearly equivalent to:

    map x in xs:
      .epilogue(zs):
        blah
      yield(x + 2)

However, the second version is slightly more powerful because it allows us to
jump out of the `map` statement. Join point contexts are reset on the RHS
of let bindings.
